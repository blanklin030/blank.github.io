<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>clickhouse 表写入报readonly排查</title>
    <url>/2022/12/08/clickhouse%20%E8%A1%A8readonly%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>clickhouse的Replicated<em>MergeTree表是通过zookeeper来完成同一个shard之间的副本数据的同步，当<em>*Table is in readonly mode</em></em>的原因是zookeeper当下压力过大，这个可以从system.replication_queue看到同步队列的数量，或者通过system.part_log看当前part的处理数量</p>
<h3 id="system-replicas"><a href="#system-replicas" class="headerlink" title="system.replicas"></a>system.replicas</h3><blockquote>
<p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/replicas" target="_blank" rel="noopener">官方地址</a>所解释,该表记录了驻留在本地服务器上的复制表的信息和状态，如下图所示，我们看到每个表的每个副本在zookeeper上的状态</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select table,zookeeper_path,replica_path from &#96;system&#96;.replicas limit 10</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/readonly/1.png" alt="clickhouse"><br>如上图所示，<strong>zookeeper_path</strong>字段可以查看到在哪个shard上的哪个副本处于readonly状态。</p>
<h3 id="system-part-log"><a href="#system-part-log" class="headerlink" title="system.part_log"></a>system.part_log</h3><blockquote>
<p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/part_log" target="_blank" rel="noopener">官方地址</a>，该表包含part操作的所有记录，包括drop/merge/download/new等。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT *    </span><br><span class="line">FROM system.part_log</span><br><span class="line">WHERE  concat(database, &#39;.&#39;, table) &#x3D; &#39;i9xiaoapp_stream.dwd_pope_core_action_diff_di_local&#39;</span><br><span class="line">and event_time &gt;&#x3D; &#39;2023-01-15 12:00:00&#39;</span><br><span class="line">order by event_time desc</span><br></pre></td></tr></table></figure><br><img src="/images/clickhouse/readonly/2.png" alt="clickhouse"></p>
</blockquote>
<h3 id="解决副本不同步问题"><a href="#解决副本不同步问题" class="headerlink" title="解决副本不同步问题"></a>解决副本不同步问题</h3><blockquote>
<p>注意，此时先让用户把写入任务停掉，已方便观察！</p>
<ul>
<li>可以通过system.part_log查询mergepart状态的写入是否都已经完成</li>
<li>根据system.replicas表给出的readonly状态的zookeeper_path，去到当前所指向的副本机器上，删除这个副本的表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop table i9xiaoapp_stream.dwd_pope_core_action_diff_di_local</span><br></pre></td></tr></table></figure></li>
<li>操作之后，可以通过查询system.replicas里看是否还有处于readonly，发现已经消失<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select table,zookeeper_path,replica_path from &#96;system&#96;.replicas where concat(database, &#39;.&#39;, table) &#x3D; &#39;i9xiaoapp_stream.dwd_pope_core_action_diff_di_local&#39; limit 10</span><br></pre></td></tr></table></figure></li>
<li>再在出问题的副本上，重新创建该本，之后可通过system.replicas找到该副本再次出现，并且已恢复<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table</span><br></pre></td></tr></table></figure></li>
<li>如果还没恢复，则去对应出错的副本节点，去检查一下zookeeper上的对应路径是否也已经删除<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rmr zookeeper_path</span><br></pre></td></tr></table></figure></li>
<li>此时再查询system.replicas表readonly的队列应该已经被清理掉了<br>可以继续操作元数据修改</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>使用clickhouse实现数据更新和删除</title>
    <url>/2022/02/03/clickhouse-crud/</url>
    <content><![CDATA[<h3 id="什么是CRUD"><a href="#什么是CRUD" class="headerlink" title="什么是CRUD"></a>什么是CRUD</h3><blockquote>
<p><code>CRUD</code>是指在做计算处理时的增加(<code>Create</code>)、检索(<code>Retrieve</code>)、更新(<code>Update</code>)和删除(<code>Delete</code>)几个单词的首字母简写。<code>crud</code>主要被用在描述软件系统中数据库或者持久层的基本操作功能</p>
</blockquote>
<h3 id="clickhouse物理上的crud"><a href="#clickhouse物理上的crud" class="headerlink" title="clickhouse物理上的crud"></a>clickhouse物理上的crud</h3><ul>
<li><ol>
<li>create创建表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table account(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  is_delete UInt8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; MergeTree </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure>
<img src="/images/clickhouse/crud/5.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>insert写入数据<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into default.account(time, name, alias, age, version, is_delete) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 0)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>写入数据后会按照partitionby生成对应的分区part目录<br><img src="/images/clickhouse/crud/6.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>update更新<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table default.account</span><br><span class="line">update alias &#x3D; &#39;super_hero&#39;</span><br><span class="line">where alias &#x3D; &#39;superhero&#39;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/4.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>delete删除<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table delete where id &#x3D; 1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/7.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>retrieve检索<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select time, name, alias, age, version, is_delete from account where is_delete &#x3D; 0 order by version desc</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><ol>
<li>可以通过system.mutations查询执行计划<br><img src="/images/clickhouse/crud/9.png" alt="avatar"><br>当mutation操作执行完成后，system.mutations表中对应的mutation记录中is_done字段的值会变为1。</li>
</ol>
</li>
<li><ol>
<li>可以通过system.parts查询执行结果<br><img src="/images/clickhouse/crud/8.png" alt="avatar"><br>当旧的数据片段移除后，system.parts表中旧数据片段对应的记录会被移除。</li>
</ol>
</li>
</ul>
<blockquote>
<p>可以看到mutation操作完成后，之前的目录已经被删除<br><img src="/images/clickhouse/crud/10.png" alt="avatar"></p>
</blockquote>
<h3 id="clickhouse的mutation是什么"><a href="#clickhouse的mutation是什么" class="headerlink" title="clickhouse的mutation是什么"></a>clickhouse的mutation是什么</h3><h4 id="官方文档解释"><a href="#官方文档解释" class="headerlink" title="官方文档解释"></a>官方文档解释</h4><p>从官方对于mutaiton的解释<a href="https://clickhouse.com/docs/zh/sql-reference/statements/alter/#alter-mutations" target="_blank" rel="noopener">链接</a>中，我们需要注意到几个关键词，如下</p>
<ul>
<li><ol>
<li>manipulate table data<br>操作表数据</li>
</ol>
</li>
<li><ol>
<li>asynchronous background processes<br>异步后台处理</li>
</ol>
</li>
<li><ol>
<li>rewriting whole data parts<br>重写全部数据part</li>
</ol>
</li>
<li><ol>
<li>a SELECT query that started executing during a mutation will see data from parts that have already been mutated along with data from parts that have not been mutated yet<br>在突变期间的查询语句，将看到已经完成突变的数据part和还未发生突变的part</li>
</ol>
</li>
<li><ol>
<li>data that was inserted into the table before the mutation was submitted will be mutated and data that was inserted after that will not be mutated<br>在提交突变之前插入表中的数据将被突变，而在此之后插入的数据将不会被突变</li>
</ol>
</li>
<li><ol>
<li>There is no way to roll back the mutation once it is submitted, but if the mutation is stuck for some reason it can be cancelled with the KILL MUTATION query<br>突变一旦被提交就没有方式可以回滚，但是如果突变由于一些原因被卡住，可以使用<code>KILL MUTATION</code>取消突变</li>
</ol>
</li>
</ul>
<h4 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h4><p>当用户执行一个如上的Mutation操作获得返回时，ClickHouse内核其实只做了两件事情：<br><img src="/images/clickhouse/crud/1.png" alt="avatar"></p>
<ul>
<li><ol>
<li>检查Mutation操作是否合法；<blockquote>
<p>主体逻辑在MutationsInterpreter::validate函数</p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>保存Mutation命令到存储文件中，唤醒一个异步处理merge和mutation的工作线程；<blockquote>
<p>主体逻辑在StorageMergeTree::mutate函数中。</p>
</blockquote>
</li>
</ol>
</li>
</ul>
<p>Merge逻辑<br><strong>StorageMergeTree::merge</strong>函数是<code>MergeTree</code>异步<code>Merge</code>的核心逻辑，<code>Data Part Merge</code>的工作除了通过后台工作线程自动完成，用户还可以通过<code>Optimize</code>命令来手动触发。自动触发的场景中，系统会根据后台空闲线程的数据来启发式地决定本次<code>Merge</code>最大可以处理的数据量大小，<strong>max_bytes_to_merge_at_min_space_in_pool</strong>: 决定当空闲线程数最大时可处理的数据量上限（默认150GB）<br><strong>max_bytes_to_merge_at_max_space_in_pool</strong>: 决定只剩下一个空闲线程时可处理的数据量上限（默认1MB）<br>当用户的写入量非常大的时候，应该适当调整工作线程池的大小和这两个参数。当用户手动触发<code>merge</code>时，系统则是根据<code>disk</code>剩余容量来决定可处理的最大数据量。</p>
<p>Mutation逻辑<br>系统每次都只会订正一个<code>Data Part</code>，但是会聚合多个<code>mutation</code>任务批量完成，这点实现非常的棒。因为在用户真实业务场景中一次数据订正逻辑中可能会包含多个<code>Mutation</code>命令，把这多个<code>mutation</code>操作聚合到一起订正效率上就非常高。系统每次选择一个排序键最小的并且需要订正<code>Data Part</code>进行操作，本意上就是把数据从前往后进行依次订正。<br><img src="/images/clickhouse/crud/11.png" alt="avatar"><br><img src="/images/clickhouse/crud/13.png" alt="avatar"><br><img src="/images/clickhouse/crud/12.png" alt="avatar"></p>
<p>mutation和merge相互独立执行。看完本文前面的分析，大家应该也注意到了目前Data Part的merge和mutation是相互独立执行的，Data Part在同一时刻只能是在merge或者mutation操作中。对于MergeTree这种存储彻底Immutable的设计，数据频繁merge、mutation会引入巨大的IO负载。实时上merge和mutation操作是可以合并到一起去考虑的，这样可以省去数据一次读写盘的开销。对数据写入压力很大又有频繁mutation的场景，会有很大帮助</p>
<h3 id="clickhouse逻辑CRUD"><a href="#clickhouse逻辑CRUD" class="headerlink" title="clickhouse逻辑CRUD"></a>clickhouse逻辑CRUD</h3><p><a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/versionedcollapsingmergetree/" target="_blank" rel="noopener">VersionedCollapsingMergeTree介绍</a>，引擎继承自 <code>MergeTree</code> 并将折叠行的逻辑添加到合并数据部分的算法中。 <code>VersionedCollapsingMergeTree</code> 用于相同的目的 折叠树 但使用不同的折叠算法，允许以多个线程的任何顺序插入数据。 特别是， <code>Version</code> 列有助于正确折叠行，即使它们以错误的顺序插入。 相比之下, <code>CollapsingMergeTree</code> 只允许严格连续插入。</p>
<h4 id="创建VersionedCollapsingMergeTree表"><a href="#创建VersionedCollapsingMergeTree表" class="headerlink" title="创建VersionedCollapsingMergeTree表"></a>创建VersionedCollapsingMergeTree表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table test_version_collapsing(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  sign Int8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; VersionedCollapsingMergeTree(sign, version) </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure>
<h4 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 1)</span><br></pre></td></tr></table></figure>
<h4 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h4><ul>
<li><ol>
<li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>假设要更新alias=update_super_hero，其他值不变，将version由1.捞出的值上+1，类似以下sql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先将旧行标示为删除，就是将sign &#x3D; -1</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, -1);</span><br><span class="line"></span><br><span class="line"># 再去插入新行，包含要更新的列</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, 1).</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><ul>
<li><ol>
<li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>假设要删除alias=update_super_hero，其他值不变，将sign=1,类似以下sql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, -1)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h4 id="注意项"><a href="#注意项" class="headerlink" title="注意项"></a>注意项</h4><ul>
<li><ol>
<li>只有相同分区内的数据才能删除和更新</li>
</ol>
</li>
<li><ol>
<li>如果不使用 <strong>having sum(sign) &gt; 0</strong>的方式去查询，则可以使用<code>final</code>方式查询<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from test_version_collapsing final;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>也可以使用<code>optimize</code>方式强制合并分区，再查询，但是这个方式可能会造成集群cpu飙高，而且<code>optimize</code>一个大表需要时间很长，效率极低<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">optimize table test_version_collapsing final</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>sign必须要唯一，添加用1，则删除一定是-1，才可以被折叠处理</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>beego安装和使用</title>
    <url>/2020/08/17/beego-install/</url>
    <content><![CDATA[<ul>
<li><p>beego是什么</p>
<blockquote>
<p>beego 是一个快速开发 Go 应用的 HTTP 框架，他可以用来快速开发 API、Web 及后端服务等各种应用，是一个 RESTful 的框架，主要设计灵感来源于 tornado、sinatra 和 flask 这三个框架，但是结合了 Go 本身的一些特性（interface、struct 嵌入等）而设计的一个框架。<a href="https://beego.me" target="_blank" rel="noopener">beego</a></p>
</blockquote>
</li>
<li><p>查看go的安装环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go env || grep GO111MODULE</span><br></pre></td></tr></table></figure>
<p><img src="/images/go-env.png" alt="go-env"></p>
</li>
<li><p>打开GO111MODULE</p>
<blockquote>
<p>go在1.11之后推出了自己的官方版本管理工具mod，需要使用mod必须将go的配置参数GO111MODULE打开，用以支持使用模块，注意在打开GO111MODULE后下载的依赖还是存在$GOPATH/pkg/mod中，而go install的结果放在$GOPATH/bin下，但是项目不再局限放在$GOPATH/src下，在任何位置我们都可以使用到$GOPATH/pkg/mod下的依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go env -w GO111MODULE&#x3D;on</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>修改go proxy</p>
<blockquote>
<p>由于wall的存在，我们无法使用官方的go proxy，所以需要修改proxy地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go env -w GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn,direct</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>安装beego和bee</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go get github.com&#x2F;astaxie&#x2F;beego</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装bee工具</p>
<blockquote>
<p>bee 工具是一个为了协助快速开发 beego 项目而创建的项目，您可以通过 bee 快速创建项目、实现热编译、开发测试以及开发完之后打包发布的一整套从创建、开发到部署的方案。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go get github.com&#x2F;beego&#x2F;bee</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>把bee添加为系统命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export GOPATH&#x3D;&#x2F;Users&#x2F;blanklin&#x2F;go</span><br><span class="line">export PATH&#x3D;$PATH:$GOPATH&#x2F;bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>新建helloworld项目</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bee new helloworld</span><br></pre></td></tr></table></figure></li>
<li><p>helloworld项目目录结构<br>helloworld<br>├── conf<br>│   └── app.conf<br>├── controllers<br>│   └── default.go<br>├── main.go<br>├── models<br>├── routers<br>│   └── router.go<br>├── static<br>│   ├── css<br>│   ├── img<br>│   └── js<br>├── tests<br>│   └── default_test.go<br>└── views<br>  └── index.tpl</p>
</li>
<li><p>新建api项目</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bee api helloworld</span><br></pre></td></tr></table></figure>
</li>
<li><p>api项目目录结构<br>helloworld<br>├── conf<br>│   └── app.conf<br>├── controllers<br>│   └── object.go<br>│   └── user.go<br>├── docs<br>│   └── doc.go<br>├── main.go<br>├── models<br>│   └── object.go<br>│   └── user.go<br>├── routers<br>│   └── router.go<br>└── tests<br>  └── default_test.go</p>
</li>
</ul>
<blockquote>
<p>和web项目对比，少了 static 和 views 目录，多了一个 test 模块，用来做单元测试的<br>可直接通过参数创建orm：bee api [appname] [-tables=””] [-driver=mysql] [-conn=root:@tcp(127.0.0.1:3306)/test]</p>
</blockquote>
<ul>
<li><p>使用go mod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go mod init helloworld</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行beego项目</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bee run</span><br><span class="line"># 配合conf&#x2F;app.conf[EnableDocs &#x3D; true]开启swagger</span><br><span class="line">bee run -downdoc&#x3D;true -gendoc&#x3D;true</span><br></pre></td></tr></table></figure>
<blockquote>
<p>打开浏览器访问beego开启的本地端口，一般是8080，所以地址是：<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
</blockquote>
</li>
<li><p>使用pack命令部署生产环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bee pack -be GOOS&#x3D;linux</span><br><span class="line"># 生成一个压缩文件helloworld.tar.gz</span><br><span class="line"># 在生成环境解压后运行</span><br><span class="line">nohup .&#x2F;helloworld &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用docker部署生产环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM golang:1.14.2-buster</span><br><span class="line"></span><br><span class="line">ENV TZ Asia&#x2F;Shanghai</span><br><span class="line">ENV GOKU_LOGLEVEL info</span><br><span class="line"></span><br><span class="line">ENV GOKU_RUNMODE prod</span><br><span class="line">ENV GOKU_PORT 8080</span><br><span class="line"></span><br><span class="line">RUN go build -v -o .&#x2F;build&#x2F;goku .&#x2F;main.go</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;app</span><br><span class="line"></span><br><span class="line">COPY ..&#x2F;conf &#x2F;app&#x2F;conf</span><br><span class="line">COPY .&#x2F;build&#x2F;goku &#x2F;app&#x2F;goku</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [&quot;.&#x2F;goku&quot;]</span><br></pre></td></tr></table></figure></li>
<li>本项目GitHub<br><a href="https://github.com/blanklin030/beego-docker" target="_blank" rel="noopener">https://github.com/blanklin030/beego-docker</a><blockquote>
<p>提供初始化后支持mysql的基础crud和相关配置</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>beego</tag>
      </tags>
  </entry>
  <entry>
    <title>带你开箱真香ClickHouse</title>
    <url>/2019/11/26/clickhouse-hello-world/</url>
    <content><![CDATA[<h2 id="OLAP介绍"><a href="#OLAP介绍" class="headerlink" title="OLAP介绍"></a>OLAP介绍</h2><h4 id="OLAP概述"><a href="#OLAP概述" class="headerlink" title="OLAP概述"></a>OLAP概述</h4><p>OLAP，也叫联机分析处理（Online Analytical Processing）系统，就是我们说的数据仓库。在这样的系统中，语句的执行量不是考核标准，因为一条语句的执行时间可能会非常长，读取的数据也非常多。所以，在这样的系统中，考核的标准往往是磁盘子系统的吞吐量（带宽），如能达到多少MB/s的流量。<br>在OLAP系统中，比较典型的应用是BI平台，常使用分区技术、并行技术。 分区技术在OLAP系统中的重要性主要体现在数据库管理上，比如数据库加载，可以通过分区交换的方式实现，备份可以通过备份分区表空间实现，删除数据可以通过分区进行删除，至于分区在性能上的影响，它可以使得一些大表的扫描变得很快（只扫描单个分区）。另外，如果分区结合并行的话，也可以使得整个表的扫描会变得很快。总之，分区主要的功能是管理上的方便性，它并不能绝对保证查询性能的提高，有时候分区会带来性能上的提高，有时候会降低。</p>
<h4 id="OLAP特点"><a href="#OLAP特点" class="headerlink" title="OLAP特点"></a>OLAP特点</h4><ul>
<li>大多数是读请求</li>
<li>数据总是以相当大的批(&gt; 1000 rows)进行写入</li>
<li>不修改已添加的数据</li>
<li>每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列</li>
<li>宽表，即每个表包含着大量的列</li>
<li>较少的查询(通常每台服务器每秒数百个查询或更少)</li>
<li>对于简单查询，允许延迟大约50毫秒</li>
<li>列中的数据相对较小： 数字和短字符串(例如，每个URL 60个字节)</li>
<li>处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行）</li>
<li>事务不是必须的</li>
<li>对数据一致性要求低</li>
<li>每一个查询除了一个大表外都很小</li>
<li>查询结果明显小于源数据，换句话说，数据被过滤或聚合后能够被盛放在单台服务器的内存中<blockquote>
<p>很容易可以看出，OLAP场景与其他流行场景(例如,OLTP或K/V)有很大的不同， 因此想要使用OLTP或Key-Value数据库去高效的处理分析查询是没有意义的，例如，使用OLAP数据库去处理分析请求通常要优于使用MongoDB或Redis去处理分析请求。  </p>
</blockquote>
</li>
</ul>
<h2 id="行式数据库系统介绍"><a href="#行式数据库系统介绍" class="headerlink" title="行式数据库系统介绍"></a>行式数据库系统介绍</h2><p>常见的行式数据库系统有： MySQL、Postgres和MS SQL Server。<br>处于同一行中的数据总是被物理的存储在一起。  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Row</th>
<th style="text-align:center">WatchID</th>
<th style="text-align:right">JavaEnable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">#0</td>
<td style="text-align:center">11111</td>
<td style="text-align:right">1</td>
</tr>
<tr>
<td style="text-align:left">#1</td>
<td style="text-align:center">22222</td>
<td style="text-align:right">0</td>
</tr>
<tr>
<td style="text-align:left">#3</td>
<td style="text-align:center">33333</td>
<td style="text-align:right">1</td>
</tr>
</tbody>
</table>
</div>
<h2 id="列式数据库系统介绍"><a href="#列式数据库系统介绍" class="headerlink" title="列式数据库系统介绍"></a>列式数据库系统介绍</h2><p>常见的列式数据库有： Vertica、 Paraccel (Actian Matrix，Amazon Redshift)、 Sybase IQ、 Exasol、 Infobright、 InfiniDB、 MonetDB (VectorWise， Actian Vector)、 LucidDB、 SAP HANA、 Google Dremel、 Google PowerDrill、 Druid、 kdb+。列式数据库总是将同一列的数据存储在一起，不同列的数据也总是分开存储。  </p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Row</th>
<th style="text-align:center">#0</th>
<th style="text-align:right">#1</th>
<th style="text-align:right">#2 ｜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">WatchID</td>
<td style="text-align:center">11111</td>
<td style="text-align:right">22222</td>
<td style="text-align:right">33333</td>
</tr>
<tr>
<td style="text-align:left">JavaEnable</td>
<td style="text-align:center">1</td>
<td style="text-align:right">0</td>
<td style="text-align:right">1</td>
</tr>
</tbody>
</table>
</div>
<h2 id="clickhouse介绍"><a href="#clickhouse介绍" class="headerlink" title="clickhouse介绍"></a>clickhouse介绍</h2><p> ClickHouse是一个用于联机分析(<strong>OLAP</strong>)的<strong>列式数据库</strong>管理系统(DBMS)，是俄罗斯的百度——yandex公司开发的。yandex公司在处理自己公司日常数据业务中，开发了一套数据管理系统，随后进行了开源分享，命名为<a href="https://clickhouse.yandex/docs/en/" target="_blank" rel="noopener">clickhouse</a>。</p>
<h3 id="clickhouse优势"><a href="#clickhouse优势" class="headerlink" title="clickhouse优势"></a>clickhouse优势</h3><ul>
<li><p>线性可扩展</p>
<ul>
<li>可以部署在虚拟机上，也可以部署在有成百上千个节点（机器）的集群上,单个节点可容纳万亿行数据或超过100TB数据</li>
</ul>
</li>
<li><p>高效的硬件利用</p>
<ul>
<li>多核并行处理,数据高效压缩</li>
</ul>
</li>
<li>容错性和高可靠性<ul>
<li>ClickHouse支持多shard（master/slave）异步复制并且能部署在多个数据中心上</li>
<li>单节点或者整个数据中心宕机不会影响系统读写的可靠性</li>
<li>分布式读取模式，自动（将吞吐压力）均衡于各可用的备份节点上从而避免高时延</li>
<li>宕机恢复后备份间数据自动同步或半自动同步</li>
</ul>
</li>
<li>查询速度快<ul>
<li>面向列的DBMS，使用向量化引擎，数据压缩，每秒能处理亿级行级别的数据，简单查询时峰值处理性能可达到单服务器每秒2TB</li>
</ul>
</li>
<li>丰富的特征<ul>
<li>支持sql语法，丰富的内置分析统计函数/组件，比如基数、百分位数计算；日期、时间、时区数据函数；URL和IP地址处理函数</li>
<li>数据组织和存储格式丰富，比如存储复杂数据的arrays, array joins, tuples and nested data structures，这些数据结构都做了读写和计算优化，因此用来处理和查询非结构化数据（也可以叫半结构化）也是非常高效率的</li>
<li>支持本地join和分布式join，支持额外定义的字典、从外部导入的维度表，通过简单的语法句子就能无缝join数据</li>
<li>支持近似查询处理，提高获得结果的速度，特别是在处理TB/PB级别数据的时候（比如抽样部分数据计算一个结果然后推广到总体）</li>
<li>支持按条件汇总函数，可以用非常简单的句法查询极值和汇总数据查询  <h2 id="clickhouse缺点"><a href="#clickhouse缺点" class="headerlink" title="clickhouse缺点"></a>clickhouse缺点</h2></li>
</ul>
</li>
<li>不支持Transaction：想快就别想Transaction</li>
<li>聚合结果必须小于一台机器的内存大小：不是大问题</li>
<li>缺少完整的Update/Delete操作<h2 id="clickhouse架构"><a href="#clickhouse架构" class="headerlink" title="clickhouse架构"></a>clickhouse架构</h2><img src="/images/clickhouse.png" alt="clickhouse"><h2 id="clickhou接入"><a href="#clickhou接入" class="headerlink" title="clickhou接入"></a>clickhou接入</h2></li>
</ul>
<ol>
<li>http接入<br>传入用户名密码的方式<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 读方式</span><br><span class="line">echo &#39;SELECT 1&#39; | curl &#39;http:&#x2F;&#x2F;user:password@localhost:8123&#x2F;?database&#x3D;dbname&#39; -d @-</span><br><span class="line">&#x2F;&#x2F; 写方式</span><br><span class="line">echo &#39;SELECT 1&#39; | curl &#39;http:&#x2F;&#x2F;localhost:8123&#x2F;?database&#x3D;dbname&amp;user&#x3D;user&amp;password&#x3D;password&#39; -d @-</span><br></pre></td></tr></table></figure></li>
<li><p>JDBC驱动</p>
<ul>
<li><p>ClickHouse官方有 JDBC 的驱动。 见<a href="https://github.com/yandex/clickhouse-jdbc" target="_blank" rel="noopener">这里</a>。</p>
</li>
<li><p>第三方提供的 JDBC 驱动 <a href="https://github.com/blynkkk/clickhouse4j" target="_blank" rel="noopener">clickhouse4j</a> （推荐，依赖较少）。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; jdbc的连接字符串是</span><br><span class="line">jdbc:clickhouse:&#x2F;&#x2F;&lt;host&gt;&#x2F;&lt;database&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>可视化操作界面Tabix<br>ClickHouse Web 界面 <a href="https://github.com/tabixio/tabix" target="_blank" rel="noopener">Tabix</a></p>
<p> 主要功能：</p>
<ul>
<li>浏览器直接连接 ClickHouse，不需要安装其他软件。</li>
<li>高亮语法的编辑器。</li>
<li>自动命令补全。</li>
<li>查询命令执行的图形分析工具。</li>
<li>配色方案选项。</li>
</ul>
</li>
<li><p>命令行客户端<br>参照 <a href="https://github.com/hatarist/clickhouse-cli" target="_blank" rel="noopener">https://github.com/hatarist/clickhouse-cli</a> 使用，要求Python 3.4+</p>
<p>pip3安装请<a href="https://www.runoob.com/w3cnote/python-pip-install-usage.html" target="_blank" rel="noopener">参照</a></p>
<p><a href="https://github.com/hatarist/clickhouse-cli#configuration-file" target="_blank" rel="noopener">内容查看</a><br>步骤如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 install clickhouse-cli</span><br><span class="line">vi ~&#x2F;.clickhouse-cli.rc</span><br></pre></td></tr></table></figure>
<h2 id="表引擎"><a href="#表引擎" class="headerlink" title="表引擎"></a>表引擎</h2><p>表引擎（即表的类型）决定了：</p>
</li>
</ol>
<ul>
<li>数据的存储方式和位置，写到哪里以及从哪里读取数据</li>
<li>支持哪些查询以及如何支持。</li>
<li>并发数据访问。</li>
<li>索引的使用（如果存在）。</li>
<li>是否可以执行多线程请求。</li>
<li>数据复制参数。<h3 id="MergeTree"><a href="#MergeTree" class="headerlink" title="MergeTree"></a>MergeTree</h3>适用于高负载任务的最通用和功能最强大的表引擎。这些引擎的共同特点是可以快速插入数据并进行后续的后台数据处理。 MergeTree系列引擎支持数据复制（使用Replicated* 的引擎版本），分区和一些其他引擎不支持的其他功能<br>该类型的引擎： </li>
<li>MergeTree </li>
<li>ReplacingMergeTree </li>
<li>SummingMergeTree </li>
<li>AggregatingMergeTree </li>
<li>CollapsingMergeTree</li>
<li>VersionedCollapsingMergeTree </li>
<li>GraphiteMergeTree</li>
</ul>
<h3 id="数据副本"><a href="#数据副本" class="headerlink" title="数据副本"></a>数据副本</h3><p>只有 MergeTree 系列里的表可支持副本：</p>
<ul>
<li>ReplicatedMergeTree</li>
<li>ReplicatedSummingMergeTree</li>
<li>ReplicatedReplacingMergeTree</li>
<li>ReplicatedAggregatingMergeTree</li>
<li>ReplicatedCollapsingMergeTree</li>
<li>ReplicatedVersionedCollapsingMergeTree</li>
<li><p>ReplicatedGraphiteMergeTree<br>副本是表级别的，不是整个服务器级的。所以，服务器里可以同时有复制表和非复制表。<br>副本不依赖分片。每个分片有它自己的独立副本。</p>
<blockquote>
<p>对于 INSERT 和 ALTER 语句操作数据的会在压缩的情况下被复制（从master-》slave ）。<br>而 CREATE，DROP，ATTACH，DETACH 和 RENAME 语句只会在单个服务器上执行，不会被复制。<br>所以在使用集群操作表时需要使用ON CLUSTER cluster_name来通知集群所有机器都操作这个动作。</p>
</blockquote>
</li>
<li><p>The CREATE TABLE 在运行此语句的服务器上创建一个新的可复制表。如果此表已存在其他服务器上，则给该表添加新副本。</p>
</li>
<li>The DROP TABLE 删除运行此查询的服务器上的副本。</li>
<li>The RENAME 重命名一个副本。换句话说，可复制表不同的副本可以有不同的名称。<br>要使用副本，需在配置文件中设置 ZooKeeper 集群的地址。例如：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;zookeeper&gt;</span><br><span class="line">    &lt;node index&#x3D;&quot;1&quot;&gt;</span><br><span class="line">        &lt;host&gt;example1&lt;&#x2F;host&gt;</span><br><span class="line">        &lt;port&gt;2181&lt;&#x2F;port&gt;</span><br><span class="line">    &lt;&#x2F;node&gt;</span><br><span class="line">    &lt;node index&#x3D;&quot;2&quot;&gt;</span><br><span class="line">        &lt;host&gt;example2&lt;&#x2F;host&gt;</span><br><span class="line">        &lt;port&gt;2181&lt;&#x2F;port&gt;</span><br><span class="line">    &lt;&#x2F;node&gt;</span><br><span class="line">    &lt;node index&#x3D;&quot;3&quot;&gt;</span><br><span class="line">        &lt;host&gt;example3&lt;&#x2F;host&gt;</span><br><span class="line">        &lt;port&gt;2181&lt;&#x2F;port&gt;</span><br><span class="line">    &lt;&#x2F;node&gt;</span><br><span class="line">&lt;&#x2F;zookeeper&gt;</span><br></pre></td></tr></table></figure>
注意：ZooKeeper 3.4.5 或更高版本。<h3 id="创建复制表"><a href="#创建复制表" class="headerlink" title="创建复制表"></a>创建复制表</h3>在表引擎名称上加上 Replicated 前缀。例如：ReplicatedMergeTree。<br>Replicated*MergeTree 参数</li>
<li>zoo_path — ZooKeeper 中该表的路径。</li>
<li>replica_name — ZooKeeper 中的该表的副本名称。  </li>
</ul>
<p>使用ON CLUSTER cluster功能在集群创建本地表<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE db.table_local </span><br><span class="line">ON CLUSTER cluster_name (</span><br><span class="line">  &#96;name&#96; String COMMENT &#39;姓名&#39;,</span><br><span class="line">  &#96;age&#96; String,</span><br><span class="line">  &#96;pt&#96; String,</span><br><span class="line">) </span><br><span class="line">ENGINE &#x3D; ReplicatedMergeTree(</span><br><span class="line">  &#39;&#x2F;clickhouse&#x2F;tables&#x2F;&#123;shard&#125;&#x2F;db&#x2F;table_local&#39;,</span><br><span class="line">  &#39;&#123;replica&#125;&#39;</span><br><span class="line">) </span><br><span class="line">PARTITION BY (pt)</span><br><span class="line">ORDER BY (age) </span><br><span class="line">SETTINGS index_granularity &#x3D; 8192</span><br></pre></td></tr></table></figure><br>如上例所示，这些参数可以包含宏替换的占位符，即大括号的部分。它们会被替换为配置文件里 ‘macros’ 那部分配置的值。示例：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;macros&gt;</span><br><span class="line">    &lt;shard&gt;02&lt;&#x2F;shard&gt;</span><br><span class="line">    &lt;replica&gt;example05-02-1.yandex.ru&lt;&#x2F;replica&gt;</span><br><span class="line">&lt;&#x2F;macros&gt;</span><br></pre></td></tr></table></figure><br>ZooKeeper 中该表的路径对每个可复制表都要是唯一的。不同分片(shard)上的表要有不同的路径。 这种情况下，路径包含下面这些部分：<br>/clickhouse/tables/ 是公共前缀，我们推荐使用这个。<br>{shard} 是分片标识部分。保留 {shard} 占位符即可，它会替换展开为分片标识。<br>db/table_local 是该表在 ZooKeeper 中的名称。使其与 ClickHouse 中的表名相同加后缀_local来区分。<br>注意：也可以显式指定这些参数，而不是使用宏替换。对于测试和配置小型集群这可能会很方便。但是，这种情况下，则不能使用分布式 DDL 语句（ON CLUSTER）。</p>
<ul>
<li>使用ON CLUSTER cluster功能在集群创建分布式表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE db.table </span><br><span class="line">ON CLUSTER cluster_name</span><br><span class="line">AS db.table_local</span><br><span class="line">ENGINE &#x3D; Distributed (</span><br><span class="line">  cluster_name, </span><br><span class="line">  db,</span><br><span class="line">  table_local,</span><br><span class="line">  rand()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3></li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse query on cluster源码解读</title>
    <url>/2022/01/21/clickhouse-ddl-on-cluster/</url>
    <content><![CDATA[<h3 id="分布式DDL执行链路"><a href="#分布式DDL执行链路" class="headerlink" title="分布式DDL执行链路"></a>分布式DDL执行链路</h3><blockquote>
<p>在介绍具体的分布式<code>DDL</code>执行链路之前，先为大家梳理一下哪些操作是可以走分布式<code>DDL</code>执行链路的，大家也可以自己在源码中查看一下<code>ASTQueryWithOnCluster</code>的继承类有哪些：<br><img src="/images/clickhouse/ddloncluster/1.png" alt="cgi">  </p>
</blockquote>
<ul>
<li>ASTAlterQuery：<br>包括<code>ATTACH_PARTITION</code>、<code>FETCH_PARTITION</code>、<code>FREEZE_PARTITION</code>、<code>FREEZE_ALL</code>等操作（对表的数据分区粒度进行操作）。</li>
<li>ASTCreateQuery：<br>包括常见的建库、建表、建视图，还有<code>ClickHouse</code>独有的<code>Attach Table</code>（可以从存储文件中直接加载一个之前卸载的数据表）。</li>
<li>ASTCreateQuotaQuery:<br>包括对租户的配额操作语句，例如<code>create quaota</code>，或者<code>alter quota</code>语句</li>
<li>ASTCreateRoleQuery：<br>包括对租户角色操作语句，例如<code>create/alter/drop/set/set default/show create role</code>语句，或者<code>show roles</code></li>
<li>ASTCreateRowPolicyQuery<br>对表的查询做行级别的策略限制，例如<code>create row policy</code> 或者 <code>alter row policy</code></li>
<li>ASTCreateSettingsProfileQuery<br>对角色或者租户的资源限制和约束，例如<code>create settings profile</code> 或者 <code>alter settings profile</code></li>
<li>ASTCreateUserQuery<br>对租户的操作语句，例如<code>create create user</code> 或者 <code>alter create user</code></li>
<li>ASTDropAccessEntityQuery<br>涉及到了clickhouse权限相关的所有删除语句，包括<code>DROP USER</code>,<code>DROP ROLE</code>,<code>DROP QUOTA</code>,<code>DROP [ROW] POLICY</code>,<code>DROP [SETTINGS] PROFILE</code></li>
<li>ASTDropQuery：<br>其中包含了三种不同的删除操作（<code>Drop</code> / <code>Truncate</code> / <code>Detach</code>），<code>Detach Table</code>和<code>Attach Table</code>对应，它是表的卸载动作，把表的存储目录整个移到专门的<code>detach</code>文件夹下，然后关闭表在节点<code>RAM</code>中的”引用”，这张表在节点中不再可见。</li>
<li>ASTGrantQuery:<br>这是授权相关的<code>RBAC</code>，可以对库/表授予或者撤销读/写等权限命令，例如<code>GRANT insert on db.tb to acount</code>，或者<code>REVOKE all on db.tb from account</code>。</li>
<li>ASTKillQueryQuery：<br>可以<code>Kill</code>正在运行的<code>Query</code>，也可以<code>Kill</code>之前发送的<code>Mutation</code>命令。</li>
<li>ASTOptimizeQuery：<br>这是<code>MergeTree</code>表引擎特有的操作命令，它可以手动触发<code>MergeTree</code>表的合并动作，并可以强制数据分区下的所有<code>Data Part</code>合并成一个。</li>
<li>ASTRenameQuery：<br>修改表名，可更改到不同库下。</li>
</ul>
<h3 id="DDL-Query-Task分发"><a href="#DDL-Query-Task分发" class="headerlink" title="DDL Query Task分发"></a>DDL Query Task分发</h3><p><img src="/images/clickhouse/ddloncluster/2.png" alt="cgi"><br><code>ClickHouse</code>内核对每种<code>SQL</code>操作都有对应的<code>IInterpreter</code>实现类，其中的<code>execute</code>方法负责具体的操作逻辑。而以上列举的<code>ASTQuery</code>对应的<code>IInterpreter</code>实现类中的<code>execute</code>方法都加入了分布式<code>DDL</code>执行判断逻辑，把所有分布式<code>DDL</code>执行链路统一都<code>DDLWorker::executeDDLQueryOnCluster</code>方法中。<br><code>executeDDLQueryOnCluster</code>的过程大致可以分为三个步骤：</p>
<h4 id="检查DDLQuery的合法性，"><a href="#检查DDLQuery的合法性，" class="headerlink" title="检查DDLQuery的合法性，"></a>检查<code>DDLQuery</code>的合法性，</h4><ul>
<li>1、校验query规则<br><img src="/images/clickhouse/ddloncluster/3.png" alt="cgi"></li>
<li>2、初始化DDLWorker，取config.xml表的配置<br><img src="/images/clickhouse/ddloncluster/4.png" alt="cgi"></li>
<li>3、替换query里的数据库名称<br><img src="/images/clickhouse/ddloncluster/5.png" alt="cgi"><br>这里替换库名的逻辑是，</li>
<li>3.1、如果query里有带上库名称，则直接使用，若无，则走2</li>
<li>3.2、metrika.xml里配置了shard的默认库<code>&lt;default_database&gt;default&lt;/default_database&gt;</code>，则使用默认库，否则走3</li>
<li>3.3、使用当前session的database<br><img src="/images/clickhouse/ddloncluster/6.png" alt="cgi"></li>
</ul>
<h4 id="把DDLQuery写入到Zookeeper任务队列中"><a href="#把DDLQuery写入到Zookeeper任务队列中" class="headerlink" title="把DDLQuery写入到Zookeeper任务队列中"></a>把<code>DDLQuery</code>写入到<code>Zookeeper</code>任务队列中</h4><ul>
<li>1、构造DDLLogEntry对象，把entry对象加入到queue队列中<br><img src="/images/clickhouse/ddloncluster/7.png" alt="cgi"><br>注意：queue_dir是由<strong>config.xml</strong>配置的，如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;distributed_ddl&gt;</span><br><span class="line">    &lt;path&gt;&#x2F;clickhouse&#x2F;task_queue&#x2F;ddl&lt;&#x2F;path&gt;</span><br><span class="line">&lt;&#x2F;distributed_ddl&gt;</span><br></pre></td></tr></table></figure></li>
<li>2、去zookeeper执行创建znode，把entry序列化存入znode<br><img src="/images/clickhouse/ddloncluster/8.png" alt="cgi"></li>
<li>3、在znode下创建active和finished的znode<br><img src="/images/clickhouse/ddloncluster/9.png" alt="cgi"><blockquote>
<p>下面截图为query-xxx的记录的entry内容<br><img src="/images/clickhouse/ddloncluster/10.png" alt="cgi"></p>
</blockquote>
</li>
</ul>
<h4 id="等待Zookeeper任务队列的反馈把结果返回给用户。"><a href="#等待Zookeeper任务队列的反馈把结果返回给用户。" class="headerlink" title="等待Zookeeper任务队列的反馈把结果返回给用户。"></a>等待<code>Zookeeper</code>任务队列的反馈把结果返回给用户。</h4><p><img src="/images/clickhouse/ddloncluster/11.png" alt="cgi"></p>
<h4 id="DDL-Query-Task执行线程"><a href="#DDL-Query-Task执行线程" class="headerlink" title="DDL Query Task执行线程"></a>DDL Query Task执行线程</h4><ul>
<li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li>
<li>2、执行线程加入到线程池后，执行ddl task<br><img src="/images/clickhouse/ddloncluster/13.png" alt="cgi"></li>
<li>3、过滤掉 query 中带有 on cluster xxx的语句，根据不同的query选择不同执行方式<br><img src="/images/clickhouse/ddloncluster/14.png" alt="cgi"></li>
<li>4、alter、optimize、truncate语句需要在leader节点执行<br><img src="/images/clickhouse/ddloncluster/15.png" alt="cgi"><blockquote>
<p>注意：Replcated表的alter、optimize、truncate这些query是会先判断是否leader节点，不是则不处理，在执行时，会先给zookeeper加一个分布式锁，锁住这个任务防止被修改，执行时都是把自己的host:port注册到znode/query-xxx/active下，执行完成后，结果写到znode/query-xxx/finished下。</p>
</blockquote>
</li>
</ul>
<h4 id="DDL-Query-Task清理线程"><a href="#DDL-Query-Task清理线程" class="headerlink" title="DDL Query Task清理线程"></a>DDL Query Task清理线程</h4><ul>
<li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li>
<li>2、执行清理逻辑，每次执行后，下一次执行需要过1分钟后才可以接着做清理<br><img src="/images/clickhouse/ddloncluster/16.png" alt="cgi"></li>
</ul>
<h3 id="分布式DDL的执行链路总结"><a href="#分布式DDL的执行链路总结" class="headerlink" title="分布式DDL的执行链路总结"></a>分布式DDL的执行链路总结</h3><ul>
<li><p>1）节点收到用户的分布式<code>DDL</code>请求</p>
</li>
<li><p>2）节点校验分布式DDL请求合法性，在<code>Zookeeper</code>的任务队列中创建<code>Znode</code>并上传<strong>DDL LogEntry（query-xxxx）</strong>，同时在<code>LogEntry</code>的<code>Znode</code>下创建<code>active</code>和<code>finish</code>两个状态同步的<code>Znode</code></p>
</li>
<li><p>3）<code>Cluster</code>中的节点后台线程消费<code>Zookeeper</code>中的<code>LogEntry</code>队列执行处理逻辑，处理过程中把自己注册到<code>acitve Znode</code>下，并把处理结果写回到<code>finish Znode</code>下<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></p>
</li>
<li><p>4）用户的原始请求节点，不断轮询<code>LogEntry Znode</code>下的<code>active</code>和<code>finish</code>状态<code>Znode</code>，当目标节点全部执行完成任务或者触发超时逻辑时，用户就会获得结果反馈</p>
</li>
</ul>
<p>这个分发逻辑中有个值得注意的点：分布式<code>DDL</code>执行链路中有超时逻辑，如果触发超时用户将无法从客户端返回中确定最终执行结果，需要自己去<code>Zookeeper</code>上<code>check</code>节点返回结果（也可以通过<strong>system.zookeeper</strong>系统表查看）。<strong>每个节点只有一个后台线程在消费执行DDL任务</strong>，碰到某个DDL任务（典型的是optimize任务）执行时间很长时，会导致DDL任务队列积压从而产生大面积的超时反馈。</p>
<p>可以看出Zookeeper在分布式DDL执行过程中主要充当DDL Task的分发、串行化执行、结果收集的一致性介质。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊cgi的二三事</title>
    <url>/2019/11/07/cgi/</url>
    <content><![CDATA[<h2 id="CGI"><a href="#CGI" class="headerlink" title="CGI"></a>CGI</h2><p><strong>通用网关接口</strong>（Common Gateway Interface/CGI）描述了客户端和服务器程序之间传输数据的一种标准，可以让一个客户端，从网页浏览器向执行在网络服务器上的程序请求数据。CGI 独立于任何语言的，CGI 程序可以用任何脚本语言或者是完全独立编程语言实现，只要这个语言可以在这个系统上运行。</p>
<p><img src="/images/cgi.jpg" alt="cgi"><br>从上面这站图我们可以窥知几个重点的阶段<br>1、web browser 收到 Http request 后，将 request 转给 web server<br>2、web server 启动 CGI 程序，并通过环境变量、标准输入传递数据<br>3、cgi 进程启动解析器、加载配置（如业务相关配置）、连接其它服务器（如数据库服务器）、逻辑处理等<br>4、cgi 程将处理结果通过标准输出、标准错误，传递给 web server<br>5、 web server 收到 cgi 返回的结果，构建 Http Response 返回给客户端，并杀死 cgi 进程</p>
<blockquote>
<p>web erver 与 cgi 通过环境变量、标准输入、标准输出、标准错误互相传递数据这就是 fork and execute 模式，有多少的 http request，就会 fork 出多少的子进程去处理，而每个子进程都需要启动 cgi 解释器、加载配置、链接其他服务器等初始化工作，所以这就是 cgi 性能低下的根本原因，当用户请求非常多的时候，会大量挤占系统的资源如：内存、cpu 时间等。</p>
</blockquote>
<p>以下是一些 get 请求常见的环境变量</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">环境变量</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">REMOTE_ADDR</td>
<td style="text-align:center">client 端的 host 名称。</td>
</tr>
<tr>
<td style="text-align:center">REMOTE_METHOD</td>
<td style="text-align:center">client 端发出请求的方法（如 get、post）。</td>
</tr>
<tr>
<td style="text-align:center">SCRIPT_NAME</td>
<td style="text-align:center">CGI 程式所在的虚拟路径，如/cgi-bin/echo。</td>
</tr>
<tr>
<td style="text-align:center">SERVER_NAME</td>
<td style="text-align:center">server 的 host 名称或 IP 地址。</td>
</tr>
<tr>
<td style="text-align:center">QUERY_STRING</td>
<td style="text-align:center">传递给 CGI 程式的请求参数，也就是用”?”隔开，添加在 URL 后面的字串。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="标准输入"><a href="#标准输入" class="headerlink" title="标准输入"></a>标准输入</h3><p>环境变量的大小是有一定的限制的，当需要传送的数据量大时，储存环境变量的空间可能会不足，造成数据接收不完全，甚至无法执行 CGI 程序。因此后来又发展出另外一种方法：POST，也就是利用 I/O 重新导向的技巧，让 CGI 程序可以由 STDIN 和 STDOUT 直接跟浏览器沟通。<br>当我们指定用这种方法传递请求的数据时，web 服务器收到数据后会先放在一块输入缓冲区中，并且将数据的大小记录在 CONTENT_LENGTH 这个环境变数，然后调用 CGI 程式并将 CGI 程序的 STDIN 指向这块缓冲区，于是我们就可以很顺利的通过 STDIN 和环境变数 CONTENT_LENGTH 得到所有的资料，再没有资料大小的限制了。<br><strong>总结</strong>：CGI 使外部程序与 Web 服务器之间交互成为可能。CGI 程式运行在独立的进程中，并对每个 Web 请求建立一个进程，这种方法非常容易实现，但效率很差，难以扩展。面对大量请求，进程的大量建立和消亡使操作系统性能大大下降。此外，由于地址空间无法共享，也限制了资源重用。</p>
<h2 id="FastCGI"><a href="#FastCGI" class="headerlink" title="FastCGI"></a>FastCGI</h2><p><strong>快速通用网关接口</strong>（Fast Common Gateway Interface／FastCGI）是通用网关接口（CGI）的改进，描述了客户端和服务器程序之间传输数据的一种标准。FastCGI 致力于减少 Web 服务器与 CGI 程式之间互动的开销，从而使服务器可以同时处理更多的 Web 请求。与为每个请求创建一个新的进程不同，FastCGI 使用持续的进程来处理一连串的请求。这些进程由 FastCGI 进程管理器管理，而不是 web 服务器。<br><img src="/images/fastcgi.jpg" alt="fastcgi"><br>1、Web 服务器启动时载入初始化 FastCGI 执行环境 。 例如 IIS ISAPI、apache mod_fastcgi、nginx ngx_http_fastcgi_module、lighttpd mod_fastcgi</p>
<p>2、FastCGI 进程管理器自身初始化，启动多个 CGI 解释器进程并等待来自 Web 服务器的连接。启动 FastCGI 进程时，可以配置以 ip 和 UNIX 域 socket 两种方式启动。</p>
<p>3、当客户端请求到达 Web 服务器时， Web 服务器将请求采用 socket 方式转发到 FastCGI 主进程，FastCGI 主进程选择并连接到一个 CGI 解释器。Web 服务器将 CGI 环境变量和标准输入发送到 FastCGI 子进程。</p>
<p>4、FastCGI 子进程完成处理后将标准输出和错误信息从同一 socket 连接返回 Web 服务器。当 FastCGI 子进程关闭连接时，请求便处理完成。</p>
<p>5、FastCGI 子进程接着等待并处理来自 Web 服务器的下一个连接。</p>
<p>由于 FastCGI 程序并不需要不断的产生新进程，可以大大降低服务器的压力并且产生较高的应用效率。它的速度效率最少要比 CGI 技术提高 5 倍以上。它还支持分布式的部署， 即 FastCGI 程序可以在 web 服务器以外的主机上执行。</p>
<p>总结：CGI 就是所谓的短生存期应用程序，FastCGI 就是所谓的长生存期应用程序。FastCGI 像是一个常驻(long-live)型的 CGI，它可以一直执行着，不会每次都要花费时间去 fork 一次(这是 CGI 最为人诟病的 fork-and-execute 模式)。</p>
<h3 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h3><p>FastCGI 协议分为了 10 种类型，具体定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef enum _fcgi_request_type &#123;</span><br><span class="line">      FCGI_BEGIN_REQUEST   &#x3D;  1, &#x2F;* [in] *&#x2F;</span><br><span class="line">      FCGI_ABORT_REQUEST   &#x3D;  2, &#x2F;* [in]  (not supported) *&#x2F;</span><br><span class="line">      FCGI_END_REQUEST     &#x3D;  3, &#x2F;* [out] *&#x2F;</span><br><span class="line">      FCGI_PARAMS          &#x3D;  4, &#x2F;* [in]  environment variables  *&#x2F;</span><br><span class="line">      FCGI_STDIN           &#x3D;  5, &#x2F;* [in]  post data   *&#x2F;</span><br><span class="line">      FCGI_STDOUT          &#x3D;  6, &#x2F;* [out] response   *&#x2F;</span><br><span class="line">      FCGI_STDERR          &#x3D;  7, &#x2F;* [out] errors     *&#x2F;</span><br><span class="line">      FCGI_DATA    &#x3D;  8, &#x2F;* [in]  filter data (not supported) *&#x2F;</span><br><span class="line">      FCGI_GET_VALUES      &#x3D;  9, &#x2F;* [in]  *&#x2F;</span><br><span class="line">      FCGI_GET_VALUES_RESULT &#x3D; 10  &#x2F;* [out] *&#x2F;</span><br><span class="line">&#125; fcgi_request_type;</span><br></pre></td></tr></table></figure>
<p>整个 FastCGI 是二进制连续传递的，定义了一个统一结构的消息头，用来读取每个消息的消息体，方便消息包的切割。一般情况下，最先发送的是 FCGI_BEGIN_REQUEST 类型的消息，然后是 FCGI_PARAMS 和 FCGI_STDIN 类型的消息，当 FastCGI 响应处理完后，将发送 FCGI_STDOUT 和 FCGI_STDERR 类型的消息，最后以 FCGI_END_REQUEST 表示请求的结束。FCGI_BEGIN_REQUEST 和 FCGI_END_REQUEST 分别表示请求的开始和结束，与整个协议相关。</p>
<h2 id="php-fpm"><a href="#php-fpm" class="headerlink" title="php-fpm"></a>php-fpm</h2><p>PHP-FPM(<strong>FastCGI Process Manager</strong>：FastCGI 进程管理器)是一个 PHPFastCGI 管理器，是 FastCGI 的实现，并提供了进程管理的功能。进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置 pm.max_children = 5)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。<br><img src="/images/fpm.jpg" alt="fastcgi"></p>
<h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><p>Nginx 不只有处理 http 请求的功能，还能做反向代理。Nginx 通过反向代理功能将动态请求转向后端 Php-fpm.<br>下面我们简单解释一下 nginx 的 server 模块是如何配置的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80; #监听80端口，接收http请求</span><br><span class="line">    server_name  www.example.com; #就是网站地址</span><br><span class="line">    root         &#x2F;usr&#x2F;local&#x2F;etc&#x2F;nginx&#x2F;www&#x2F;example; # 准备存放代码工程的路径</span><br><span class="line">    #路由到网站根目录www.example.com时候的处理</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        index index.php; #跳转到www.example.com&#x2F;index.php</span><br><span class="line">    &#125;</span><br><span class="line">    #当请求网站下php文件的时候，反向代理到php-fpm</span><br><span class="line">    location ~ \.php &#123;</span><br><span class="line">        fastcgi_pass        127.0.0.1:9000;#nginx fastcgi进程监听的IP地址和端口</span><br><span class="line">        fastcgi_index       index.php;</span><br><span class="line">        fastcgi_param       SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class="line">        include             fastcgi_params; #加载nginx的fastcgi模块</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>cgi</tag>
        <tag>fastcgi</tag>
      </tags>
  </entry>
  <entry>
    <title>使用clickhouse实现索引</title>
    <url>/2022/02/21/clickhouse-index/</url>
    <content><![CDATA[<h3 id="一级索引"><a href="#一级索引" class="headerlink" title="一级索引"></a>一级索引</h3><h4 id="index-granularity"><a href="#index-granularity" class="headerlink" title="index_granularity"></a>index_granularity</h4><p><img src="/images/clickhouse/crud/5.png" alt="avatar"></p>
<h3 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h3><h4 id="granularity"><a href="#granularity" class="headerlink" title="granularity"></a>granularity</h4>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse的写入流程</title>
    <url>/2022/04/05/clickhouse-insert/</url>
    <content><![CDATA[<h3 id="请求处理"><a href="#请求处理" class="headerlink" title="请求处理"></a>请求处理</h3><p>ck请求处理过程<br><img src="/images/clickhouse/insert/1.png" alt="clickhouse"></p>
<h4 id="客户端请求发给ck，ck接收到请求，放入请求队列"><a href="#客户端请求发给ck，ck接收到请求，放入请求队列" class="headerlink" title="客户端请求发给ck，ck接收到请求，放入请求队列"></a>客户端请求发给ck，ck接收到请求，放入请求队列</h4><h4 id="ck将请求队列的请求分发给Request-handler线程处理"><a href="#ck将请求队列的请求分发给Request-handler线程处理" class="headerlink" title="ck将请求队列的请求分发给Request handler线程处理"></a>ck将请求队列的请求分发给Request handler线程处理</h4><h4 id="Request-handler线程处理请求，解析sql语句，执行sql语句逻辑。"><a href="#Request-handler线程处理请求，解析sql语句，执行sql语句逻辑。" class="headerlink" title="Request handler线程处理请求，解析sql语句，执行sql语句逻辑。"></a>Request handler线程处理请求，解析sql语句，执行sql语句逻辑。</h4><h4 id="简单请求处理使用Request-handler线程直接执行（如create，insert，alter等），-复杂请求处理使用Pipeline-executor执行（如select，-insert-select等）"><a href="#简单请求处理使用Request-handler线程直接执行（如create，insert，alter等），-复杂请求处理使用Pipeline-executor执行（如select，-insert-select等）" class="headerlink" title="简单请求处理使用Request handler线程直接执行（如create，insert，alter等）， 复杂请求处理使用Pipeline executor执行（如select， insert select等）"></a>简单请求处理使用Request handler线程直接执行（如create，insert，alter等）， 复杂请求处理使用Pipeline executor执行（如select， insert select等）</h4><h4 id="请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求"><a href="#请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求" class="headerlink" title="请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求"></a>请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求</h4><h3 id="insert语句解析执行"><a href="#insert语句解析执行" class="headerlink" title="insert语句解析执行"></a>insert语句解析执行</h3><h4 id="初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息"><a href="#初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息" class="headerlink" title="初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息"></a>初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息</h4><h4 id="解析sql语句"><a href="#解析sql语句" class="headerlink" title="解析sql语句"></a>解析sql语句</h4><h4 id="检查被写入的表是否存在，是否有写入权限，是否被限流"><a href="#检查被写入的表是否存在，是否有写入权限，是否被限流" class="headerlink" title="检查被写入的表是否存在，是否有写入权限，是否被限流"></a>检查被写入的表是否存在，是否有写入权限，是否被限流</h4><h4 id="对insert数据校验，字段是否存在，是否满足约束"><a href="#对insert数据校验，字段是否存在，是否满足约束" class="headerlink" title="对insert数据校验，字段是否存在，是否满足约束"></a>对insert数据校验，字段是否存在，是否满足约束</h4><h4 id="根据默认值填充空字段和物化字段"><a href="#根据默认值填充空字段和物化字段" class="headerlink" title="根据默认值填充空字段和物化字段"></a>根据默认值填充空字段和物化字段</h4><h4 id="缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。"><a href="#缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。" class="headerlink" title="缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。"></a>缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。</h4><h4 id="将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree"><a href="#将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree" class="headerlink" title="将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree"></a>将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree</h4><h4 id="检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表"><a href="#检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表" class="headerlink" title="检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表"></a>检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表</h4><h3 id="分布式表写入"><a href="#分布式表写入" class="headerlink" title="分布式表写入"></a>分布式表写入</h3><blockquote>
<p>分布式表数据写入一般情况下是异步写入，只有对使用 remote(‘addresses_expr’, db, table[, ‘user’[, ‘password’], sharding_key]) 定义的表的写入是同步的。如果分布式表中含有local表或replical的表local副本，直接写本地表。<br><img src="/images/clickhouse/insert/2.png" alt="clickhouse"></p>
</blockquote>
<h4 id="将写入block数据按sharding逻辑分成多个block"><a href="#将写入block数据按sharding逻辑分成多个block" class="headerlink" title="将写入block数据按sharding逻辑分成多个block"></a>将写入block数据按sharding逻辑分成多个block</h4><h4 id="将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据"><a href="#将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据" class="headerlink" title="将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据"></a>将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据</h4><h4 id="检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎"><a href="#检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎" class="headerlink" title="检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎"></a>检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎</h4><h4 id="shard在远程，将新insert语句写入远程shard本地缓存文件。"><a href="#shard在远程，将新insert语句写入远程shard本地缓存文件。" class="headerlink" title="shard在远程，将新insert语句写入远程shard本地缓存文件。"></a>shard在远程，将新insert语句写入远程shard本地缓存文件。</h4><h4 id="通知后台线程发送本地缓存中的数据"><a href="#通知后台线程发送本地缓存中的数据" class="headerlink" title="通知后台线程发送本地缓存中的数据"></a>通知后台线程发送本地缓存中的数据</h4><h4 id="后台执行过程"><a href="#后台执行过程" class="headerlink" title="后台执行过程"></a>后台执行过程</h4><h4 id="读远程shard本地缓存目录"><a href="#读远程shard本地缓存目录" class="headerlink" title="读远程shard本地缓存目录"></a>读远程shard本地缓存目录</h4><h4 id="逐个处理每个文件"><a href="#逐个处理每个文件" class="headerlink" title="逐个处理每个文件"></a>逐个处理每个文件</h4><h4 id="根据配置的loadbalance策略，选择合适的机器连接"><a href="#根据配置的loadbalance策略，选择合适的机器连接" class="headerlink" title="根据配置的loadbalance策略，选择合适的机器连接"></a>根据配置的loadbalance策略，选择合适的机器连接</h4><h4 id="将文件的insert语句通过上步连接发送给远程机器执行"><a href="#将文件的insert语句通过上步连接发送给远程机器执行" class="headerlink" title="将文件的insert语句通过上步连接发送给远程机器执行"></a>将文件的insert语句通过上步连接发送给远程机器执行</h4><h4 id="执行成功后删除对应文件"><a href="#执行成功后删除对应文件" class="headerlink" title="执行成功后删除对应文件"></a>执行成功后删除对应文件</h4><h3 id="本地表写入"><a href="#本地表写入" class="headerlink" title="本地表写入"></a>本地表写入</h3><blockquote>
<p>本地表一般是StorageReplicatedXXMergeTree，其写入过程如下：<br><img src="/images/clickhouse/insert/3.png" alt="clickhouse"><br>本地表是以block为最小单元单次写入，一个block中的数据可能是一次insert的全部数据，也可以是部分数据。</p>
</blockquote>
<h4 id="检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。"><a href="#检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。" class="headerlink" title="检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。"></a>检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。</h4><h4 id="检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。"><a href="#检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。" class="headerlink" title="检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。"></a>检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。</h4><h4 id="将写入block数据按partition-by-逻辑分成多个block"><a href="#将写入block数据按partition-by-逻辑分成多个block" class="headerlink" title="将写入block数据按partition by 逻辑分成多个block"></a>将写入block数据按partition by 逻辑分成多个block</h4><h4 id="依次将每个分区的block数据写入表中"><a href="#依次将每个分区的block数据写入表中" class="headerlink" title="依次将每个分区的block数据写入表中"></a>依次将每个分区的block数据写入表中</h4><h4 id="创建分区的临时part"><a href="#创建分区的临时part" class="headerlink" title="创建分区的临时part"></a>创建分区的临时part</h4><h4 id="计算part数据的sha1生成part对应的blockid"><a href="#计算part数据的sha1生成part对应的blockid" class="headerlink" title="计算part数据的sha1生成part对应的blockid"></a>计算part数据的sha1生成part对应的blockid</h4><h4 id="检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。"><a href="#检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。" class="headerlink" title="检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。"></a>检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。</h4><h4 id="将part信息发布到ck，通知其他副本拉去新添加part"><a href="#将part信息发布到ck，通知其他副本拉去新添加part" class="headerlink" title="将part信息发布到ck，通知其他副本拉去新添加part"></a>将part信息发布到ck，通知其他副本拉去新添加part</h4><h4 id="将临时part加入到commit到mergetree表"><a href="#将临时part加入到commit到mergetree表" class="headerlink" title="将临时part加入到commit到mergetree表"></a>将临时part加入到commit到mergetree表</h4><h4 id="如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件"><a href="#如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件" class="headerlink" title="如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件"></a>如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件</h4><h4 id="临时part创建过程"><a href="#临时part创建过程" class="headerlink" title="临时part创建过程"></a>临时part创建过程</h4><ul>
<li>创建block数据对应分区的临时part对象</li>
<li>计算分区min_max索引</li>
<li>处理排序和主键索引</li>
<li>ttl处理</li>
<li>其他二级索引处理</li>
<li>将处理过的block数据和索引写入临时part，根据配置的压缩方式压缩</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>2022年终总结</title>
    <url>/2022/12/30/2022/</url>
    <content><![CDATA[<ul>
<li><p>2022年仓皇而逃，在恍惚间我仍然有一丝怀疑，此时此刻是2019年的冬天，我们在准备着即将到来到2020年，订好了机票，订好了酒店，在跨年夜的云层之上，陌生人在沉睡，而我即将见到相隔数月思念日日夜夜的人儿。</p>
</li>
<li><p>这种怀疑在这3年间时不时的击碎我，重建我，沉溺我，到最后清醒我，时间过得太快了啊，快到迅雷烈风，快到掩耳而逝，我不是还在17/8岁的高中课堂上汗流浃背准备高考吗？怎么这一眨眼之间，我竟已是前额白发丝丝黑眼圈蜡黄脸的中年人了呢？</p>
</li>
<li><p>人世间的痛不知道何时能结束，人世间的离愁不知道何时能消散，虚度30余载光阴，到如今即将到来的第二个本命年，我有何成就吗？我有实现过理想吗？我活着的这些时刻，有给这个世界带来什么美好吗？我不自知只觉惭愧。</p>
</li>
<li><p>麻木的躯壳麻木的灵魂，肤浅的知识肤浅的见识，2022年在核酸、隔离、阳性中结束，这浅浅6个字结束了我的又一个365天，我是谁？我在2022年都做了什么事？有什么可以拿说来细说一二吗？有什么不足和遗憾吗？希望2023年可以改变吗？希望改变什么呢？</p>
</li>
<li><p>没有答案，我甚至连流水账都写不出来，哦，我这个可笑的中年人。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>blank</category>
      </categories>
      <tags>
        <tag>流水记</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse分布式表写入积压排查</title>
    <url>/2022/01/12/clickhouse-distribute-insert-problem/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><ul>
<li>首先解释下为什么要写入分布式表，而不是<code>MergeTree</code>表<br><a href="https://clickhouse.com/docs/en/engines/table-engines/special/distributed/" target="_blank" rel="noopener">分布式表链接</a>，分布式表引擎不会存储任务数据，但是允许分布式查询可以路由到多台机器，读取都是并行的，每一个读操作，如果有配置的话，远程机器上的表索引都会被使用到，所以我们知道分布式表是不存储数据的，只是数据的搬运工而已，我们正常做法应该是直接写入数据到<code>MergeTree</code>引擎表，然后通过分布式做路由分发查询而已。那么问题来了，什么场景要写入到分布式表呢？<br>因为分布式表建表语句支持指定分片索引<code>sharding_key</code>，这个<code>sharding_key</code>可以把通过分布式表写入的数据转发到同一个<code>shard</code>，那么在同一个shard里的数据才能满足<strong>排序主键和去重</strong>。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]</span><br><span class="line">(</span><br><span class="line">    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],</span><br><span class="line">    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],</span><br><span class="line">    ...</span><br><span class="line">) ENGINE &#x3D; Distributed(cluster, database, table[, sharding_key[, policy_name]])</span><br><span class="line">[SETTINGS name&#x3D;value, ...]</span><br></pre></td></tr></table></figure></li>
<li>可以使用<code>xxHash32</code>函数来对要去重的字段进行哈希计算后路由到同一个分片上<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ENGINE &#x3D; Distributed(&#39;cluster&#39;, &#39;database&#39;, &#39;table_local&#39;, xxHash32(logid))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="system-metrics"><a href="#system-metrics" class="headerlink" title="system.metrics"></a>system.metrics</h3><ul>
<li><p>介绍</p>
<blockquote>
<p><a href="https://clickhouse.com/docs/en/operations/system-tables/metrics/" target="_blank" rel="noopener">地址</a>,该表包含了被直接算计的指标，或者当前值，举例就是同时查询的进程数，或者当前副本延迟时间，这个表一直被实时更新。<br>该表包含3个元素，如下</p>
<ul>
<li>metric (String) — 指标名.</li>
<li>value (Int64) — 指标值.</li>
<li>description (String) — 指标描述.</li>
</ul>
</blockquote>
</li>
<li><p>找出当前每个节点分布式文件写入的总数，找出最高的那个节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from system.metrics where metric &#x3D; &#39;DistributedFilesToInsert&#39;</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/1.png" alt="clickhouse"></p>
</li>
</ul>
<h3 id="system-distribution-queue"><a href="#system-distribution-queue" class="headerlink" title="system.distribution_queue"></a>system.distribution_queue</h3><ul>
<li>介绍<blockquote>
<p><a href="https://clickhouse.com/docs/en/operations/system-tables/distribution_queue/" target="_blank" rel="noopener">地址</a>，该表包含了关于本地文件等待传递到shard的队列信息，这些本地文件包含的用异步方式通过写入分布式表创建的新part文件。  </p>
</blockquote>
</li>
</ul>
<p>该表包含字段如下：</p>
<ul>
<li><p>database (String) — 数据库名称.</p>
</li>
<li><p>table (String) — 表名称.</p>
</li>
<li><p>data_path (String) — 本地文件的路径.</p>
</li>
<li><p>is_blocked (UInt8) — 标示位，是否传递文件到服务器被锁住.</p>
</li>
<li><p>error_count (UInt64) — 错误数.</p>
</li>
<li><p>data_files (UInt64) — 一个目录下文件个数.</p>
</li>
<li><p>data_compressed_bytes (UInt64) — 单位字节，被压缩的数据大小.</p>
</li>
<li><p>broken_data_files (UInt64) — 由于错误而标示损坏的文件数.</p>
</li>
<li><p>broken_data_compressed_bytes (UInt64) — 单位字节，所损文件的压缩字节大小.</p>
</li>
<li><p>last_exception (String) — 上次发生错误的内容.</p>
</li>
</ul>
<ul>
<li>去最高的那个节点查找正在写入的队列<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from system.distribution_queue where data_files &gt; 0</span><br></pre></td></tr></table></figure>
<img src="/images/clickhouse/distribute/2.png" alt="clickhouse"><blockquote>
<p>通过<code>data_files</code>可以看到当前在等待写入的文件数，通过<code>data_compressed_bytes</code>可以看到当前等待写入的总文件大小，通过<code>error_count</code>可以看到错误次数，通过<code>last_exception</code>可以看到上次发生错误的内容</p>
</blockquote>
</li>
</ul>
<h3 id="若是clickhosue19版本，则使用以下命令查询"><a href="#若是clickhosue19版本，则使用以下命令查询" class="headerlink" title="若是clickhosue19版本，则使用以下命令查询"></a>若是clickhosue19版本，则使用以下命令查询</h3><ul>
<li>查出分布式表存储的路径配置<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd config.d</span><br><span class="line">cat storage.xml</span><br><span class="line">&lt;path&gt;&#x2F;data1&#x2F;default&#x2F;clickhouse-data&lt;&#x2F;path&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果不是这样的配置，直接查询 <code>storage_configuration</code>的配置</p>
</blockquote>
</li>
<li><p>进入分布式表的存储目录，计算出每个库表的总文件数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data1&#x2F;default&#x2F;clickhouse-data&#x2F;data</span><br><span class="line"># find -type f 表示查找出所有类型是文件的格式</span><br><span class="line"># awk -F &#39;,&#39; &#39;&#123;print $1&#125;&#39; 表示按照,切割后取第一个</span><br><span class="line"># uniq -c 表示聚合后去重</span><br><span class="line"># sort -h -r 表示逆序排序</span><br><span class="line"># awk -F &#39;&#x2F;default&#39; &#39;&#123;print $1&#125;&#39; 表示按&#x2F;default切割后取第一条</span><br><span class="line">find -type f | awk -F &#39;,&#39; &#39;&#123;print $1&#125;&#39; |  uniq -c | sort -h -r | awk -F &#39;&#x2F;default&#39; &#39;&#123;print $1&#125;&#39;</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/3.png" alt="clickhouse"></p>
<blockquote>
<p>文件数目最多的就是写入积压的</p>
</blockquote>
</li>
<li><p>根据flush命令获取到写入错误的原因</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SYSTEM FLUSH DISTRIBUTED db.tb</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/4.png" alt="clickhouse"></p>
<blockquote>
<p>根据错误能直接解决就直接去解决，无法解决的话看下面</p>
<h3 id="解决分布式表写入积压"><a href="#解决分布式表写入积压" class="headerlink" title="解决分布式表写入积压"></a>解决分布式表写入积压</h3></blockquote>
</li>
<li>删除分布式表<blockquote>
<p>则意味着这个分布式表的所有写入任务都会自动清理，谨慎操作，别把底表删了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop table if exists db.tb</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li>清空分布式表数据<blockquote>
<p>这个方式只是清除掉积压的数据，不用删表，用户通过分布式表来查询时不会报表不存在，但是如果数据量非常大就不要用truncate方式了，因为会导致整个表被锁非常久，应该用<code>alter table xx drop partititon xx</code>方式，一个一个分区删。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">truncate table db.tb</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse报错Metadata on replica的解决方法</title>
    <url>/2022/01/13/clickhouse-mutation-problem/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ClickHouse exception, code: 517, host: xx.xx.xx.xx, port: xxxx; Code: 517, e.displayText() &#x3D; DB::Exception: Metadata on replica is not up to date with common metadata in Zookeeper. Cannot alter: Bad version</span><br></pre></td></tr></table></figure>
<p>我们在修改表结构（例如<code>alter table drop column xxx</code>）时经常会遇到以上报错，原因副本上的元数据和在zookeeper上的元数据不一致，无法更新，因为版本号不一样。</p>
<h3 id="查找system-replication-queue"><a href="#查找system-replication-queue" class="headerlink" title="查找system.replication_queue"></a>查找system.replication_queue</h3><ul>
<li>表介绍<br><a href="https://clickhouse.com/docs/en/operations/system-tables/replication_queue/" target="_blank" rel="noopener">链接地址</a>包含了所有<code>ReplicatedMergeTree</code>复制表家族在<code>zookeeper</code>上存储的副本任务队列的相关信息。</li>
<li><p>列信息</p>
<ul>
<li>database (String) — 数据库名称.</li>
<li>table (String) — 表名称.</li>
<li>replica_name (String) — zookeeper上副本名称，同表不同副本有不同名字.</li>
<li>position (UInt32) — 当前任务队列的位置.</li>
<li>node_name (String) — ZooKeeper上节点名称.</li>
<li>type (String) — 任务队列的名称，分别是:<ul>
<li>GET_PART — 从另一个副本拿到part.</li>
<li>ATTACH_PART — 加载part, 有可能来自我们自己的副本 (如果是在detached目录上发现). 您可以认为它是带有一些优化的GET_PART，因为他们接近相似.</li>
<li>MERGE_PARTS — 合并part.</li>
<li>DROP_RANGE — 删除指定范围内的指定分区列表.</li>
<li>CLEAR_COLUMN — 注意：从指定分区删除特殊列（已弃用）.</li>
<li>CLEAR_INDEX — 注意：从指定分区删除指定索引（已弃用）.</li>
<li>REPLACE_RANGE — 删除一定范围内的part，并用新part替换.</li>
<li>MUTATE_PART — 对part应用用一个或多个mutation.</li>
<li>ALTER_METADATA — 根据/metadata和/columns路径应用alter修改.</li>
</ul>
</li>
<li>create_time (Datetime) — 任务被提交执行后的时间.</li>
<li>required_quorum (UInt32) — 等待任务完成并且确认完成的副本数. 这个字段仅跟GET_PARTS任务相关.</li>
<li>source_replica (String) — 源副本的名称.</li>
<li>new_part_name (String) — 新part的名称.</li>
<li>parts_to_merge (Array (String)) — 要更新或者合并的part名称.</li>
<li>is_detach (UInt8) — DETACH_PARTS任务是否在任务队列里的标示位.</li>
<li>is_currently_executing (UInt8) — 当然任务是否正在执行的标示位.</li>
<li>num_tries (UInt32) — 尝试完成任务失败的次数.</li>
<li>last_exception (String) — 上次错误发生的详情.</li>
<li>last_attempt_time (Datetime) — 任务最后一次尝试的时间</li>
<li>num_postponed (UInt32) — 延期任务数.</li>
<li>postpone_reason (String) — 任务延期时间.</li>
<li>last_postpone_time (Datetime) — 任务上次延期的时间.</li>
<li>merge_type (String) — 当前合并的类型. 如果是mutation则为空.</li>
</ul>
</li>
<li><p>通过该表捞出zookeeper的节点副本信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select node_name from system.replication_queue where database &#x3D; &#39;xx&#39; and table &#x3D; &#39;xx&#39; and is_currently_executing &#x3D; 1</span><br></pre></td></tr></table></figure>
<h3 id="system-replcas"><a href="#system-replcas" class="headerlink" title="system.replcas"></a>system.replcas</h3></li>
</ul>
<h3 id="system-mutations"><a href="#system-mutations" class="headerlink" title="system.mutations"></a>system.mutations</h3><h3 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h3><p>+ </p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>mac下编译clickhouse</title>
    <url>/2021/10/01/clickhouse-mac-compile/</url>
    <content><![CDATA[<h3 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h3><blockquote>
<p>Homebrew要安装正确, 确保/usr/local下面出现各种share/include等目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="安装环境所需插件"><a href="#安装环境所需插件" class="headerlink" title="安装环境所需插件"></a>安装环境所需插件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install cmake ninja libtool gettext ccache</span><br></pre></td></tr></table></figure>
<h3 id="修正objcopy的问题"><a href="#修正objcopy的问题" class="headerlink" title="修正objcopy的问题"></a>修正objcopy的问题</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install binutils</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;opt&#x2F;binutils&#x2F;bin&#x2F;objcopy &#x2F;usr&#x2F;local&#x2F;bin&#x2F;objcopy</span><br></pre></td></tr></table></figure>
<h3 id="clion打开clickouse-local不成功，无法正常编译debug"><a href="#clion打开clickouse-local不成功，无法正常编译debug" class="headerlink" title="clion打开clickouse local不成功，无法正常编译debug"></a>clion打开clickouse local不成功，无法正常编译debug</h3><p>1&gt; 安装llvm<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install llvm</span><br></pre></td></tr></table></figure><br>2&gt; 配置clion的工具链ToolChain<br><img src="/images/clickhouse/1.png" alt="avatar"><br>cmake和make是新版本就可以了，配置好c和c++编译器(compiler)使用刚装好的llvm下的clang</p>
</blockquote>
<h3 id="安装googletest"><a href="#安装googletest" class="headerlink" title="安装googletest"></a>安装googletest</h3><p>有报错ld: library not found for -lgtest<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install googletest</span><br></pre></td></tr></table></figure><br><img src="/images/clickhouse/8.png" alt="avatar"></p>
<h3 id="使用支持ninja的CLion版本-可选-最新版是支持的"><a href="#使用支持ninja的CLion版本-可选-最新版是支持的" class="headerlink" title="使用支持ninja的CLion版本(可选, 最新版是支持的)"></a>使用支持ninja的CLion版本(可选, 最新版是支持的)</h3><blockquote>
<p>CLion中的CMake使用选项<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-DCMAKE_CXX_COMPILER_LAUNCHER&#x3D;ccache</span><br><span class="line">-DCMAKE_BUILD_TYPE&#x3D;Debug</span><br><span class="line">-GNinja</span><br><span class="line">-DENABLE_CLICKHOUSE_ALL&#x3D;OFF</span><br><span class="line">-DENABLE_CLICKHOUSE_SERVER&#x3D;ON</span><br><span class="line">-DENABLE_CLICKHOUSE_CLIENT&#x3D;ON</span><br><span class="line">-DUSE_STATIC_LIBRARIES&#x3D;OFF</span><br><span class="line">-DCLICKHOUSE_SPLIT_BINARY&#x3D;ON</span><br><span class="line">-DSPLIT_SHARED_LIBRARIES&#x3D;ON</span><br><span class="line">-DENABLE_LIBRARIES&#x3D;OFF</span><br><span class="line">-DENABLE_UTILS&#x3D;OFF</span><br><span class="line">-DENABLE_TESTS&#x3D;OFF</span><br><span class="line">-DUSE_ROCKSDB&#x3D;ON</span><br><span class="line">-DENABLE_ROCKSDB&#x3D;ON</span><br><span class="line">-DUSE_INTERNAL_ROCKSDB_LIBRARY&#x3D;ON</span><br><span class="line">-DENABLE_PROTOBUF&#x3D;ON</span><br><span class="line">-DENABLE_GRPC&#x3D;ON</span><br></pre></td></tr></table></figure><br><img src="/images/clickhouse/2.png" alt="avatar"></p>
</blockquote>
<h3 id="点Tools-gt-CMake→Reset-Cache-and-Reload-Project"><a href="#点Tools-gt-CMake→Reset-Cache-and-Reload-Project" class="headerlink" title="点Tools-&gt;CMake→Reset Cache and Reload Project"></a>点Tools-&gt;CMake→Reset Cache and Reload Project</h3><p><img src="/images/clickhouse/3.png" alt="avatar"></p>
<blockquote>
<p>load过程可能会遇到的错误<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CMake Error at contrib&#x2F;croaring-cmake&#x2F;CMakeLists.txt:22 (add_library):Cannot find source file:…</span><br></pre></td></tr></table></figure><br>执行git submodule update —init —recursive 重新拉取相关依赖</p>
</blockquote>
<h3 id="编译clickhouse-server"><a href="#编译clickhouse-server" class="headerlink" title="编译clickhouse-server"></a>编译clickhouse-server</h3><p>1&gt; 点右上角锤子进行编译<br><img src="/images/clickhouse/4.png" alt="avatar"><br>2&gt; 查看编译进度<br><img src="/images/clickhouse/5.png" alt="avatar"></p>
<h3 id="debug方式运行"><a href="#debug方式运行" class="headerlink" title="debug方式运行"></a>debug方式运行</h3><ul>
<li><ol>
<li>debug时需要指定配置文件config.xml路径<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--config-file&#x3D;&#x2F;Users&#x2F;blanklin&#x2F;Code&#x2F;cpp&#x2F;clickhouse-debug&#x2F;conf&#x2F;config.xml</span><br></pre></td></tr></table></figure>
<img src="/images/clickhouse/7.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>点右侧的蜘蛛按钮进行debug<br><img src="/images/clickhouse/6.png" alt="avatar"></li>
</ol>
</li>
</ul>
<h3 id="cpp快速入门"><a href="#cpp快速入门" class="headerlink" title="cpp快速入门"></a>cpp快速入门</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; main() 是程序开始执行的地方</span><br><span class="line"> </span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">   cout &lt;&lt; &quot;Hello World&quot;; &#x2F;&#x2F; 输出 Hello World</span><br><span class="line">   return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来我们讲解一下上面这段程序：</p>
<ul>
<li>C++ 语言定义了一些头文件，这些头文件包含了程序中必需的或有用的信息。上面这段程序中，包含了头文件 <iostream>。</li>
<li>using namespace std; 告诉编译器使用 std 命名空间。命名空间是 C++ 中一个相对新的概念。</li>
<li>// main() 是程序开始执行的地方 是一个单行注释。单行注释以 // 开头，在行末结束。</li>
<li>int main() 是主函数，程序从这里开始执行。</li>
<li>cout &lt;&lt; “Hello World”; 会在屏幕上显示消息 “Hello World”。</li>
<li>return 0; 终止 main( )函数，并向调用进程返回值 0。</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse物化视图在滴滴的实践</title>
    <url>/2022/04/01/clickhouse-materialized-view/</url>
    <content><![CDATA[<h3 id="什么是物化视图"><a href="#什么是物化视图" class="headerlink" title="什么是物化视图"></a>什么是物化视图</h3><ul>
<li>普通视图（View）是从一张或者多张数据库表查询导出的虚拟表，可以反映出基础表之间的数据变化，但是本身是不存储数据的，每次的查询都会从基础表重新聚合出查询结果，所以普通视图查询其实等同于创建视图时的查询语句的查询效率。</li>
<li>物化视图（Materialized View）是查询结果集的一份持久化存储，也称为底表的快照（snapshot），查询结果集的范围很宽泛，可以是基础表中部分数据的一份简单拷贝，也可以是多表join之后产生的结果或其子集，或者原始数据的聚合指标等等。物化视图不会随着基础表的变化而变化，如果要更新数据的话，需要用户手动进行，如周期性执行SQL，或利用触发器等机制。</li>
</ul>
<p><img src="/images/clickhouse/crud/5.png" alt="avatar"></p>
<h3 id="如何创建物化视图"><a href="#如何创建物化视图" class="headerlink" title="如何创建物化视图"></a>如何创建物化视图</h3><blockquote>
<h4 id="MergeTree排序引擎"><a href="#MergeTree排序引擎" class="headerlink" title="MergeTree排序引擎"></a>MergeTree排序引擎</h4></blockquote>
<h4 id="ReplacingMergeTree去重引擎"><a href="#ReplacingMergeTree去重引擎" class="headerlink" title="ReplacingMergeTree去重引擎"></a>ReplacingMergeTree去重引擎</h4><h4 id="AggregatingMergeTree聚合引擎"><a href="#AggregatingMergeTree聚合引擎" class="headerlink" title="AggregatingMergeTree聚合引擎"></a>AggregatingMergeTree聚合引擎</h4><h4 id="UniqueMergeTree-实时去重引擎"><a href="#UniqueMergeTree-实时去重引擎" class="headerlink" title="UniqueMergeTree 实时去重引擎"></a>UniqueMergeTree 实时去重引擎</h4><h4 id="SummingMergeTree-求和引擎"><a href="#SummingMergeTree-求和引擎" class="headerlink" title="SummingMergeTree 求和引擎"></a>SummingMergeTree 求和引擎</h4><h4 id="CollapsingMergeTree-折叠引擎"><a href="#CollapsingMergeTree-折叠引擎" class="headerlink" title="CollapsingMergeTree 折叠引擎"></a>CollapsingMergeTree 折叠引擎</h4><h4 id="VersionedCollapsingMergeTree-版本折叠引擎"><a href="#VersionedCollapsingMergeTree-版本折叠引擎" class="headerlink" title="VersionedCollapsingMergeTree 版本折叠引擎"></a>VersionedCollapsingMergeTree 版本折叠引擎</h4><h3 id="如何写入物化视图"><a href="#如何写入物化视图" class="headerlink" title="如何写入物化视图"></a>如何写入物化视图</h3><h4 id="底表触发"><a href="#底表触发" class="headerlink" title="底表触发"></a>底表触发</h4><h4 id="同步任务触发"><a href="#同步任务触发" class="headerlink" title="同步任务触发"></a>同步任务触发</h4><h4 id="直接写入到分布式表"><a href="#直接写入到分布式表" class="headerlink" title="直接写入到分布式表"></a>直接写入到分布式表</h4><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3>]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse Read Timed Out追踪过程</title>
    <url>/2021/12/21/clickhouse-read-timed-out/</url>
    <content><![CDATA[<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>最近经常遇到<code>Read timed out</code>报错，具体内容看下面，从字面意思判断我们知道是读超时，那为什么会发生读超时呢？<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 159, host: bigdata-clickhouse-xxxx.ys, port: 8023; Read timed out	at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.getException(ClickHouseExceptionSpecifier.java:86)	at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:56)	at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:25)	at ru.yandex.clickhouse.ClickHouseStatementImpl.getInputStream(ClickHouseStatementImpl.java:797)	at ru.yandex.clickhouse.ClickHouseStatementImpl.getLastInputStream(ClickHouseStatementImpl.java:691)	at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:340)	at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:324)	at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:319)	at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:314)	at</span><br></pre></td></tr></table></figure></p>
<h3 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h3><ul>
<li>从抛出的堆栈入手，先读<code>ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier</code>类<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> &#x2F;**</span><br><span class="line">  * Here we expect the ClickHouse error message to be of the following format:</span><br><span class="line">  * &quot;Code: 10, e.displayText() &#x3D; DB::Exception: ...&quot;.</span><br><span class="line">  *&#x2F;</span><br><span class="line">private static ClickHouseException specify(String clickHouseMessage, Throwable cause, String host, int port) &#123;</span><br><span class="line">    if (Utils.isNullOrEmptyString(clickHouseMessage) &amp;&amp; cause !&#x3D; null) &#123;</span><br><span class="line">        return getException(cause, host, port);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        int code;</span><br><span class="line">        if (clickHouseMessage.startsWith(&quot;Poco::Exception. Code: 1000, &quot;)) &#123;</span><br><span class="line">            code &#x3D; 1000;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            &#x2F;&#x2F; Code: 175, e.displayText() &#x3D; DB::Exception:</span><br><span class="line">            code &#x3D; getErrorCode(clickHouseMessage);</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; ошибку в изначальном виде все-таки укажем</span><br><span class="line">        Throwable messageHolder &#x3D; cause !&#x3D; null ? cause : new Throwable(clickHouseMessage);</span><br><span class="line">        if (code &#x3D;&#x3D; -1) &#123;</span><br><span class="line">            return getException(messageHolder, host, port);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return new ClickHouseException(code, messageHolder, host, port);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        log.error(&quot;Unsupported ClickHouse error format, please fix ClickHouseExceptionSpecifier, message: &#123;&#125;, error: &#123;&#125;&quot;, clickHouseMessage, e.getMessage());</span><br><span class="line">        return new ClickHouseUnknownException(clickHouseMessage, cause, host, port);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">private static ClickHouseException getException(Throwable cause, String host, int port) &#123;</span><br><span class="line">        if (cause instanceof SocketTimeoutException)</span><br><span class="line">        &#x2F;&#x2F; if we&#39;ve got SocketTimeoutException, we&#39;ll say that the query is not good. This is not the same as SOCKET_TIMEOUT of clickhouse</span><br><span class="line">        &#x2F;&#x2F; but it actually could be a failing ClickHouse</span><br><span class="line">        &#123;</span><br><span class="line">            return new ClickHouseException(ClickHouseErrorCode.TIMEOUT_EXCEEDED.code, cause, host, port);</span><br><span class="line">        &#125; else if (cause instanceof ConnectTimeoutException || cause instanceof ConnectException)</span><br><span class="line">        &#x2F;&#x2F; couldn&#39;t connect to ClickHouse during connectTimeout</span><br><span class="line">        &#123;</span><br><span class="line">            return new ClickHouseException(ClickHouseErrorCode.NETWORK_ERROR.code, cause, host, port);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return new ClickHouseUnknownException(cause, host, port);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
注意到上文中异常类型是<code>SocketTimeoutException</code>，为啥会是这个异常呢？</li>
<li>继续阅读<code>ru.yandex.clickhouse.ClickHouseStatementImpl</code>类<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private InputStream getInputStream(</span><br><span class="line">  ClickHouseSqlStatement parsedStmt,</span><br><span class="line">  Map&lt;ClickHouseQueryParam, String&gt; additionalClickHouseDBParams,</span><br><span class="line">  List&lt;ClickHouseExternalData&gt; externalData,</span><br><span class="line">  Map&lt;String, String&gt; additionalRequestParams</span><br><span class="line">) throws ClickHouseException &#123;</span><br><span class="line">  .............................</span><br><span class="line">  HttpEntity entity &#x3D; null;</span><br><span class="line">  try &#123;</span><br><span class="line">      uri &#x3D; followRedirects(uri);</span><br><span class="line">      HttpPost post &#x3D; new HttpPost(uri);</span><br><span class="line">      post.setEntity(requestEntity);</span><br><span class="line"></span><br><span class="line">      if (parsedStmt.isIdemponent()) &#123;</span><br><span class="line">          httpContext.setAttribute(&quot;is_idempotent&quot;, Boolean.TRUE);</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">          httpContext.removeAttribute(&quot;is_idempotent&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      HttpResponse response &#x3D; client.execute(post, httpContext);</span><br><span class="line">      entity &#x3D; response.getEntity();</span><br><span class="line">      checkForErrorAndThrow(entity, response);</span><br><span class="line"></span><br><span class="line">      InputStream is;</span><br><span class="line">      if (entity.isStreaming()) &#123;</span><br><span class="line">          is &#x3D; entity.getContent();</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">          FastByteArrayOutputStream baos &#x3D; new FastByteArrayOutputStream();</span><br><span class="line">          entity.writeTo(baos);</span><br><span class="line">          is &#x3D; baos.convertToInputStream();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      &#x2F;&#x2F; retrieve response summary</span><br><span class="line">      if (isQueryParamSet(ClickHouseQueryParam.SEND_PROGRESS_IN_HTTP_HEADERS, additionalClickHouseDBParams, additionalRequestParams)) &#123;</span><br><span class="line">          Header summaryHeader &#x3D; response.getFirstHeader(&quot;X-ClickHouse-Summary&quot;);</span><br><span class="line">          currentSummary &#x3D; summaryHeader !&#x3D; null ? Jackson.getObjectMapper().readValue(summaryHeader.getValue(), ClickHouseResponseSummary.class) : null;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      return is;</span><br><span class="line">  &#125; catch (ClickHouseException e) &#123;</span><br><span class="line">      throw e;</span><br><span class="line">  &#125; catch (Exception e) &#123;</span><br><span class="line">      log.info(&quot;Error during connection to &#123;&#125;, reporting failure to data source, message: &#123;&#125;&quot;, properties, e.getMessage());</span><br><span class="line">      EntityUtils.consumeQuietly(entity);</span><br><span class="line">      log.info(&quot;Error sql: &#123;&#125;&quot;, sql);</span><br><span class="line">      throw ClickHouseExceptionSpecifier.specify(e, properties.getHost(), properties.getPort());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
注意到这是建立一个<code>http</code>连接，使用<code>post</code>方式，等到数据传输完成，返回执行结果，如果有任何<code>ClickHouseException</code>则直接抛掉，否则捕获未知异常<code>Exception</code>，格式化成固定文本的错误信息，这个错误信息就是在<code>ClickHouseExceptionSpecifier.specify</code>方法里被处理成<code>Code: 10, e.displayText() = DB::Exception: ...</code>这种结构。<br>所以回到上面的结论，就是说这个<code>http</code>连接出现异常，未等到结果，抛出了<code>SocketTimeoutException</code>，那么根据这个异常，我们可以定位到根本原因了</li>
<li>接着看<code>java.net.SocketTimeoutException</code>类<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Signals that a timeout has occurred on a socket read or accept.</span><br><span class="line"> *</span><br><span class="line"> * @since   1.4</span><br><span class="line"> *&#x2F;</span><br><span class="line"></span><br><span class="line">public class SocketTimeoutException extends java.io.InterruptedIOException &#123;</span><br><span class="line">    private static final long serialVersionUID &#x3D; -8846654841826352300L;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * Constructs a new SocketTimeoutException with a detail</span><br><span class="line">     * message.</span><br><span class="line">     * @param msg the detail message</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public SocketTimeoutException(String msg) &#123;</span><br><span class="line">        super(msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * Construct a new SocketTimeoutException with no detailed message.</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public SocketTimeoutException() &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
这个类非常简短，但是很清晰告诉我们，会抛出<code>SocketTimeoutException</code>异常的原因只能是一个<code>socket</code>读取或者接收时发生了超时</li>
<li>题外话什么是<code>socket</code><br><code>socket</code>的含义就是两个应用程序通过一个双向的通信连接实现数据的交换，连接的一段就是一个<code>socket</code>，又称为套接字。实现一个<code>socket</code>连接通信至少需要两个套接字，一个运行在服务端（插孔），一个运行在客户端（插头）。套接字用于描述<code>IP</code>地址和端口，是一个通信链的句柄。应用程序通过套接字向网络发出请求或应答网络请求。注意的是套接字既不是程序也不是协议，只是操作系统提供给通信层的一组抽象<code>API</code>接口。<br><code>socket</code>是应用层与<code>TCP/IP</code>协议簇通信的中间抽象层，是一组接口。在设计模式中其实就是门面模式。<code>Socket</code>将复杂的<code>TCP/IP</code>协议簇隐藏在接口后面，对于用户而言，一组接口即可让<code>Socket</code>去组织数据，以符合指定的协议。<br><img src="/images/clickhouse/jdbc/1.png" alt="1"></li>
</ul>
<h3 id="回归正题，什么是Read-Timed-Out"><a href="#回归正题，什么是Read-Timed-Out" class="headerlink" title="回归正题，什么是Read Timed Out"></a>回归正题，什么是Read Timed Out</h3><p>所谓<code>read timed out</code>就是读超时，<code>http</code>连接已创建，客户端等待服务端返回结果，等待时间超过了超时时间，所以客户端连接断开，抛出<code>SocketTimeoutException</code>异常。我们可以模拟出这个过程，代码如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ReadTimedOutTest &#123;</span><br><span class="line"></span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      ServerSocket serverSocket &#x3D; new ServerSocket(8888, 200);</span><br><span class="line">      Thread.sleep(66666666);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  @Test</span><br><span class="line">  public void tetReadTimedOut() &#123;</span><br><span class="line">    Socket socket &#x3D; new Socket();</span><br><span class="line">    long starTime &#x3D; 0;</span><br><span class="line">    try &#123;</span><br><span class="line">      socket.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8888), 10000);</span><br><span class="line">      System.out.println(&quot;socket连接成功。。。。&quot;);</span><br><span class="line">      socket.setSoTimeout(2000);</span><br><span class="line">      starTime &#x3D; System.currentTimeMillis();</span><br><span class="line">      int read &#x3D; socket.getInputStream().read();</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      long endTime &#x3D; System.currentTimeMillis();</span><br><span class="line">      System.out.println(&quot;执行时间：&quot;+(endTime - starTime));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>报错信息如下截图：<br><img src="/images/clickhouse/jdbc/2.png" alt="2"><br>意思是说已连接服务端的8888端口，握手是正常的，然后开始传输数据，因为限制了服务端<code>Thread.sleep</code>，让服务端无法给客户端传输数据</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p><code>clickhouse-jdbc</code>默认给<code>SOCKET_TIMEOUT</code>设置的时间是30s，由于服务端不知道何时能返回结果（此时间受<code>settings.max_execution_time</code>影响），所以我们最好给<code>jdbc</code>设置一个<strong>socket_timeout=max_execution_time+10s</strong>，防止服务端还在处理，而客户端已经超时断开连接。<br><img src="/images/clickhouse/jdbc/3.png" alt="3"><br>下面这个方法，主要是解析<strong>jdbc:clickhouse://127.0.0.1:8023?socket_timeout=500000&amp;connection_timeout=500000</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static Properties parseUriQueryPart(String query, Properties defaults) &#123;</span><br><span class="line">  if (query &#x3D;&#x3D; null) &#123;</span><br><span class="line">      return defaults;</span><br><span class="line">  &#125;</span><br><span class="line">  Properties urlProps &#x3D; new Properties(defaults);</span><br><span class="line">  String queryKeyValues[] &#x3D; query.split(&quot;&amp;&quot;);</span><br><span class="line">  for (String keyValue : queryKeyValues) &#123;</span><br><span class="line">      String keyValueTokens[] &#x3D; keyValue.split(&quot;&#x3D;&quot;);</span><br><span class="line">      if (keyValueTokens.length &#x3D;&#x3D; 2) &#123;</span><br><span class="line">          urlProps.put(keyValueTokens[0], keyValueTokens[1]);</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">          logger.warn(&quot;don&#39;t know how to handle parameter pair: &#123;&#125;&quot;, keyValue);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return urlProps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><img src="/images/clickhouse/jdbc/4.png" alt="4"><br><img src="/images/clickhouse/jdbc/5.png" alt="5"></p>
<h3 id="clickhouse-jdbc执行过程"><a href="#clickhouse-jdbc执行过程" class="headerlink" title="clickhouse-jdbc执行过程"></a>clickhouse-jdbc执行过程</h3><h4 id="实例化ClickHouseDataSource对象"><a href="#实例化ClickHouseDataSource对象" class="headerlink" title="实例化ClickHouseDataSource对象"></a>实例化ClickHouseDataSource对象</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ClickHouseDataSource dataSource &#x3D; new ClickHouseDataSource(jdbc, properties);</span><br></pre></td></tr></table></figure>
<p>该构造函数主要是将<strong>jdbc:clickhouse//ip:port/database?key1=value1&amp;key2=value2</strong>这个url进行解析，若涉及clickhouse默认参数，则会覆盖<code>clickhouse</code>默认配置，返回<code>ClickHouseProperties</code>d对象<br><img src="/images/clickhouse/jdbc/6.png" alt="6"></p>
<h4 id="获取ClickHouseConnectionImpl连接"><a href="#获取ClickHouseConnectionImpl连接" class="headerlink" title="获取ClickHouseConnectionImpl连接"></a>获取ClickHouseConnectionImpl连接</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ClickHouseConnectionImpl connection &#x3D; (ClickHouseConnectionImpl) dataSource.getConnection();</span><br></pre></td></tr></table></figure>
<ul>
<li><p>1、实例化ClickHouseConnectionImpl对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ClickHouseConnectionImpl connection &#x3D; new ClickHouseConnectionImpl(url, properties);</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/jdbc/7.png" alt="7"><br><img src="/images/clickhouse/jdbc/8.png" alt="8"><br>这里主要是干2件事，1、首先要实例化出<code>ClickHouseHttpClientBuilder</code>客户端对象构造器，这个构造器会把我们在<strong>jdbc:clickhouse//ip:port/database?key1=value1&amp;key2=value2</strong>这个url里的<strong>key1=value1&amp;key2=value2</strong>传入给<code>CloseableHttpClient</code>类型的<code>httpclient</code>，2、再去初始化连接，获取<code>clickhouse</code>服务端的时区和版本，所以我们每次连接<code>clickhouse-jdbc</code>，都会看到发出一条sql<code>select timezone(), version()</code></p>
</li>
<li><p>2、把连接存到<code>Collections.synchronizedMap</code>线程安全的<code>map</code>里</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">registerConnection(connection);</span><br></pre></td></tr></table></figure></li>
<li>3、返回连接对象</li>
</ul>
<h4 id="执行sql过程"><a href="#执行sql过程" class="headerlink" title="执行sql过程"></a>执行sql过程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">connection.createStatement().executeQuery(sql);</span><br></pre></td></tr></table></figure>
<ul>
<li><p>先初始化<code>ClickHouseStatementImpl</code>对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public ClickHouseStatement createStatement(int resultSetType) throws SQLException &#123;</span><br><span class="line">    return LogProxy.wrap(</span><br><span class="line">        ClickHouseStatement.class,</span><br><span class="line">        new ClickHouseStatementImpl(</span><br><span class="line">            httpclient,</span><br><span class="line">            this,</span><br><span class="line">            properties,</span><br><span class="line">            resultSetType));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>再执行<code>sql</code><br>1、方法<code>getLastInputStream</code>，支持<code>multi-query</code>用法，多条sql去查<br><img src="/images/clickhouse/jdbc/9.png" alt="9"><br>2、调用的<code>getInputStream</code>方法其实就是构造http的post请求，去执行和返回结果，出错则抛出异常<br><img src="/images/clickhouse/jdbc/10.png" alt="10"><br>3、获取最后的执行结果<br><img src="/images/clickhouse/jdbc/11.png" alt="11"><br>4、返回最后sql的结果集<code>ResultSet</code>，select查询类按配置取到最后结果，其他为null</p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><code>Read timed out</code>表示已经连接成功(即三次握手已经完成)，但是服务器没有及时返回数据(没有在设定的时间内返回数据)，导致读超时。</li>
<li><code>java</code>在<code>linux</code>中的 <code>Read timed out</code> 并不是通过<code>C</code>函数<code>setSockOpt(SO_RCVTIMEO)</code>来设置的，而是通过<code>select(s, timeout)</code>来实现定时器，并抛出<code>JNI</code>异常来控制的</li>
<li><code>java socket</code>读超时的设置是在<code>read()</code>方法被调用的时候传入的，所以只要在<code>read()</code>调用之前设置即可</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
        <tag>http</tag>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse用户资源隔离在滴滴的实践</title>
    <url>/2021/12/11/clickhouse-user-quota/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>大数据架构<code>olap</code>团队对<code>clickhouse</code>的使用是从2019年5月开始，最开始我们只在国内永顺机房落地了4台机器做共享集群，就是最开始的<code>cluster01</code>集群，4台机器做2个<code>shard</code>，每个<code>shard</code>2个<code>replica</code>，而用户对集群的访问只是通过一个<code>vip</code>做简单的负载均衡，关于权限这一块，我们在当时只做到了库级别的管控，简单说就是通过同步<code>dpp_v3</code>.<code>hadoop_account</code>和<code>dpp_v3</code>.<code>hive_database</code>库去更新<code>user.xml</code>文件，如下图所示，我们并未对租户资源做任何隔离，虽然最开始我们就是使用的多租户模型，但每个租户可以有权限去操作自己名下的所有库，包括读和写，且无限制的进行大量耗资源（<code>cpu</code>和<code>memory</code>）写入和查询后就会影响到<code>cluster01</code>集群下其他的租户，因为<code>cpu</code>和<code>memory</code>是固定的，而租户的分摊并未做限制。<br><img src="/images/clickhouse/authority/2.png" alt="avatar"></p>
<h3 id="clickhouse配置详解"><a href="#clickhouse配置详解" class="headerlink" title="clickhouse配置详解"></a>clickhouse配置详解</h3><h4 id="config-xml文件介绍"><a href="#config-xml文件介绍" class="headerlink" title="config.xml文件介绍"></a>config.xml文件介绍</h4><p><code>clickhouse</code>的启动方式是通过以下命令处理的，就让 <code>ClickHouse</code> 按照<code>config.xml</code>配置文件运行，同时 <code>ClickHouse</code> 监听配置文件，如有变化，不需要重启就能按新的配置运行。具体介绍可以参考<a href="https://clickhouse.com/docs/en/operations/configuration-files/#implementation-details" target="_blank" rel="noopener">链接</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;clickhouse-server --config&#x3D;.&#x2F;conf&#x2F;config.xml</span><br></pre></td></tr></table></figure><br>我们在生产环境下<code>config.xml</code>文件主要是如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt; </span><br><span class="line">&lt;yandex&gt; </span><br><span class="line">    &lt;!-- 日志配置 --&gt;</span><br><span class="line">    &lt;logger&gt; </span><br><span class="line">        &lt;level&gt;trace&lt;&#x2F;level&gt; </span><br><span class="line">        &lt;log&gt;&#x2F;tmp&#x2F;log&#x2F;clickhouse-server.log&lt;&#x2F;log&gt; </span><br><span class="line">        &lt;errorlog&gt;&#x2F;tmp&#x2F;log&#x2F;clickhouse-server.err.log&lt;&#x2F;errorlog&gt; </span><br><span class="line">        &lt;size&gt;1000M&lt;&#x2F;size&gt; </span><br><span class="line">        &lt;count&gt;10&lt;&#x2F;count&gt; </span><br><span class="line">    &lt;&#x2F;logger&gt; </span><br><span class="line">    &lt;!-- 开启查询和写入相关日志配置 --&gt;</span><br><span class="line">    &lt;query_log&gt; </span><br><span class="line">        &lt;database&gt;system&lt;&#x2F;database&gt; </span><br><span class="line">        &lt;table&gt;query_log&lt;&#x2F;table&gt; </span><br><span class="line">        &lt;partition_by&gt;toYYYYMM(event_date)&lt;&#x2F;partition_by&gt; </span><br><span class="line">        &lt;flush_interval_milliseconds&gt;1000&lt;&#x2F;flush_interval_milliseconds&gt; </span><br><span class="line">    &lt;&#x2F;query_log&gt; </span><br><span class="line">    &lt;!-- tcp端口 --&gt;</span><br><span class="line">    &lt;tcp_port&gt;9000&lt;&#x2F;tcp_port&gt; </span><br><span class="line">    &lt;!-- 运行所有ip访问 --&gt;</span><br><span class="line">    &lt;listen_host&gt;0.0.0.0&lt;&#x2F;listen_host&gt; </span><br><span class="line">    &lt;!-- 最大连接数 --&gt;</span><br><span class="line">    &lt;max_connections&gt;4096&lt;&#x2F;max_connections&gt;</span><br><span class="line">    &lt;!-- 连接超时时间 --&gt;</span><br><span class="line">    &lt;keep_alive_timeout&gt;90&lt;&#x2F;keep_alive_timeout&gt;</span><br><span class="line">    &lt;!-- 最大并发查询数 --&gt;</span><br><span class="line">    &lt;max_concurrent_queries&gt;1000&lt;&#x2F;max_concurrent_queries&gt;</span><br><span class="line">    &lt;!-- 用户配置文件 --&gt;</span><br><span class="line">    &lt;users_config&gt;users.xml&lt;&#x2F;users_config&gt;</span><br><span class="line">    &lt;!-- 默认配置名称 --&gt;</span><br><span class="line">    &lt;default_profile&gt;default&lt;&#x2F;default_profile&gt;</span><br><span class="line">    &lt;!-- 默认数据库名称 --&gt;</span><br><span class="line">    &lt;default_database&gt;default&lt;&#x2F;default_database&gt;</span><br><span class="line">    &lt;!-- zookeeper配置 --&gt;</span><br><span class="line">    &lt;zookeeper incl&#x3D;&quot;zookeeper-servers&quot; optional&#x3D;&quot;true&quot; &#x2F;&gt;</span><br><span class="line">    &lt;!-- 宏配置 --&gt;</span><br><span class="line">    &lt;macros incl&#x3D;&quot;macros&quot; optional&#x3D;&quot;true&quot; &#x2F;&gt;</span><br><span class="line">    &lt;!-- 权限相关的sql存储路径 --&gt;</span><br><span class="line">    &lt;access_control_path&gt;&#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;access&lt;&#x2F;access_control_path&gt;</span><br><span class="line">&lt;&#x2F;yandex&gt;</span><br></pre></td></tr></table></figure><br>我们应该注意到 <code>&lt;users_config&gt;users.xml&lt;/users_config&gt;</code> 绑定了 <code>config.xml</code> 当前目录的 <code>users.xml</code>,而 <code>users.xml</code>就是我们最初版本的用户配置文件</p>
<h4 id="users-xml文件介绍"><a href="#users-xml文件介绍" class="headerlink" title="users.xml文件介绍"></a>users.xml文件介绍</h4><p><code>ClickHouse</code>支持基于 <a href="https://en.wikipedia.org/wiki/Role-based_access_control" target="_blank" rel="noopener">RBAC</a>（基于角色的访问控制权限）方法的访问控制管理。作为一个分析类型（<code>OLAP</code>）的数据库系统，相对于<code>MySQL</code>数据库在用户管理方面有很大不同，<code>clickhouse</code>支持使用两种方式配置访问实体：</p>
<ul>
<li>通过<code>sql</code>直接设置，这也是官方推荐的，但是需要至少一个用户帐户启用<code>SQL</code>驱动的访问控制和帐户管理，这需要使用第二种方式设置<code>access_management</code></li>
<li>通过配置文件<code>users.xml</code>，默认位置在<code>/etc/clickhouse-server</code>目录下，<code>ClickHouse</code>使用它来定义用户相关的配置项。<blockquote>
<p>注意，您不能同时通过两种配置方法来管理同一访问实体。（You can’t manage the same access entity by both configuration methods simultaneously.）<br><code>users.xml</code>有三大块进行说明，分别为：<code>profiles</code>，<code>quotas</code>，<code>users</code>，主要配置如下所示：</p>
</blockquote>
</li>
<li>profiles介绍<br><a href="https://clickhouse.com/docs/en/operations/settings/settings-profiles/" target="_blank" rel="noopener">官方链接</a><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- profiles相当于role角色配置 --&gt;</span><br><span class="line">&lt;profiles&gt; </span><br><span class="line">    &lt;!-- 角色名称，可配置多个 --&gt;</span><br><span class="line">    &lt;default&gt; </span><br><span class="line">        &lt;!-- 单个服务器 最大可使用内存 --&gt;</span><br><span class="line">        &lt;max_memory_usage&gt;10G&lt;&#x2F;max_memory_usage&gt; </span><br><span class="line">        &lt;!-- 单个服务器 用户查询最大可使用内存 --&gt;</span><br><span class="line">        &lt;max_memory_usage_for_user&gt;10G&lt;&#x2F;max_memory_usage_for_user&gt; </span><br><span class="line">        &lt;!-- 所有查询可使用的最大内存 --&gt;</span><br><span class="line">        &lt;max_memory_usage_for_all_queries&gt;10G&lt;&#x2F;max_memory_usage_for_all_queries&gt; </span><br><span class="line">        &lt;!-- 最大查询长度 --&gt;</span><br><span class="line">        &lt;max_query_size&gt;1073741824&lt;&#x2F;max_query_size&gt; </span><br><span class="line">        &lt;!-- DDL查询：CREATE，ALTER，RENAME，ATTACH，DETACH，DROP TRUNCATE,0:禁止，1:允许 --&gt;</span><br><span class="line">        &lt;allow_ddl&gt;0&lt;&#x2F;allow_ddl&gt;</span><br><span class="line">    &lt;&#x2F;default&gt; </span><br><span class="line">    &lt;readonly&gt;</span><br><span class="line">      &lt;!-- 只读角色，枚举0:允许所有查询，1:只允许读数据的查询，3:运行读取数据和更改配置 --&gt;</span><br><span class="line">      &lt;readonly&gt;2&lt;&#x2F;readonly&gt;</span><br><span class="line">    &lt;&#x2F;readonly&gt;</span><br><span class="line">&lt;&#x2F;profiles&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>quotas介绍<br><a href="https://clickhouse.com/docs/en/operations/quotas/" target="_blank" rel="noopener">官方链接</a>，截取部分代码实现细节如下,从源码中我们能看出，每次查询的时候，都去检查(<code>checkExceeded()</code>)是否超过配额<br><img src="/images/clickhouse/authority/3.png" alt="avatar">，每个 interval 都有多种资源(<code>resource_type</code>), 比如 <code>`&lt;query&gt;1&lt;/query&gt;</code> 是一种 <code>type</code>, 检查最大库存 <code>max</code>，检查已经使用的配额 <code>used</code>, 如果 <code>used</code> &gt; <code>max</code>, 则报错。<br><img src="/images/clickhouse/authority/4.png" alt="avatar"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 配额，限制用户一段时间内的资源使用，即对一段时间内运行的一组查询施加限制，而不是限制单个查询。 --&gt;</span><br><span class="line">&lt;quotas&gt; </span><br><span class="line">    &lt;!-- 配额名称 --&gt;</span><br><span class="line">    &lt;default&gt; </span><br><span class="line">        &lt;!-- 时间间隔 --&gt;</span><br><span class="line">        &lt;interval&gt; </span><br><span class="line">            &lt;!-- 时间周期 以秒为单位 --&gt; </span><br><span class="line">            &lt;duration&gt;10&lt;&#x2F;duration&gt; </span><br><span class="line">            &lt;!-- 10 秒内只能查询一次 --&gt; </span><br><span class="line">            &lt;queries&gt;2&lt;&#x2F;queries&gt; </span><br><span class="line">            &lt;errors&gt;0&lt;&#x2F;errors&gt; </span><br><span class="line">            &lt;!-- 时间周期内允许返回的行数，0表示不限制 --&gt;</span><br><span class="line">            &lt;result_rows&gt;0&lt;&#x2F;result_rows&gt; </span><br><span class="line">            &lt;!-- 时间周期内运行读取的行数，0表示不限制 --&gt;</span><br><span class="line">            &lt;read_rows&gt;0&lt;&#x2F;read_rows&gt; </span><br><span class="line">            &lt;!-- 时间周期内查询的可执行时间，0表示不限制 --&gt;</span><br><span class="line">            &lt;execution_time&gt;0&lt;&#x2F;execution_time&gt; </span><br><span class="line">        &lt;&#x2F;interval&gt;</span><br><span class="line">    &lt;&#x2F;default&gt; </span><br><span class="line">&lt;&#x2F;quotas&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>users介绍<br><a href="https://clickhouse.com/docs/en/operations/quotas/" target="_blank" rel="noopener">官方链接</a><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 用户配置,定义一个新用户，必须包含以下几项属性：用户名、密码、访问ip、数据库、表等等。它还可以应用上面的profile、quota --&gt;</span><br><span class="line">&lt;users&gt; </span><br><span class="line">    &lt;!-- 用户名 --&gt;</span><br><span class="line">    &lt;default&gt; </span><br><span class="line">        &lt;!-- 此设置为用户启用或禁用SQL驱动的访问控制和帐户管理。可能的值：0-禁用。1-启用。默认为0 --&gt;</span><br><span class="line">        &lt;access_management&gt;1&lt;&#x2F;access_management&gt;</span><br><span class="line">        &lt;!-- 密码 --&gt;</span><br><span class="line">        &lt;password&gt;password&lt;&#x2F;password&gt; </span><br><span class="line">        &lt;!-- 用户可以从中连接到ClickHouse服务器的网络列表 --&gt;</span><br><span class="line">        &lt;networks&gt; </span><br><span class="line">            &lt;!-- 要为来自任何网络的用户打开访问权限 --&gt;</span><br><span class="line">            &lt;ip&gt;::&#x2F;0&lt;&#x2F;ip&gt; </span><br><span class="line">        &lt;&#x2F;networks&gt; </span><br><span class="line">        &lt;!-- 指定用户的角色 --&gt;</span><br><span class="line">        &lt;profile&gt;default&lt;&#x2F;profile&gt; </span><br><span class="line">        &lt;!-- 指定用户的配额 --&gt;</span><br><span class="line">        &lt;quota&gt;default&lt;&#x2F;quota&gt; </span><br><span class="line">    &lt;&#x2F;default&gt; </span><br><span class="line">&lt;&#x2F;users&gt;</span><br></pre></td></tr></table></figure>
<h4 id="常见的权限报错"><a href="#常见的权限报错" class="headerlink" title="常见的权限报错"></a>常见的权限报错</h4></li>
<li>超过quota限制<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Code: 201. DB::Exception: Received from localhost:9000. DB::Exception: Quota for user &#96;default&#96; for 10s has been exceeded: queries &#x3D; 4&#x2F;3. Interval will end at 2020-04-02 11:29:40. Name of quota template: &#96;default&#96;.</span><br></pre></td></tr></table></figure>
如果在至少一个时间间隔内超过了限制，则将引发一个异常，并显示一条文本：是对于哪一个间隔的，何时新间隔可以开始（何时可以再次发送查询）。</li>
<li>超过profile限制<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Code: 452, e.displayText() &#x3D; DB::Exception: Setting max_memory_usage should not be greater than 20000000000.</span><br><span class="line">Code: 452, e.displayText() &#x3D; DB::Exception: Setting max_memory_usage should not be less than 5000000000.</span><br></pre></td></tr></table></figure>
查询超过了最大使用内存</li>
<li>user限制<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Code: 516, e.displayText() &#x3D; DB::Exception: prod_dlap_manager: Authentication failed: password is incorrect or there is no user with such name (version 206.1.1)</span><br></pre></td></tr></table></figure>
用户不存在，或者用户的密码错误<h3 id="改进方案"><a href="#改进方案" class="headerlink" title="改进方案"></a>改进方案</h3>经过对<code>clickhouse</code>的权限相关了解之后，我们在2021年8月进行了一次权限升级方案改造，通过default用户创建出超级管理员super_admin及普通管理员admin（如果在user.xml里定义了super_admin用户，之后就无法修改，若修改则直接报错<code>Cannot update user admin in users.xml because this storage is readonly</code>），以超级管理员的身份给超级租户和普通租户赋权，可以通过SQL的方式进行权限的<code>CRUD</code>，以达到动态分配集群资源的目的。<br><img src="/images/clickhouse/authority/5.png" alt="avatar"><br>经过拆分后，我们单独自研了<code>DlapManager</code>组件，用以管控<code>Clickhouse</code>集群读写节点、<code>zookeeper</code>组件、<code>CHProxy</code>组件（采用开源工具快速接入以实现读写ck角色的区分，达到数据写入均衡查询均衡的 目的，<a href="https://github.com/Vertamedia/chproxy" target="_blank" rel="noopener">链接</a>），而<code>CHProxy</code>组件需要的集群读写资源则通过<code>DlapManager</code>角色进行实时更新和生产，而外部平台业务方直接调用<code>DlapManager</code>组件对外开放的<code>api</code>进行库表的所有<code>DDL</code>操作，目前我们的所有普通租户均是用户通过数据梦工厂的创建项目开通实时权限后，我们会自动创建一个租户在<code>Clickhouse</code>这边，当该租户进行库表<code>DDL</code>后，<code>DlapManager</code>组件就会生成相应的<code>DDL</code>任务队列，队列以异步线程方式实时发往对应的集群，以下的<code>DlapManager</code>组件的系统架构设计图：<br><img src="/images/clickhouse/authority/6.png" alt="avatar"><h3 id="赋权过程"><a href="#赋权过程" class="headerlink" title="赋权过程"></a>赋权过程</h3>按照<a href="https://clickhouse.com/docs/en/operations/access-rights/#enabling-access-control" target="_blank" rel="noopener">官方推荐</a>的方式进行赋权过程，以达到不同租户使用相应的配额，实现集群内的资源隔离，保障集群的稳定性。</li>
<li>创建超级租户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE USER super_admin; </span><br><span class="line">GRANT ALL ON *.* TO super_admin WITH GRANT OPTION; </span><br><span class="line">CREATE USER admin;</span><br></pre></td></tr></table></figure></li>
<li>创建profiles设置<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE SETTINGS PROFILE IF NOT EXISTS didi_profile SETTINGS readonly &#x3D; 2 READONLY</span><br></pre></td></tr></table></figure></li>
<li>创建quota配额<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE QUOTA IF NOT EXISTS didi_quota </span><br><span class="line">FOR INTERVAL 10 second </span><br><span class="line">MAX queries 1</span><br></pre></td></tr></table></figure></li>
<li>创建角色<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE ROLE IF NOT EXISTS didi_role</span><br></pre></td></tr></table></figure></li>
<li>赋予 Role 权限<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 允许didi_role这个角色可以访问库名叫db的所有表的查询权限</span><br><span class="line">GRANT SELECT ON db.* TO didi_role</span><br></pre></td></tr></table></figure></li>
<li>创建一个回收角色，用以回收不使用的profile、quota<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REATE ROLE IF NOT EXISTS gc_role</span><br></pre></td></tr></table></figure></li>
<li>Role 绑定 Profile, Quota<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER SETTINGS PROFILE didi_profile TO didi_role;</span><br><span class="line">ALTER QUOTA didi_quota TO didi_role;</span><br></pre></td></tr></table></figure></li>
<li>应用到租户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GRANT didi_role TO super_admin</span><br></pre></td></tr></table></figure></li>
<li>验证租户角色<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM system.role_grants WHERE user_name LIKE &#39;admin&#39;</span><br></pre></td></tr></table></figure></li>
<li>修改用户的quota(当用户的读/写超过了限额后需要给用户扩容)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先创建新quota</span><br><span class="line">CREATE QUOTA IF NOT EXISTS new_quota FOR INTERVAL 5 second MAX queries 1;</span><br><span class="line"># 将原先的didi_quota绑定到gc_role</span><br><span class="line">ALTER QUOTA didi_quota TO gc_role;</span><br><span class="line"># 绑定新quota</span><br><span class="line">ALTER QUOTA new_quota TO didi_role; </span><br><span class="line"># 刷新admin的角色</span><br><span class="line">revoke didi_role from admin; </span><br><span class="line">grant didi_role to admin;</span><br><span class="line"># double check检查</span><br><span class="line">SELECT name, apply_to_list FROM system.quotas WHERE name LIKE &#39;new_quota&#39;</span><br></pre></td></tr></table></figure></li>
<li>修改用户的profile(当用户的读/写超过了限额后需要给用户扩容)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 先创建新profile</span><br><span class="line">CREATE SETTINGS PROFILE IF NOT EXISTS new_profile SETTINGS readonly &#x3D; 0 READONLY;</span><br><span class="line"># 将原先的didi_profile绑定到gc_role</span><br><span class="line">ALTER SETTINGS PROFILE didi_profile TO gc_role</span><br><span class="line"># 绑定新profile</span><br><span class="line">ALTER SETTINGS PROFILE new_profile TO didi_role;</span><br><span class="line"># 刷新admin的角色</span><br><span class="line">revoke didi_role from admin; </span><br><span class="line">grant didi_role to admin;</span><br><span class="line"># double check检查</span><br><span class="line">SELECT name, apply_to_list FROM system.settings_profiles WHERE name LIKE &#39;new_quota&#39;</span><br></pre></td></tr></table></figure>
<h3 id="权限持久化"><a href="#权限持久化" class="headerlink" title="权限持久化"></a>权限持久化</h3></li>
<li>存放目录配置<br>根据<a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#access_control_path" target="_blank" rel="noopener">官方文档</a>介绍，通过<code>sql</code>进行的权限相关配置，可以通过<code>config.xml</code>里的<code>access_control_path</code>属性进行路径配置，若未配置则默认是<code>/var/lib/clickhouse/access/</code>目录，如下图所示，当<code>clickhouse</code>重启后，都会先从<code>access_control_path</code>配置的目录里根据<code>sql</code>恢复所有权限，如果这些文件被删除，则重启<code>clickhouse</code>后之前通过<code>sql</code>创建的这些<code>setting</code>都会消失，所以注意文件的备份，目前<code>DlapManager</code>组件是使用<code>mysql</code>数据存储引擎单独存储了这份<code>RBAC</code>数据，再发送给<code>clickhouse</code>进行权限相关的<code>CRUD</code>，这个方式也相当于是<code>clickhouse</code>的备份地址，如果<code>clickhouse</code>重启后无法刷新这些权限，则仍然可以通过<code>DlapManager</code>组件写的脚本工具去重新生产出新的<code>sql</code>给<code>clickhouse</code>使用。<br><img src="/images/clickhouse/authority/7.png" alt="avatar"></li>
<li>users.list介绍<br>每创建一个用户，则会在<code>users.list</code>文件里记录到用户名对应的一串<code>uuid</code>，可通过<code>uuid</code>找到创建该用户的<code>sql</code>语句，如下图：<br><img src="/images/clickhouse/authority/8.png" alt="avatar"></li>
<li>uuid.sql介绍<br>包含了创建用户（create user）的sql，赋权（GRANT）的sql等<br><img src="/images/clickhouse/authority/9.png" alt="avatar"></li>
<li>quotas.list介绍<br>每创建一个<code>quota</code>，都会在<code>quotas.list</code>文件记录quota名称及对应的一个<code>uuid</code>，可通过<code>uuid</code>找到创建该<code>quota</code>的<code>sql</code>语句</li>
<li>roles.list介绍<br>每创建一个<code>role</code>，都会在<code>roles.list</code>文件记录quota名称及对应的一个<code>uuid</code>，可通过<code>uuid</code>找到创建该<code>role</code>的<code>sql</code>语句</li>
<li>row_policies.list介绍<br>每创建一个<code>row_policy</code>，都会在<code>row_policies.list</code>文件记录quota名称及对应的一个<code>uuid</code>，可通过<code>uuid</code>找到创建该<code>row_policy</code>的<code>sql</code>语句</li>
<li>settings_profiles.list介绍<br>每创建一个<code>profile</code>，都会在<code>settings_profiles.list</code>文件记录quota名称及对应的一个<code>uuid</code>，可通过<code>uuid</code>找到创建该<code>profile</code>的<code>sql</code>语句<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3>本文从<code>clickhouse</code>的用户资源角度来简单介绍了<code>clickhouse</code>的相关配置及如何使用，而我们自研的<code>DlapManager</code>组件则承担起了 <code>ClickHouse</code> 用户管理的角色，通过对<code>clickhouse</code>的<code>profle</code>、<code>quota</code>、<code>role</code>等抽象层的配置来达到对<code>clickhouse</code>使用资源的租户隔离目的，中心思想是我们不是直接给租户赋予相关权限，而是在租户之上创建了角色的维度，和<code>RBAC</code>思想一致，可以达到对租户进行灵活的扩缩容配额，最终来保障我们目前200+<code>clickhouse</code>节点的稳定性。最后笔者从2019年6月开始接触<code>clickhouse</code>，到现在也已经2年+的时间，但仍然只学到了<code>clickhouse</code>的冰山一角，所以以上文字也只能做到抛砖引玉，但仍然希望对阅读的各位有所帮助。</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>ClickHouse</tag>
      </tags>
  </entry>
  <entry>
    <title>ClickHouse解析器大揭秘</title>
    <url>/2022/11/04/clickhouse-parser/</url>
    <content><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>我们知道语法分析器的作用是根据给定的<a href="https://baike.baidu.com/item/%E5%BD%A2%E5%BC%8F%E6%96%87%E6%B3%95/2447403" target="_blank" rel="noopener">形式文法</a>对由词法单元（Token）序列构成的输入进行语法检查、并构建由输入的词法单元（Token）组成的数据结构（一般是<a href="https://baike.baidu.com/item/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E6%A0%91/20452541" target="_blank" rel="noopener">语法分析树</a>、<a href="https://baike.baidu.com/item/%E6%8A%BD%E8%B1%A1%E8%AF%AD%E6%B3%95%E6%A0%91/6129952" target="_blank" rel="noopener">抽象语法树</a>等层次化的数据结构）。而一提到语法解析目前市面上有很多语法解析器，其中解析sql更是数不胜数，例如最为人所知的antlr和jflex，而本文的主人公ClickHouse却自己去纯手工打造实现了一套sql解析器，本篇文章就来聊聊 ClickHouse 的纯手工解析器，看看它们的底层工作机制。</p>
<h2 id="简单入门"><a href="#简单入门" class="headerlink" title="简单入门"></a>简单入门</h2><blockquote>
<p>首先来简单入门解决个小问题，那就是我们如何去连接ck，如何将query传递ck呢，如何设置传递给ck的query长度呢？   </p>
</blockquote>
<h3 id="通过TCP方式请求"><a href="#通过TCP方式请求" class="headerlink" title="通过TCP方式请求"></a>通过TCP方式请求</h3><blockquote>
<p>通过tcp方式使用clickhouse自己的客户端，连接clickhouse，在会话session里先使用<strong>set max_query_size=xx</strong>的方式让当前这个会话修改query的长度，如下图：  </p>
</blockquote>
<p><img src="/images/clickhouse/maxquerysize/1.png" alt="clickhouse"></p>
<h3 id="通过HTTP方式请求"><a href="#通过HTTP方式请求" class="headerlink" title="通过HTTP方式请求"></a>通过HTTP方式请求</h3><blockquote>
<p>通过http方式请求，<a href="http://ip:port/database?user=xx&amp;password=yy&amp;max_query_size=xx，ck会传递这个参数给setting重写">http://ip:port/database?user=xx&amp;password=yy&amp;max_query_size=xx，ck会传递这个参数给setting重写</a><br>注意chproxy只允许最大max_query_size为512mb，超过此长度会直接报错  </p>
</blockquote>
<h3 id="通过sql创建setting授权给登陆用户"><a href="#通过sql创建setting授权给登陆用户" class="headerlink" title="通过sql创建setting授权给登陆用户"></a>通过sql创建setting授权给登陆用户</h3><ol>
<li>创建setting profile<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create settings profile if not exists role_max_query_size SETTINGS max_query_size &#x3D; 100000000000;</span><br></pre></td></tr></table></figure></li>
<li>将profile赋值给某个用户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant role_max_query_size to prod_voyager_stats_events;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="源码解析ck是如何处理max-query-size的"><a href="#源码解析ck是如何处理max-query-size的" class="headerlink" title="源码解析ck是如何处理max_query_size的"></a>源码解析ck是如何处理max_query_size的</h3><blockquote>
<p>由于源码较多，只抽出具体实现函数进行源码讲解，本次讲解基于clickhouse v20.6.3.28-stable（该版本与最新版出入较大）。  </p>
</blockquote>
<p><img src="/images/clickhouse/maxquerysize/2.png" alt="clickhouse"></p>
<ol>
<li>如上图所示，在<code>HTTPHandler.cpp</code>下进行各种http的协议处理时，有一个变量叫<strong>HTMLForm</strong>类型的<code>params</code>，承载的是http请求里的<code>uri</code>，并且在代码的484行进行了此变量的处理，如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (const auto &amp; [key, value] : params)</span><br><span class="line">&#123;</span><br><span class="line">    if (key &#x3D;&#x3D; &quot;database&quot;)</span><br><span class="line">    &#123;</span><br><span class="line">        if (database.empty())</span><br><span class="line">            database &#x3D; value;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (key &#x3D;&#x3D; &quot;default_format&quot;)</span><br><span class="line">    &#123;</span><br><span class="line">        if (default_format.empty())</span><br><span class="line">            default_format &#x3D; value;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (param_could_be_skipped(key))</span><br><span class="line">    &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F;&#x2F; Other than query parameters are treated as settings.</span><br><span class="line">        if (!customizeQueryParam(context, key, value))</span><br><span class="line">            settings_changes.push_back(&#123;key, value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>而<code>customizeQueryParam</code>会判断该参数param是否等于query，如果是则不会进入setting的设置，再判断是否是param_开头的如果是则会传入context（理解为这次session会话中需要设置的各种上下文内容）则也不会进行setting处理，不是前面2个case则进行setting处理，重载系统默认的setting里的参数，如下图<br><img src="/images/clickhouse/maxquerysize/3.png" alt="clickhouse"></li>
<li>虽然第二步已经设置了setting，但注意代码的512行，这行代码会走向<strong>SettingsConstraints.cpp</strong>类的<strong>checkImpl</strong>校验逻辑里，有一些配置是不允许修改的，例如<strong>profile</strong>，例如配置就是如果已经通过grant授权配置了<strong>setting profile</strong>了，会去看这个用户的相关权限，如果不符合则会直接抛出exception，不再进行处理，注意这里还有一个问题，抛了异常后，不再将此次请求写入到system.query_log中，之后我们会修复此问题<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;&#x2F; For external data we also want settings</span><br><span class="line">context.checkSettingsConstraints(settings_changes);</span><br><span class="line">context.applySettingsChanges(settings_changes);</span><br></pre></td></tr></table></figure></li>
<li>做完setting的约束校验后，都符合条件，则我们已经重载了setting里的<strong>max_query_size</strong>，之后就走入了<strong>executeQuery.cpp</strong>执行query逻辑，在它的构造函数里我们就可以看到query是根据<strong>max_query_size</strong>来读取的，如下图<br><img src="/images/clickhouse/maxquerysize/4.png" alt="clickhouse"></li>
</ol>
<h2 id="深入探知"><a href="#深入探知" class="headerlink" title="深入探知"></a>深入探知</h2><p>介绍完了<strong>max_query_size</strong>的处理逻辑后，其实我们已经大致明白ck在query的处理流程是如何流转的，那么现在问题来了，我们知道可以通过<code>select xx from tb SETTINGS max_query_size=12112</code>这种方式传入自定义的setting参数，但是有些参数有生效，而select语法却对max_query_size不生效，原因是什么呢？好了，别着急现在我们就来解答ck是如何处理setting这层逻辑的。</p>
<h3 id="为什么max-query-size的select中不生效？"><a href="#为什么max-query-size的select中不生效？" class="headerlink" title="为什么max_query_size的select中不生效？"></a>为什么max_query_size的select中不生效？</h3><p><img src="/images/clickhouse/maxquerysize/5.png" alt="clickhouse"><br>原因很简单，只要我们读过了上面的流转过程，就知道max_query_size这个参数的处理系统默认是256kb，那么如果未通过uri方式传入<strong>max_query_size</strong>，则在截取query长度前，默认都是256kb，注意截取query时是还未进行ck的parser逻辑处理的，我们可以看到query里的setting是需要经过ck的parser解析后，才会重载进去(如下图6)，所以呢如果你的select query在256kb范围内，则截取完整query后，经过ck的parser解析出ast树，是会带上新的setting，但此时已经没有意义了，而相反的如果你的query超过了256kb，则只截取到256kb前的query，此时setting也不会走到<strong>ParserSelectQuery</strong>里，同时因为你的query被不完整截取后，会直接报ast语法错误<br><img src="/images/clickhouse/maxquerysize/6.png" alt="图6"></p>
<h2 id="源码看解析器"><a href="#源码看解析器" class="headerlink" title="源码看解析器"></a>源码看解析器</h2><h3 id="1-HTTPHandler-cpp-gt-processQuery"><a href="#1-HTTPHandler-cpp-gt-processQuery" class="headerlink" title="1. HTTPHandler.cpp =&gt; processQuery"></a>1. HTTPHandler.cpp =&gt; processQuery</h3><blockquote>
<p>每一个http请求都在clickhouse都会起一个叫<strong>HTTPHandler</strong>的线程去处理，根据http请求header和body，初始化请求上下文环境：包括session、用户信息、当前database、响应信息等，另外还处理限流，用户权限，根据配置取到setting信息进行设置，本文重点是调用<code>executeQuery</code>方法处理<code>query</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">executeQuery(*in, *used_output.out_maybe_delayed_and_compressed, &#x2F;* allow_into_outfile &#x3D; *&#x2F; false, context,</span><br><span class="line">        [&amp;response] (const String &amp; current_query_id, const String &amp; content_type, const String &amp; format, const String &amp; timezone)</span><br><span class="line">        &#123;</span><br><span class="line">            response.setContentType(content_type);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Query-Id&quot;, current_query_id);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Format&quot;, format);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Timezone&quot;, timezone);</span><br><span class="line">        &#125;</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="2-executeQuery-cpp-gt-executeQuery"><a href="#2-executeQuery-cpp-gt-executeQuery" class="headerlink" title="2. executeQuery.cpp =&gt; executeQuery"></a>2. executeQuery.cpp =&gt; executeQuery</h3><p>从流中读出字节到buffer里，根据设置的<code>max_query_size</code>判断buffer是否已满，复制到LimitReadBuffer里，重点是执行<strong>executeQueryImpl</strong>，返回tuple类型的(ast, stream)，从stream里提取出<strong>pipeline(流水线)</strong>，根据ast构造出<code>IBlockInputStream</code>或者<code>IBlockOutputStream</code>，传给pipeline后执行pipeline的execute方法<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">std::tie(ast, streams) &#x3D; executeQueryImpl(begin, end, context, false, QueryProcessingStage::Complete, may_have_tail, &amp;istr);</span><br></pre></td></tr></table></figure></p>
<h3 id="2-executeQuery-cpp-gt-executeQueryImpl"><a href="#2-executeQuery-cpp-gt-executeQueryImpl" class="headerlink" title="2. executeQuery.cpp =&gt; executeQueryImpl"></a>2. executeQuery.cpp =&gt; executeQueryImpl</h3><p>按照解析出的ast，构造出Interpreter，调用Interpreter的exec方法去执行后返回pipeline，执行结果记录到query_log里，最后把构造出对应的ast和pipeline返回<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 这里是实现了ParserQuery对象，继承了IParserBase，IParserBase继承自IParser，等下走到6时，才知道虚函数parseImpl会通过ParserQuery对象实现</span><br><span class="line">ParserQuery parser(end, settings.enable_debug_queries);</span><br><span class="line">.........</span><br><span class="line">ast &#x3D; parseQuery(parser, begin, end, &quot;&quot;, max_query_size, settings.max_parser_depth);</span><br><span class="line">.........</span><br><span class="line">auto interpreter &#x3D; InterpreterFactory::get(ast, context, stage);</span><br><span class="line">.........</span><br><span class="line">res &#x3D; interpreter-&gt;execute();</span><br><span class="line">QueryPipeline &amp; pipeline &#x3D; res.pipeline;</span><br><span class="line">.........</span><br><span class="line">return std::make_tuple(ast, std::move(res));</span><br></pre></td></tr></table></figure></p>
<h3 id="3-parseQuery-cpp-gt-parseQueryAndMovePosition"><a href="#3-parseQuery-cpp-gt-parseQueryAndMovePosition" class="headerlink" title="3. parseQuery.cpp =&gt; parseQueryAndMovePosition"></a>3. parseQuery.cpp =&gt; parseQueryAndMovePosition</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ASTPtr res &#x3D; tryParseQuery(parser, pos, end, error_message, false, query_description, allow_multi_statements, max_query_size, max_parser_depth);</span><br></pre></td></tr></table></figure>
<h3 id="4-parseQuery-cpp-gt-tryParseQuery"><a href="#4-parseQuery-cpp-gt-tryParseQuery" class="headerlink" title="4. parseQuery.cpp =&gt; tryParseQuery"></a>4. parseQuery.cpp =&gt; tryParseQuery</h3><blockquote>
<p>尝试解析SQL，将sql通过语法树规则装入TokenIterator，返回ASTPtr  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; ClickHouse词法分析器是由Tokens和Lexer类来实现，token是最基础的元祖，之间是没有任何关联的，只是一堆词组和符号，通过lexer语法进行解析后，把元祖里的token建立起关系。</span><br><span class="line">Tokens tokens(pos, end, max_query_size);</span><br><span class="line">IParser::Pos token_iterator(tokens, max_parser_depth);</span><br><span class="line">&#x2F;&#x2F; 注意这里，TokenIterator对-&gt;使用了重载，在重载函数里去初始化TOKEN，主要是从第一个字符开始使用pos++的方式进行判断，可以进入Token Lexer::nextTokenImpl()进行查看</span><br><span class="line">if (token_iterator-&gt;isEnd() || token_iterator-&gt;type &#x3D;&#x3D; TokenType::Semicolon) &#123;</span><br><span class="line">    out_error_message &#x3D; &quot;Empty query&quot;;</span><br><span class="line">    pos &#x3D; token_iterator-&gt;begin;</span><br><span class="line">    return nullptr;</span><br><span class="line">&#125;</span><br><span class="line">.....</span><br><span class="line">Expected expected;</span><br><span class="line">......</span><br><span class="line">ASTPtr res;</span><br><span class="line">bool parse_res &#x3D; parser.parse(token_iterator, res, expected);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：<code>IParser</code>的<code>parse</code>方法是<code>virtual</code>虚函数，<code>IParser</code>作为接口角色，被<code>IParserBase</code>继承，在<code>IParserBase</code>里实现了<code>parse</code>方法。</p>
</blockquote>
<h3 id="5-IParserBase-cpp-gt-parse"><a href="#5-IParserBase-cpp-gt-parse" class="headerlink" title="5. IParserBase.cpp =&gt; parse"></a>5. IParserBase.cpp =&gt; parse</h3><blockquote>
<p>在解每个token时都会根据当前的token进行预判（parseImpl返回的结果），返回true才会进入下一个子token  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool IParserBase::parse(Pos &amp; pos, ASTPtr &amp; node, Expected &amp; expected)</span><br><span class="line">&#123;</span><br><span class="line">    expected.add(pos, getName());</span><br><span class="line"></span><br><span class="line">    return wrapParseImpl(pos, IncreaseDepthTag&#123;&#125;, [&amp;]</span><br><span class="line">    &#123;</span><br><span class="line">        bool res &#x3D; parseImpl(pos, node, expected);</span><br><span class="line">        if (!res)</span><br><span class="line">            node &#x3D; nullptr;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意到parseImpl在IParserBase中是一个虚函数，将被继承自IParserBase类的子类实现，而在 <strong><em> 第2步 </em></strong>中我们定义的子类是ParserQuery，所以此时是直接调用到ParserQuery子类的parseImpl方法</p>
</blockquote>
<h3 id="6-ParserQuery-cpp-gt-parseImpl"><a href="#6-ParserQuery-cpp-gt-parseImpl" class="headerlink" title="6. ParserQuery.cpp =&gt; parseImpl"></a>6. ParserQuery.cpp =&gt; parseImpl</h3><blockquote>
<p>Parser的主要类（也都是继承自IParserBase）分别定义出来后，每个去尝试解析，如果都不在这几个主要Parser里，则返回false，否则返回true，clickhouse把query分类成以下14类，但本质上可以归纳为2类，第一类是有结果输出可对应show/select/desc/create等，第二类是无结果输出可对应insert/use/set等  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bool ParserQuery::parseImpl(Pos &amp; pos, ASTPtr &amp; node, Expected &amp; expected)</span><br><span class="line">&#123;</span><br><span class="line">    ParserQueryWithOutput query_with_output_p(enable_explain);</span><br><span class="line">    ParserInsertQuery insert_p(end);</span><br><span class="line">    ParserUseQuery use_p;</span><br><span class="line">    ParserSetQuery set_p;</span><br><span class="line">    ParserSystemQuery system_p;</span><br><span class="line">    ParserCreateUserQuery create_user_p;</span><br><span class="line">    ParserCreateRoleQuery create_role_p;</span><br><span class="line">    ParserCreateQuotaQuery create_quota_p;</span><br><span class="line">    ParserCreateRowPolicyQuery create_row_policy_p;</span><br><span class="line">    ParserCreateSettingsProfileQuery create_settings_profile_p;</span><br><span class="line">    ParserDropAccessEntityQuery drop_access_entity_p;</span><br><span class="line">    ParserGrantQuery grant_p;</span><br><span class="line">    ParserSetRoleQuery set_role_p;</span><br><span class="line">    ParserExternalDDLQuery external_ddl_p;</span><br><span class="line"></span><br><span class="line">    bool res &#x3D; query_with_output_p.parse(pos, node, expected)</span><br><span class="line">        || insert_p.parse(pos, node, expected)</span><br><span class="line">        || use_p.parse(pos, node, expected)</span><br><span class="line">        || set_role_p.parse(pos, node, expected)</span><br><span class="line">        || set_p.parse(pos, node, expected)</span><br><span class="line">        || system_p.parse(pos, node, expected)</span><br><span class="line">        || create_user_p.parse(pos, node, expected)</span><br><span class="line">        || create_role_p.parse(pos, node, expected)</span><br><span class="line">        || create_quota_p.parse(pos, node, expected)</span><br><span class="line">        || create_row_policy_p.parse(pos, node, expected)</span><br><span class="line">        || create_settings_profile_p.parse(pos, node, expected)</span><br><span class="line">        || drop_access_entity_p.parse(pos, node, expected)</span><br><span class="line">        || grant_p.parse(pos, node, expected)</span><br><span class="line">        || external_ddl_p.parse(pos, node, expected);</span><br><span class="line"></span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意看这个parseImpl方法，进来后都会先去接<code>ParserQueryWithOutput</code>类解析相关ast，这里类涉及到了<code>explain</code>、<code>select</code>、<code>show</code>，<code>create</code>、<code>alter</code>等相关语法的解析，如果解析不过，则直接报错，解析成功后会处理我们这篇文章中提到的<strong>SETTING</strong>，如下图7定义的，将setting传入的变量存入到<code>s_settings</code>指针中。<br><img src="/images/clickhouse/maxquerysize/7.png" alt="图7"></p>
<h3 id="clcikhouse的parser总结："><a href="#clcikhouse的parser总结：" class="headerlink" title="clcikhouse的parser总结："></a>clcikhouse的parser总结：</h3><ul>
<li><ol>
<li>ClickHouse词法分析器<br>词法解析的主要任务是读入源程序的输入字符、将它们组成词素，生成并输出一个词法单元（Token）序列，每个词法单元对应于一个词素。<code>ClickHouse</code>中的每个词法单元（<code>Token</code>）使用一个<code>struct Tocken</code>结构体对象来进行存储，结构体中存储了词法单元的<code>type</code>和<code>value</code>。<br>ClickHouse词法分析器是由<code>Tokens</code>和<code>Lexer</code>类来实现， <strong><em>DB::Lexer::nextTokenImpl()</em></strong>函数用来对<code>SQL</code>语句进行词法分析的具体实现</li>
</ol>
</li>
<li><ol>
<li>ClickHouse语法解析器<br>ClickHouse中定义了不同的Parser用来对不同类型的SQL语句进行语法分析，例如：ParserInsertQuery（Insert语法分析器）、ParserCreateQuery（Create语法分析器）、ParserAlterQuery（Alter语法分析器）等等。<br>Parser首先判断输入的Token序列是否是该类型的SQL，若是该类型的SQL，则继续检查语法的正确性，正确则生成AST返回，语法错误的则抛出语法错误异常，否则直接返回空AST语法树</li>
</ol>
</li>
</ul>
<p><img src="/images/clickhouse/parser/1.png" alt="clickhouse"></p>
<h3 id="解答setting生效问题"><a href="#解答setting生效问题" class="headerlink" title="解答setting生效问题"></a>解答setting生效问题</h3><p><img src="/images/clickhouse/maxquerysize/8.png" alt="图7"><br>如上图所示，当前原生ck只支持InterpreterSelectQuery和InterpreterInsertQuery对query传入setting进行了重载处理。<br>InterpreterSelectQuery是在自己的构造函数里初始化了setting到context里<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void InterpreterSelectQuery::initSettings()</span><br><span class="line">&#123;</span><br><span class="line">    auto &amp; query &#x3D; getSelectQuery();</span><br><span class="line">    if (query.settings())</span><br><span class="line">        InterpreterSetQuery(query.settings(), *context).executeForCurrentContext();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>InterpreterInsertQuery是在parser解析出ast后，在<code>executeQueryImpl</code>进行的setting重载context。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto * insert_query &#x3D; ast-&gt;as&lt;ASTInsertQuery&gt;();</span><br><span class="line"></span><br><span class="line">if (insert_query &amp;&amp; insert_query-&gt;settings_ast)</span><br><span class="line">    InterpreterSetQuery(insert_query-&gt;settings_ast, context).executeForCurrentContext();</span><br></pre></td></tr></table></figure><br>剩下的setting都已经是通过Interpreter执行结束后再处理的，对于我们需要在前置传入时没有效果了。</p>
<h3 id="解决业务困扰"><a href="#解决业务困扰" class="headerlink" title="解决业务困扰"></a>解决业务困扰</h3><p>当前我们的离线导入hive2ck，其实是通过将数据写入到临时表，这张临时表是按照目标表的表结构重新创建了一个MergeTree表，通过spark任务将hive数据以流式方式写入到临时表分区，生产出分区对应的多个part，生产过程中我们会将part拉回到临时表对应的detach目录，这个过程叫<a href="http://way.xiaojukeji.com/article/29557" target="_blank" rel="noopener">离线构建</a>，再将再将part通过ck的attach命令激活，这时候临时表就对该分区可见了，然后再通过replace partition的方式，将临时表的分区替换到我们的目标表去，这整个过程，就是我们的hive2ck处理流程，如下图所示：<br><img src="/images/clickhouse/maxquerysize/9.png" alt="图10"></p>
<blockquote>
<p>我们将此离线构建继承到数梦的同步中心后，陆续遇到了业务方来咨询相关问题，下面是问题汇总及如何解决的  </p>
</blockquote>
<h4 id="如何在离线导入中将明细数据写入到关联的物化视图"><a href="#如何在离线导入中将明细数据写入到关联的物化视图" class="headerlink" title="如何在离线导入中将明细数据写入到关联的物化视图"></a>如何在离线导入中将明细数据写入到关联的物化视图</h4><p>熟悉clickhouse的同学们都知道，原生ck对于物化视图的写入，唯一的方式是在明细表通过insert写入时，才会将数据经过物化视图的触发器写入关联的物化视图，而在离线构建过程中，ck是不支持的，但很多业务方跟我们提出这个需求，希望离线构建可以支持将分区数据写入到关联物化视图去，于是我们对ck的replace partition 进行了改造。<br>改造前的语法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221102&#39; FROM test.visits_basic_tmp;</span><br></pre></td></tr></table></figure><br>改造后的语法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221101&#39; FROM test.visits_basic_tmp AND TRIGGER VIEW;</span><br></pre></td></tr></table></figure><br>在离线构建走到替换分区这一步时，我们改造了AstAlterQuery，让<code>ParserAlterQuery</code>增加了对<code>and trigger view</code>的语法解析，解析之后进入到<code>InterpreterAlterQuery</code>时，如果ast返回的trigger view是true，则程序流程会流转到取出明细表元数据，查询是否有关联物化视图，重新构造出类似下面的sql，交过pipeline进行执行，由此将该分区数据写入到物化视图去。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into 物化视图 select from 明细表 where 分区&#x3D;xx</span><br></pre></td></tr></table></figure></p>
<h4 id="分区过大导入失败如何解决"><a href="#分区过大导入失败如何解决" class="headerlink" title="分区过大导入失败如何解决"></a>分区过大导入失败如何解决</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xxx has timed out! (120000ms) Possible deadlock avoided. Client should retry</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/maxquerysize/10.png" alt="图10"><br>如上图所示，替换分区前，会给该明细表加一把锁，并设定锁时间（lock_acquire_timeout），系统默认时120s，如果该分区过大，替换过程超过120s，则会爆上面错误，而本文最开始已经讲解过如何处理setting，考虑到ck原生只支持insert和select时interpreter对setting重载，由此进行改造让InterpreterAlterQuery也支持通过sql传入锁时间，如下面语法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221108&#39; FROM test.visits_basic_tmp AND TRIGGER VIEW SETTINGS lock_acquire_timeout&#x3D;86400000;</span><br></pre></td></tr></table></figure><br>因为ParserQueryWithOutput已经对setting进行了解析，而AstAlterQuery其实是继承自ASTQueryWithOutput，所以我们已经获得了setting这一块的ast，无需再自己初始化新的ast，只要在InterpreterAlterQuery里把setting重载就行了，如图11<br><img src="/images/clickhouse/maxquerysize/11.png" alt="图10"></p>
<h4 id="替换分区成功，物化视图数据写入报错如何解决"><a href="#替换分区成功，物化视图数据写入报错如何解决" class="headerlink" title="替换分区成功，物化视图数据写入报错如何解决"></a>替换分区成功，物化视图数据写入报错如何解决</h4><ol>
<li>首先我们在数梦平台上控制了相关的ddl语句修改，如果用户要删明细表字段，则必须先去处理关联的物化视图字段，如果用户要删明细表，则必须先删物化视图</li>
<li>遇到替换分区成功，而物化视图写入失败，报错都是锁明细表超时，对于这种case可直接解锁明细表的锁，让物化视图自己去写，不再锁明细表，所以只需要做简单的锁释放便可</li>
</ol>
<p>以上是对ck进行改造过程中遇到的3个问题，此改造过程主要是满足离线导入可写入物化视图，未来我们还将对ck进行更多改造，以满足不同业务需求，各个 业务线大佬们如果在使用ck过程中有遇到任何问题，欢迎加入ck用户群，和我们一起沟通解决。</p>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse副本不同步问题排查</title>
    <url>/2022/12/08/clickhouse%E5%89%AF%E6%9C%AC%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>clickhouse的Replicated**MergeTree表是通过zookeeper来完成同一个shard之间的副本数据的同步，因为clickhouse本身不是master/slave的架构，我们通过proxy的方式，设定了同一个shard里某个副本是读/写节点角色，另一个节点是读角色，当用户写入时，proxy会路由到读/写节点去完成写入操作，然后通过zk发起同步任务，把日志进入到system.replcation_queue。<br>今天早上用户和我们反馈说数据查询时每一次结果都不一样，用户查询也是通过连我们的proxy进行读节点的路由，所以用户反馈的结果不一致，其实是第一次路由到读/写节点查询结果是a，第二次路由到读节点，查询结果是b，由于a和b两个副本数据没有同步，导致了查询结果不一致，下面是排查的过程。</p>
<h3 id="system-replication-queue"><a href="#system-replication-queue" class="headerlink" title="system.replication_queue"></a>system.replication_queue</h3><blockquote>
<p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/replication_queue/" target="_blank" rel="noopener">官方地址</a>所解释,该表记录了当前的副本任务队列的所有信息，如下图所示，我们看到当前副本同步出现大量异常错误  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from system.replication_queue where data_files &gt; 0</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/replicas_data_diff/1.png" alt="clickhouse"><br>如下图所示，<strong>type</strong>字段可以查看到当前是什么类型的操作导致的，发现是<strong>MUTATE_PART</strong>操作，<strong>last_exception</strong>字段显示当前我们在操作ttl时创建的元数据目录下columns.txt无法打开，这个是已知bug。<br><img src="/images/clickhouse/replicas_data_diff/2.png" alt="clickhouse"></p>
<h3 id="system-mutations"><a href="#system-mutations" class="headerlink" title="system.mutations"></a>system.mutations</h3><blockquote>
<p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/mutations" target="_blank" rel="noopener">官方地址</a>，该表包含了所有mutation操作的日志信息，<a href="https://clickhouse.com/docs/en/sql-reference/statements/alter/#mutations" target="_blank" rel="noopener">mutation</a>操作包括修改字段类型/修改表ttl操作/按条件删表的数据/按条件更新表的数据等，这些操作都是异步后台线程去处理，都会去回溯该表的所有parts，需要rewrite每个part的信息并且这个操作还不是原子性的，所以如果某个节点操作失败，可能引发该表无法使用。  </p>
</blockquote>
<p>该表包含字段如下：</p>
<ul>
<li><p>database (String) — 数据库名称.</p>
</li>
<li><p>table (String) — 表名称.</p>
</li>
<li><p>data_path (String) — 本地文件的路径.</p>
</li>
<li><p>mutation_id (String) — mutation的唯一标识，可通过该标识直接kill mutation.</p>
</li>
<li><p>command (String) — mutation命令.</p>
</li>
<li><p>create_time (DateTime) —  mutation创建时间.</p>
</li>
<li><p>block_numbers (Map) — partition_id：需要进行mutation操作的分区id，number：需要进行mutation的分区对应的block序号.</p>
</li>
<li><p>parts_to_do_names (Array) — 即将完成的需要进行mutation的数组.</p>
</li>
<li><p>parts_to_do (Int64) — 准备进行mutation操作的part序号.</p>
</li>
<li><p>is_done (UInt8) — 该操作是否已完成.</p>
</li>
<li><p>latest_failed_part (String) — mutation操作最后失败的part名称.</p>
</li>
<li><p>latest_fail_time (DateTime) — 最后失败的时间.</p>
</li>
<li><p>latest_fail_reason (String) — 最后失败的原因.</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from system.mutations where latest_failed_part !&#x3D; &#39;&#39;</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/replicas_data_diff/3.png" alt="clickhouse"></p>
<blockquote>
<p>根据异常错误的<strong>command</strong>字段，我们看到错误是通过<code>MATERIALIZE TTL FAST 16070400</code>引起的，mutation操作在写节点处理完成后，也会通过zookeeper进行副本数据同步</p>
</blockquote>
<h3 id="解决副本不同步问题"><a href="#解决副本不同步问题" class="headerlink" title="解决副本不同步问题"></a>解决副本不同步问题</h3><ul>
<li>终止该失败的mutation<br>具体操作语句可以查看<a href="https://clickhouse.com/docs/zh/sql-reference/statements/kill/#:~:text=KILL%20MUTATION%E2%80%8B&amp;text=Tries%20to%20cancel%20and%20remove,list%20of%20mutations%20to%20stop." target="_blank" rel="noopener">官方文档</a><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill mutation where database &#x3D; &#39;xx&#39; and table &#x3D; &#39;yy&#39; and mutation_id &#x3D; &#39;zz&#39;;</span><br></pre></td></tr></table></figure></li>
<li>操作之后，可以通过查询shard里每个副本的count是否一致来判断数据是否已经进行同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select count(dt), dt from xx.yy group by dt;</span><br></pre></td></tr></table></figure></li>
<li>操作之后，可以通过上面的<code>system.replication_queue</code>表来观察是否开始进行副本数据同步<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from system.replication_queue where type&#x3D;&#39;GET_PART&#39; and database &#x3D; &#39;xx&#39; and table &#x3D; &#39;yy&#39;</span><br></pre></td></tr></table></figure></li>
<li>如果还没恢复，则去对应出错的副本节点，将本地表删除后重建（出错节点可以从上一步里看出来）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop table if exists xx.yy</span><br><span class="line">create table xx.yy</span><br></pre></td></tr></table></figure></li>
<li>此时再查询replication_queue表出错的队列应该已经被清理掉了<br>可以继续操作元数据修改</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>cpp奇葩语法介绍</title>
    <url>/2022/01/13/cpp_introduction/</url>
    <content><![CDATA[<h3 id="const"><a href="#const" class="headerlink" title="const"></a>const</h3><h3 id="friend"><a href="#friend" class="headerlink" title="friend"></a>friend</h3><blockquote>
<p>友邻函数</p>
</blockquote>
<h3 id="extern"><a href="#extern" class="headerlink" title="extern"></a>extern</h3><h3 id="vitrual"><a href="#vitrual" class="headerlink" title="vitrual"></a>vitrual</h3><blockquote>
<p>基类希望其派生类进行覆盖（<code>override</code>）的函数。这种函数，基类通常将其定义为虚函数（加<code>virtual</code>）。当我们使用基类的指针或者引用调用虚函数时，该调用将被<strong>动态绑定</strong></p>
<h4 id="用法解释："><a href="#用法解释：" class="headerlink" title="用法解释："></a>用法解释：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Base &#123;</span><br><span class="line">  public:</span><br><span class="line">    virtual void print() &#123;</span><br><span class="line">      cout &lt;&lt; &quot;&#x3D;&#x3D;BASE&#x3D;&#x3D;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">class Derived: public Base &#123;</span><br><span class="line">  public:</span><br><span class="line">    void print()&#123;</span><br><span class="line">      cout &lt;&lt; &quot;&#x3D;&#x3D;DERIVED&#x3D;&#x3D;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int main() &#123;</span><br><span class="line">  Base *pointer &#x3D; new Derived();</span><br><span class="line">  &#x2F;&#x2F; &#x3D;&#x3D;DERIVED&#x3D;&#x3D;</span><br><span class="line">  pointer-&gt;print();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>类<code>Base</code>中加了<code>Virtual</code>关键字的函数就是虚拟函数（例如函数<code>print</code>），于是在<code>Base</code>的派生类<code>Derived</code>中就可以通过重写虚拟函数来实现对基类虚拟函数的覆盖。当基类<code>Base</code>的指针<code>point</code>指向派生类<code>Derived</code>的对象时，对<code>point</code>的<code>print</code>函数的调用实际上是调用了<code>Derived</code>的<code>print</code>函数而不是<code>Base</code>的<code>print</code>函数。这是面向对象中的多态性的体现 </p>
<h4 id="纯虚函数"><a href="#纯虚函数" class="headerlink" title="纯虚函数"></a>纯虚函数</h4><p>纯虚函数声明如下： <code>virtual void funtion1()=0;</code> 纯虚函数一定没有定义，纯虚函数用来规范派生类的行为，即接口。包含纯虚函数的类是抽象类，抽象类不能定义实例，但可以声明指向实现该抽象类的具体类的指针或引用。</p>
</blockquote>
<h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><ul>
<li>定义一个函数为虚函数，不代表函数为不被实现的函数。</li>
<li>定义一个虚函数是为了允许用基类的指针或引用来调用子类的这个函数。</li>
<li>定义一个函数为纯虚函数，才代表函数没有被实现。</li>
<li>定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。</li>
<li>任何友元(friend)/构造(construct)/static静态函数之外的函数都可以是虚函数。</li>
<li>关键字virtual只能出现在类内部的声明语句之前而不能用于类外部的函数定义</li>
<li>基类定义了virtual，继承类的该函数也具有了virtual属性</li>
</ul>
<h3 id="static"><a href="#static" class="headerlink" title="static"></a>static</h3><h3 id="template"><a href="#template" class="headerlink" title="template"></a>template</h3><h3 id="inline"><a href="#inline" class="headerlink" title="inline"></a>inline</h3><h3 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h3><blockquote>
<p>在声明变量时根据变量初始值的类型自动为此变量选择匹配的类型。</p>
<h4 id="用法解释：-1"><a href="#用法解释：-1" class="headerlink" title="用法解释："></a>用法解释：</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto f &#x3D; 3.14;  &#x2F;&#x2F;double</span><br><span class="line">auto s(&quot;hello&quot;);  &#x2F;&#x2F;const char*</span><br><span class="line">auto z &#x3D; new auto(9);  &#x2F;&#x2F;int *</span><br></pre></td></tr></table></figure>
<h4 id="注意点-1"><a href="#注意点-1" class="headerlink" title="注意点"></a>注意点</h4><ul>
<li>可以用valatile，pointer（*），reference（&amp;），rvalue reference（&amp;&amp;） 来修饰auto<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto k &#x3D; 5;  </span><br><span class="line">auto* pK &#x3D; new auto(k);  </span><br><span class="line">auto** ppK &#x3D; new auto(&amp;k);  </span><br><span class="line">const auto n &#x3D; 6;</span><br></pre></td></tr></table></figure></li>
<li>用auto声明的变量必须初始化</li>
<li>auto不能与其他类型组合连用</li>
<li>函数和模板参数不能被声明为auto</li>
<li>定义在堆上的变量，使用了auto的表达式必须被初始化</li>
<li>以为auto是一个占位符，并不是一个他自己的类型，因此不能用于类型转换或其他一些操作，如sizeof和typeid</li>
<li>定义在一个auto序列的变量必须始终推导成同一类型<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 错误，必须是初始化为同一类型</span><br><span class="line">auto x1 &#x3D; 5, x2 &#x3D; 5.0, x3&#x3D;&#39;r&#39;;</span><br></pre></td></tr></table></figure></li>
<li>auto不能自动推导成CV-qualifiers (constant &amp; volatile qualifiers)</li>
<li>auto会退化成指向数组的指针，除非被声明为引用</li>
</ul>
</blockquote>
<h3 id="template-1"><a href="#template-1" class="headerlink" title="template"></a>template</h3><h3 id="左值和右职"><a href="#左值和右职" class="headerlink" title="左值和右职"></a>左值和右职</h3><h4 id="左值和右值的概念"><a href="#左值和右值的概念" class="headerlink" title="左值和右值的概念"></a>左值和右值的概念</h4><ul>
<li>左值是可以放在赋值号左边可以被赋值的值；左值必须要在内存中有实体；</li>
<li>右值当在赋值号右边取出值赋给其他变量的值；右值可以在内存也可以在CPU寄存器。</li>
<li>一个对象被用作右值时，使用的是它的内容(值)，被当作左值时，使用的是它的地址。</li>
</ul>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><ul>
<li>引用是C++语法做的优化，引用的本质还是靠指针来实现的。引用相当于变量的别名。</li>
<li>引用可以改变指针的指向，还可以改变指针所指向的值。</li>
<li>引用的基本规则：<ul>
<li>声明引用的时候必须初始化，且一旦绑定，不可把引用绑定到其他对象；即引用必须初始化，不能对引用重定义；</li>
<li>对引用的一切操作，就相当于对原对象的操作。</li>
</ul>
</li>
</ul>
<h4 id="左值引用和右值引用"><a href="#左值引用和右值引用" class="headerlink" title="左值引用和右值引用"></a>左值引用和右值引用</h4><ul>
<li>左值引用：<ul>
<li>左值引用的基本语法：type &amp;引用名 = 左值表达式；</li>
</ul>
</li>
<li>右值引用：<ul>
<li>右值引用的基本语法type &amp;&amp;引用名 = 右值表达式；</li>
<li>右值引用在企业开发人员在代码优化方面会经常用到。</li>
<li>右值引用的“&amp;&amp;”中间不可以有空格。</li>
</ul>
</li>
</ul>
<h3 id="operator"><a href="#operator" class="headerlink" title="operator"></a>operator</h3><blockquote>
<p>operator是C++的关键字，它和运算符一起使用，表示一个运算符函数，理解时应将operator=整体上视为一个函数名。</p>
</blockquote>
<p>1、只有C++预定义的操作符才可以被重载；</p>
<p>2、对于内置类型的操作符，它的预定义不能改变，即不能改变操作符原来的功能；</p>
<p>3、重载操作符不能改变他们的操作符优先级；</p>
<p>4、重载操作符不能改变操作数的个数；</p>
<p>5、除了对（）操作符外，对其他重载操作符提供缺省实参都是非法的； </p>
<h3 id="explicit"><a href="#explicit" class="headerlink" title="explicit"></a>explicit</h3><blockquote>
<p>放构造函数前，防止隐式转换，普通构造函数能够被隐式调用，而explicit构造函数只能被显式调用。例子如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Test1 &#123;</span><br><span class="line">  public:</span><br><span class="line">    Test1(int n) &#123;</span><br><span class="line">      num &#x3D; n;</span><br><span class="line">    &#125;</span><br><span class="line">  private:</span><br><span class="line">    int num;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Test2 &#123;</span><br><span class="line">  public:</span><br><span class="line">    explicit Test2(int n) &#123;</span><br><span class="line">      num &#x3D; n;</span><br><span class="line">    &#125;</span><br><span class="line">  private:</span><br><span class="line">    int num;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">  Test1 t1 &#x3D; 12; &#x2F;&#x2F; 隐私调用其构造函数Test1，等同于Test1 t1(12)</span><br><span class="line">  Test2 t2 &#x3D; 100; &#x2F;&#x2F;编译错误，不能隐式调用其构造函数</span><br><span class="line">  Test2 t3(323); &#x2F;&#x2F;显示调用成功</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="dynamic-cast"><a href="#dynamic-cast" class="headerlink" title="dynamic_cast"></a>dynamic_cast</h3><blockquote>
<p>将基类的指针或引用安全地转换成派生类的指针或引用，并用派生类的指针或引用调用非虚函数。如果是基类指针或引用调用的是虚函数无需转换就能在运行时调用派生类的虚函数</p>
</blockquote>
<p>前提条件：当我们将dynamic_cast用于某种类型的指针或引用时，只有该类型含有虚函数时，才能进行这种转换。否则，编译器会报错。</p>
<p>dynamic_cast运算符的调用形式如下所示：</p>
<p>dynamic_cast<type*>(e)  //e是指针</p>
<p>dynamic_cast<type&>(e)  //e是左值</p>
<p>dynamic_cast<type&&>(e)//e是右值</p>
<p>e能成功转换为type*类型的情况有三种：</p>
<p>1）e的类型是目标type的公有派生类：派生类向基类转换一定会成功。</p>
<p>2）e的类型是目标type的基类，当e是指针指向派生类对象，或者基类引用引用派生类对象时，类型转换才会成功，当e指向基类对象，试图转换为派生类对象时，转换失败。</p>
<p>3）e的类型就是type的类型时，一定会转换成功。</p>
<h3 id="reinterpt-cast"><a href="#reinterpt-cast" class="headerlink" title="reinterpt_cast"></a>reinterpt_cast</h3><blockquote>
<p>该函数将一个类型的指针转换为另一个类型的指针，这种转换不用修改指针变量值存放格式(不改变指针变量值)，只需在编译时重新解释指针的类型就可做到。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int* a &#x3D; 1;</span><br><span class="line">double* b &#x3D; reinterpret_cast&lt;double*&gt;(a)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="const-cast"><a href="#const-cast" class="headerlink" title="const_cast"></a>const_cast</h3><blockquote>
<p>该函数用于去除指针变量的常量属性，将它转换为一个对应指针类型的普通变量。反过来说，也可以将一个非常量的指针变量转换为一个常量指针变量。这种转换是在编译期间作出的类型更改。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">const int* a &#x3D; 1;</span><br><span class="line">int* pk &#x3D; const_cast&lt;int*&gt;(a); &#x2F;&#x2F; 相当于 int* pk &#x3D; (int*) a</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="static-cast"><a href="#static-cast" class="headerlink" title="static_cast"></a>static_cast</h3><blockquote>
<p>该函数主要用于基本类型之间和具有继承关系的类型之间的转换。这种转换一般会更改变量的内部表示方式，因此，static_cast应用于指针类型转换没有太大意义。</p>
</blockquote>
<p>主要有如下几种用法：</p>
<ul>
<li>用于类层次结构中基类和子类之间指针或引用的转换。</li>
<li>进行上行转换（把子类的指针或引用转换成基类表示）是安全的；</li>
<li>进行下行转换（把基类指针或引用转换成子类指针或引用）时，由于没有动态类型检查，所以是不安全的。</li>
<li>用于基本数据类型之间的转换，如把int转换成char，把int转换成enum。这种转换的安全性也要开发人员来保证。</li>
<li>把void指针转换成目标类型的指针(不安全!!)</li>
<li>把任何类型的表达式转换成void类型。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;基本类型转换</span><br><span class="line">int i&#x3D;0;</span><br><span class="line">double d &#x3D; static_cast&lt;double&gt;(i);  &#x2F;&#x2F;相当于 double d &#x3D; (double)i;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;转换继承类的对象为基类对象</span><br><span class="line">class Base&#123;&#125;;</span><br><span class="line">class Derived : public Base&#123;&#125;;</span><br><span class="line">Derived d;</span><br><span class="line">Base b &#x3D; static_cast&lt;Base&gt;(d);     &#x2F;&#x2F;相当于 Base b &#x3D; (Base)d;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="mutable"><a href="#mutable" class="headerlink" title="mutable"></a>mutable</h3><p>mutable的作用有两点：<br>（1）保持常量对象中大部分数据成员仍然是“只读”的情况下，实现对个别数据成员的修改；<br>（2）使类的const函数可以修改对象的mutable数据成员。</p>
<p>使用mutable的注意事项：<br>（1）mutable只能作用于类的非静态和非常量数据成员。<br>（2）在一个类中，应尽量或者不用mutable，大量使用mutable表示程序设计存在缺陷。</p>
<h3 id="using"><a href="#using" class="headerlink" title="using"></a>using</h3><ul>
<li><ol>
<li>命名空间的使用<blockquote>
<p>一般是为了代码的冲突，都会用命名空间，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 命名空间名称</span><br><span class="line">namespace android</span><br><span class="line">class Test &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 直接使用该命名空间</span><br><span class="line">using namespace android;</span><br><span class="line">&#x2F;&#x2F; 使用该命名空间的Test类</span><br><span class="line">using android::Test;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>在子类汇总引用基类的成员<blockquote>
<p>注意，using只是引用，不参与形参的指定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Base &#123;</span><br><span class="line">public:</span><br><span class="line">  Base() &#123;&#125;</span><br><span class="line">  virtual ~Base() &#123;&#125;</span><br><span class="line">  void hello()&#123; std::cout &lt;&lt; &quot;hello world&quot; &lt;&lt; std::endl; &#125;</span><br><span class="line">protected:</span><br><span class="line">  int value;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 私有继承，无法使用基类的public&#x2F;protected属性的变量和函数</span><br><span class="line">class Common: private Base &#123;</span><br><span class="line">public:</span><br><span class="line">&#x2F;&#x2F; 使用using方法是来引用，这样Common类就能直接用了</span><br><span class="line">  using Base::hello;</span><br><span class="line">  using Base:value;</span><br><span class="line"></span><br><span class="line">  void test() &#123; std::cout &lt;&lt; &quot;value is: &quot; &lt;&lt; value &lt;&lt; std::endll &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>别名指定<blockquote>
<p>从可读性上说，typedef 要比 using 好理解，另外typedef是无法使用模版的，而using可以使用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 这样之后就可以使用value_type xx 去代表type xx</span><br><span class="line">using value_type &#x3D; type;</span><br><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">using Vec &#x3D; MyVector&lt;T, MyAlloc&lt;T&gt;&gt;;</span><br><span class="line">&#x2F;&#x2F;usage</span><br><span class="line">Vec&lt;int&gt; vec;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
</ul>
<h3 id="const-char-char-const-char-const的区别"><a href="#const-char-char-const-char-const的区别" class="headerlink" title="const char , char const , char * const的区别"></a>const char <em>, char const </em>, char * const的区别</h3><blockquote>
<p>把一个声明从右向左读。( * 读成 pointer to ),C++标准规定，const关键字放在类型或变量名之前等价的。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; cp is a const pointer to char</span><br><span class="line">&#x2F;&#x2F; 定义一个指向字符的指针常数，即const指针</span><br><span class="line">char * const cp;  </span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; p is a pointer to const char</span><br><span class="line">&#x2F;&#x2F; 定义一个指向字符常数的指针</span><br><span class="line">const char * p; </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 同上因为C++里面没有const*的运算符，所以const只能属于前面的类型。</span><br><span class="line">char const * p;</span><br></pre></td></tr></table></figure></p>
</blockquote>
]]></content>
      <categories>
        <category>introduction</category>
      </categories>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>按日切割使用docker安装的nginx容器</title>
    <url>/2020/02/17/docke-nginx-logrotate/</url>
    <content><![CDATA[<h2 id="了解几个相关命令"><a href="#了解几个相关命令" class="headerlink" title="了解几个相关命令"></a>了解几个相关命令</h2><ul>
<li>查看docker nginx容器 进程 pid<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 请务必确认您的docker container name是什么，笔者名称是nginx</span><br><span class="line">&#x2F;&#x2F; 命令1</span><br><span class="line">sudo docker inspect --format&#x3D;&#39;&#123;&#123;.State.Pid&#125;&#125;&#39; $(sudo docker ps -a | grep nginx | awk &#39;&#123;print $1&#125;&#39;)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;命令2是命令1的缩写</span><br><span class="line">sudo docker inspect  -f &#39;&#123;&#123;.State.Pid&#125;&#125;&#39; $(sudo docker ps -a | grep nginx | awk &#39;&#123;print $1&#125;&#39;)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;命令3是命令2的缩写</span><br><span class="line">sudo docker inspect -f &#39;&#123;&#123; .State.Pid &#125;&#125;&#39; nginx</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 命令4</span><br><span class="line">sudo docker top $(sudo docker ps -a | grep nginx | awk &#39;&#123;print $1&#125;&#39;) | grep master | awk &#39;&#123;print $2&#125;&#39;</span><br></pre></td></tr></table></figure></li>
<li>通知nginx重新打开日志文件<blockquote>
<p>Nginx 官方其实给出了如何滚动日志的说明：<br>Rotating Log-files<br>In order to rotate log files, they need to be renamed first. After that USR1 signal should be sent to the master process. The master process will then re-open all currently open log files and assign them an unprivileged user under which the worker processes are running, as an owner. After successful re-opening, the master process closes all open files and sends the message to worker process to ask them to re-open files. Worker processes also open new files and close old files right away. As a result, old files are almost immediately available for post processing, such as compression.<br>以上英文的大致意思是<br>1.先把旧的日志文件重命名<br>2.然后给 nginx master 进程发送 USR1 信号<br>3.nginx master 进程收到信号后会做一些处理，然后要求工作者进程重新打开日志文件<br>4.工作者进程打开新的日志文件并关闭旧的日志文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -USR1 pid</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li><p>logrotate使用帮助</p>
<ul>
<li>配置说明</li>
</ul>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:center">参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">daily</td>
<td style="text-align:center">日志的轮替周期是每天</td>
</tr>
<tr>
<td style="text-align:left">weekly</td>
<td style="text-align:center">日志的轮替周期是每周</td>
</tr>
<tr>
<td style="text-align:left">monthly</td>
<td style="text-align:center">日志的轮替周期是每月</td>
</tr>
<tr>
<td style="text-align:left">rotate</td>
<td style="text-align:center">数字 保留的日志文件个数，0指没有备份</td>
</tr>
<tr>
<td style="text-align:left">compress</td>
<td style="text-align:center">当进行日志轮替时，对旧的日志进行压缩</td>
</tr>
<tr>
<td style="text-align:left">create</td>
<td style="text-align:center">mode owner group 建立新日志，同时指定新日志的权限与所有者和所属组，如 create 0644 root root</td>
</tr>
<tr>
<td style="text-align:left">copytruncate</td>
<td style="text-align:center">用于还在打开中的日志文件，把当前日志备份并截断</td>
</tr>
<tr>
<td style="text-align:left">mail</td>
<td style="text-align:center">address 当进行日志轮替时，输出内容通过邮件发送到指定的邮件地址，如 mail test@gmail.com</td>
</tr>
<tr>
<td style="text-align:left">missingok</td>
<td style="text-align:center">如果日志不存在，则忽略改日志的警告信息</td>
</tr>
<tr>
<td style="text-align:left">notifempty</td>
<td style="text-align:center">如果日志为空文件，则不进行日志轮替</td>
</tr>
<tr>
<td style="text-align:left">minsize</td>
<td style="text-align:center">大小 日志只有大于指定大小才进行日志轮替，而不是按照时间轮替，如 size 100k</td>
</tr>
<tr>
<td style="text-align:left">dateext</td>
<td style="text-align:center">使用日期作为日志轮替文件的后缀，如 access.log-2019-07-12</td>
</tr>
<tr>
<td style="text-align:left">sharedscripts</td>
<td style="text-align:center">在此关键词之后的脚本只执行一次</td>
</tr>
<tr>
<td style="text-align:left">prerotate/endscript</td>
<td style="text-align:center">在日志轮替之前执行脚本命令。endscript 标识 prerotate 脚本结束</td>
</tr>
<tr>
<td style="text-align:left">postrotate/endscript</td>
<td style="text-align:center">在日志轮替之前执行脚本命令。endscript 标识 postrotate脚本结束</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>参数说明</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:center">参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-?或–help</td>
<td style="text-align:center">在线帮助</td>
</tr>
<tr>
<td style="text-align:left">-d或–debug</td>
<td style="text-align:center">详细显示指令执行过程，便于排错或了解程序执行的情况</td>
</tr>
<tr>
<td style="text-align:left">-f或–force</td>
<td style="text-align:center">强行启动记录文件维护操作，纵使logrotate指令认为没有需要亦然</td>
</tr>
<tr>
<td style="text-align:left">-s&lt;状态文件&gt;或–state=&lt;状态文件&gt;</td>
<td style="text-align:center">使用指定的状态文件</td>
</tr>
<tr>
<td style="text-align:left">-v或–version</td>
<td style="text-align:center">显示指令执行过程</td>
</tr>
<tr>
<td style="text-align:left">-usage</td>
<td style="text-align:center">显示指令基本用法</td>
</tr>
</tbody>
</table>
</div>
<h2 id="脚本详解"><a href="#脚本详解" class="headerlink" title="脚本详解"></a>脚本详解</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F; logrotate.d&#x2F;nginx</span><br><span class="line">&#x2F;&#x2F;复制以下脚本，第一行是您的nginx log路径</span><br><span class="line">&#x2F;home&#x2F;xx&#x2F;docker&#x2F;nginx&#x2F;logs&#x2F;*log &#123;</span><br><span class="line">        daily</span><br><span class="line">        dateext</span><br><span class="line">        missingok</span><br><span class="line">        rotate 52</span><br><span class="line">        compress</span><br><span class="line">        delaycompress</span><br><span class="line">        notifempty</span><br><span class="line">        su hadoop hadoop</span><br><span class="line">        create 0664 hadoop hadoop</span><br><span class="line">        sharedscripts</span><br><span class="line">        postrotate</span><br><span class="line">            sudo docker inspect -f &#39;&#123;&#123; .State.Pid &#125;&#125;&#39; nginx | xargs sudo kill -USR1</span><br><span class="line">        endscript</span><br><span class="line">&#125;</span><br><span class="line">sudo  logrotate -vf &#x2F;etc&#x2F; logrotate.d&#x2F;nginx</span><br></pre></td></tr></table></figure>
<p><img src="/images/logrotate.png" alt="loratate"></p>
<h2 id="crontab-加定时脚本"><a href="#crontab-加定时脚本" class="headerlink" title="crontab 加定时脚本"></a>crontab 加定时脚本</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -e</span><br><span class="line">*&#x2F;30 * * * * &#x2F;usr&#x2F;sbin&#x2F;logrotate &#x2F;etc&#x2F;logrotate.d&#x2F;nginx &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<h2 id="使用docker安装nginx"><a href="#使用docker安装nginx" class="headerlink" title="使用docker安装nginx"></a>使用docker安装nginx</h2><ul>
<li>docker run(运行容器)的参数说明</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">–-name</td>
<td style="text-align:center">容器名称</td>
</tr>
<tr>
<td style="text-align:left">–-link</td>
<td style="text-align:center">连接某个镜像</td>
</tr>
<tr>
<td style="text-align:left">–port</td>
<td style="text-align:center">端口映射</td>
</tr>
<tr>
<td style="text-align:left">–volum</td>
<td style="text-align:center">持久化存储</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>获取nginx 镜像<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker pull nginx</span><br></pre></td></tr></table></figure></li>
<li>运行nginx容器<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; --rm标示删除旧容器 -d 标示daemon守护进程方式运行 --name标示容器名称</span><br><span class="line">docker run --name nginx --network spring-net -p 80:80 -d -v &#x2F;etc&#x2F;nginx&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf:ro -v &#x2F;etc&#x2F;nginx&#x2F;conf.d:&#x2F;etc&#x2F;nginx&#x2F;conf.d -v &#x2F;opt&#x2F;nginx&#x2F;dist:&#x2F;opt&#x2F;nginx&#x2F;dist -v &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime:ro -v &#x2F;var&#x2F;log&#x2F;nginx:&#x2F;var&#x2F;log&#x2F;nginx nginx</span><br></pre></td></tr></table></figure></li>
<li>拷贝宿主机的nginx配置到容器内，指定目录<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker cp nginx:&#x2F;etc&#x2F;nginx &#x2F;etc&#x2F;nginx</span><br></pre></td></tr></table></figure></li>
<li>Dockerfile编写<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM nginx</span><br><span class="line"> COPY content &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line"> COPY conf &#x2F;etc&#x2F;nginx</span><br><span class="line"> VOLUME &#x2F;var&#x2F;log&#x2F;nginx&#x2F;log</span><br></pre></td></tr></table></figure></li>
<li>docker-compose.yml编写<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web:</span><br><span class="line">  image: nginx</span><br><span class="line">  volumes:</span><br><span class="line">   - .&#x2F;mysite.template:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;mysite.template</span><br><span class="line">  ports:</span><br><span class="line">   - &quot;8080:80&quot;</span><br><span class="line">  environment:</span><br><span class="line">   - NGINX_HOST&#x3D;foobar.com</span><br><span class="line">   - NGINX_PORT&#x3D;80</span><br><span class="line">  command: &#x2F;bin&#x2F;bash -c &quot;envsubst &lt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;mysite.template &gt; &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf &amp;&amp; exec nginx -g &#39;daemon off;&#39;&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>docker</tag>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title>如何创建GitHub Page</title>
    <url>/2019/10/29/create-github-page/</url>
    <content><![CDATA[<h2 id="新建项目"><a href="#新建项目" class="headerlink" title="新建项目"></a>新建项目</h2><p>首先在 GitHub 新建一个仓库（Repository），名称为 {username}.github.io，注意这个名比较特殊，必须要是 github.io 为后缀结尾的。比如 我 的 GitHub 用户名就叫 blanklin030，那我就新建一个 blanklin030.github.io，新建完成之后就可以进行后续操作了。</p>
<blockquote>
<blockquote>
<p>另外如果 GitHub 没有配置 SSH 连接的建议配置一下，这样后面在部署博客的时候会更方便。</p>
</blockquote>
</blockquote>
<h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p>首先在自己的电脑上安装 Node.js，下载地址：<a href="https://nodejs.org/zh-cn/download/，可以安装" target="_blank" rel="noopener">https://nodejs.org/zh-cn/download/，可以安装</a> Stable 版本。</p>
<p>安装完毕之后，确保环境变量配置好，能正常使用 npm 命令。</p>
<h2 id="安装-Hexo"><a href="#安装-Hexo" class="headerlink" title="安装 Hexo"></a>安装 Hexo</h2><p>接下来就需要安装 Hexo 了，这是一个博客框架，Hexo 官方还提供了一个命令行工具，用于快速创建项目、页面、编译、部署 Hexo 博客，所以在这之前我们需要先安装 Hexo 的命令行工具。</p>
<p>命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>安装完毕之后，确保环境变量配置好，能正常使用 hexo 命令。</p>
<h2 id="初始化项目"><a href="#初始化项目" class="headerlink" title="初始化项目"></a>初始化项目</h2><p>接下来我们使用 Hexo 的命令行创建一个项目，并将其在本地跑起来，整体跑通看看。<br>首先使用如下命令创建项目：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init &#123;name&#125;</span><br></pre></td></tr></table></figure>
<p>这里的 name 就是项目名，我这里要创建 blanklin 的博客，我就把项目取名为 blanklin 了，用了纯小写，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init blinklin</span><br></pre></td></tr></table></figure>
<p>这样 nightteam 文件夹下就会出现 Hexo 的初始化文件，包括 themes、scaffolds、source 等文件夹，这些内容暂且先不用管是做什么的，我们先知道有什么，然后一步步走下去看看都发生了什么变化。</p>
<p>接下来我们首先进入新生成的文件夹里面，然后调用 Hexo 的 generate 命令，将 Hexo 编译生成 HTML 代码，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure>
<p>可以看到输出结果里面包含了 js、css、font 等内容，并发现他们都处在了项目根目录下的 public 文件夹下面了。</p>
<p>然后我们利用 Hexo 提供的 serve 命令把博客在本地运行起来，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo serve</span><br></pre></td></tr></table></figure>
<p>运行之后命令行输出如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http:&#x2F;&#x2F;localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>接下来我们来将这个初始化的博客进行一下部署，放到 GitHub Pages 上面验证一下其可用性。成功之后我们可以再进行后续的修改，比如修改主题、修改页面配置等等。</p>
<p>那么怎么把这个页面部署到 GitHub Pages 上面呢，其实 Hexo 已经给我们提供一个命令，利用它我们可以直接将博客一键部署，不需要手动去配置服务器或进行其他的各项配置。</p>
<p>部署命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<p>在部署之前，我们需要先知道博客的部署地址，它需要对应 GitHub 的一个 Repository 的地址，这个信息需要我们来配置一下。</p>
<p>打开根目录下的 _config.yml 文件，找到 Deployment 这个地方，把刚才新建的 Repository 的地址贴过来，然后指定分支为 master 分支，最终修改为如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Deployment</span><br><span class="line">## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: &#123;git repo ssh address&#125;</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<p>另外我们还需要额外安装一个支持 Git 的部署插件，名字叫做 hexo-deployer-git，有了它我们才可以顺利将其部署到 GitHub 上面</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p>安装成功之后，执行部署命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<p>如果没有报错，那说明 hexo deploy 操作就做了两个动作，1 个是 build 文件到 public 目录，还有 1 个就是 git add &amp;&amp; git commit &amp;&amp; git push 后到 GitHub 仓库了。<br>这时候我们去 GitHub 上面看看 Hexo 上传了什么内容，打开之后可以看到 master 分支就可以看到其实就是把 public 目录 push 到 repository 了。</p>
<p>这时候可能就有人有疑问了，那我博客的源码也想放到 GitHub 上面怎么办呢？其实很简单，新建一个其他的分支就好了，比如我这边就新建了一个 source 分支，代表博客源码的意思。</p>
<p>具体的添加过程就很简单了，就是增加一个 source 分支，记录的博客的源码，参加如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">git init</span><br><span class="line">git checkout -b source</span><br><span class="line">git add -A</span><br><span class="line">git commit -m &quot;init blog&quot;</span><br><span class="line">git remote add origin git@github.com:&#123;username&#125;&#x2F;&#123;username&#125;.github.io.git</span><br><span class="line">git push origin source</span><br></pre></td></tr></table></figure>
<p>成功之后，可以到 GitHub 上再切换下默认分支，比如我就把默认的分支设置为了 source，当然不换也可以。</p>
<h2 id="配置站点信息"><a href="#配置站点信息" class="headerlink" title="配置站点信息"></a>配置站点信息</h2><p>下面我就以自己的站点 NightTeam 为例，修改一些基本的配置，比如站点名、站点描述等等。</p>
<p>修改根目录下的 _config.yml 文件，找到 Site 区域，这里面可以配置站点标题 title、副标题 subtitle 等内容、关键字 keywords 等内容，比如我的就修改为如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: NightTeam</span><br><span class="line">subtitle: 一个专注技术的组织</span><br><span class="line">description: 涉猎的主要编程语言为 Python、Rust、C++、Go，领域涵盖爬虫、深度学习、服务研发和对象存储等。</span><br><span class="line">keywords: &quot;Python, Rust, C++, Go, 爬虫, 深度学习, 服务研发, 对象存储&quot;</span><br><span class="line">author: NightTeam</span><br></pre></td></tr></table></figure>
<p>这里大家可以参照格式把内容改成自己的。</p>
<p>另外还可以设置一下语言，如果要设置为汉语的话可以将 language 的字段设置为 zh-CN，修改如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">language: zh-CN</span><br></pre></td></tr></table></figure>
<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><p>目前 Hexo 里面应用最多的主题基本就是 Next 主题了，个人感觉这个主题还是挺好看的，另外它支持的插件和功能也极为丰富，配置了这个主题，我们的博客可以支持更多的扩展功能，比如阅览进度条、中英文空格排版、图片懒加载等等。</p>
<p>那么首先就让我们来安装下 Next 这个主题吧，目前 Next 主题已经更新到 7.x 版本了，我们可以直接到 Next 主题的 GitHub Repository 上把这个主题下载下来。</p>
<p>主题的 GitHub 地址是：<a href="https://github.com/theme-next/hexo-theme-next，我们可以直接把" target="_blank" rel="noopener">https://github.com/theme-next/hexo-theme-next，我们可以直接把</a> master 分支 Clone 下来。</p>
<p>首先命令行进入到项目的根目录，执行如下命令即可：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-theme-next themes&#x2F;next</span><br></pre></td></tr></table></figure>
<p>执行完毕之后 Next 主题的源码就会出现在项目的 themes/next 文件夹下。</p>
<p>然后我们需要修改下博客所用的主题名称，修改项目根目录下的 _config.yml 文件，找到 theme 字段，修改为 next 即可，修改如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure>
<p>然后本地重新开启服务，访问刷新下页面，就可以看到 next 主题就切换成功了</p>
<h3 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h3><p>现在我们已经成功切换到 next 主题上面了，接下来我们就对主题进行进一步地详细配置吧，比如修改样式、增加其他各项功能的支持，下面逐项道来。</p>
<p>Next 主题内部也提供了一个配置文件，名字同样叫做 _config.yml，只不过位置不一样，它在 themes/next 文件夹下，Next 主题里面所有的功能都可以通过这个配置文件来控制，下文所述的内容都是修改的 themes/next/_config.yml 文件。</p>
<h4 id="样式"><a href="#样式" class="headerlink" title="样式"></a>样式</h4><p>Next 主题还提供了多种样式，风格都是类似黑白的搭配，但整个布局位置不太一样，通过修改配置文件的 scheme 字段即可，我选了 Pisces 样式，修改 _config.yml （注意是 themes/next/_config.yml 文件）如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scheme: Pisces</span><br><span class="line"># 大家可以自行根据喜好选择。</span><br><span class="line"># scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">#scheme: Gemini</span><br></pre></td></tr></table></figure>
<blockquote>
<p>还有很多其他的配置项，可自己参考修改，在这里就不一一概述了</p>
</blockquote>
<p>最后大家修改完配置后请<a href="https://blanklin030.github.io/2019/10/29/write-article/" target="_blank" rel="noopener">参考文档</a>继续学习如何创建文章。</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>docker ipv4 forwarding is disabled</title>
    <url>/2020/09/21/docker-ipv4-forword/</url>
    <content><![CDATA[<blockquote>
<p>warning ipv4 forwarding is disabled. networking will not work.  </p>
</blockquote>
<ul>
<li>起因<br>今天早上有个同学找过来问为什么xx平台502了，原谅笔者没有没有对该xx平台配置监控告警，原因是这个平台用户数太少。</li>
<li>进入服务器查询<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 查log</span><br><span class="line">docker logs xx</span><br><span class="line">2. 无报错log，查nginx》error.lo</span><br><span class="line">connection timeout...</span><br><span class="line">3. nginx提示连接超时了,ping服务</span><br><span class="line">curl -i http:&#x2F;&#x2F;ip:port&#x2F;api&#x2F;xx&#x2F;yy</span><br><span class="line">4. 给了200的返回码，去外网再ping，</span><br><span class="line">curl: (7) Failed to connect to ip port: Operation timed out</span><br></pre></td></tr></table></figure></li>
<li>结论，外网无法连通这个ip和端口<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 重启docker container</span><br><span class="line">sudo docker restart container_name</span><br><span class="line">WARNING: IPv4 forwarding is disabled. Networking will not work.</span><br></pre></td></tr></table></figure></li>
<li><p>docker network bridge<br><img src="/images/docker-bridge.png" alt="docker-bridge"></p>
<blockquote>
<p>由于宿主机的IP地址与容器veth pair的 IP地址均不在同一个网段，故仅仅依靠veth pair和namespace的技术，还不足以使宿主机以外的网络主动发现容器的存在。为了使外界可以访问容器中的进程，docker采用了端口绑定的方式，也就是通过iptables的NAT，将宿主机上的端口流量转发到容器内的端口上。<br>举例说明 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 创建容器，并将宿主机的3306端口绑定到容器的3306端口</span><br><span class="line">docker run -tid --name db -p 3306:3306 MySQL</span><br><span class="line">2. 宿主机上，可以通过iptables -t nat -L -n，查到一条DNAT规则</span><br><span class="line">DNAT tcp -- 0.0.0.0&#x2F;0 0.0.0.0&#x2F;0 tcp dpt:3306 to:172.17.0.5:3306</span><br><span class="line">3. 以上的172.17.0.5即为bridge模式下，创建的容器IP</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>开启 ip 转发</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo echo net.ipv4.ip_forward&#x3D;1 &gt;&gt; &#x2F;etc&#x2F;sysctl.d&#x2F;enable-ip-forward.conf</span><br><span class="line">或者</span><br><span class="line">sudo echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward</span><br></pre></td></tr></table></figure></li>
<li>重启 network 服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart network</span><br></pre></td></tr></table></figure></li>
<li>查看 network 服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sysctl net.ipv4.ip_forward</span><br></pre></td></tr></table></figure>
<blockquote>
<p>返回为“net.ipv4.ip_forward = 1”则表示成功了</p>
</blockquote>
</li>
<li>重启容器<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker restart container_name</span><br></pre></td></tr></table></figure></li>
<li>如果还提示上面的ipv4问题<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart docker.service</span><br></pre></td></tr></table></figure></li>
<li>删除容器，再run<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker rm -f xx</span><br><span class="line">sudo docker run -d --name xx image_name</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse集群cpu飙高问题排查</title>
    <url>/2022/12/08/clickhouse%E9%9B%86%E7%BE%A4cpu%E9%A3%99%E9%AB%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>clickhouse是分布式系统，一条查询sql会经过pipeline处理后通过后台的查询线程池开启多线程查询，而经常会收到cpu飙高告警，则是因为这条sql开启了系统所有的cpu资源（多个线程）进行计算</p>
<h3 id="告警图"><a href="#告警图" class="headerlink" title="告警图"></a>告警图</h3><p>如下图所示，提示cpu飙高<br><img src="/images/clickhouse/cpu_high/1.png" alt="clickhouse"><br>如下图所示，ganglia上展示了当时的cpu顶着线在跑<br><img src="/images/clickhouse/cpu_high/2.png" alt="clickhouse"></p>
<h3 id="system-query-log"><a href="#system-query-log" class="headerlink" title="system.query_log"></a>system.query_log</h3><blockquote>
<p><a href="https://clickhouse.com/docs/en/operations/system-tables/query_log" target="_blank" rel="noopener">地址</a>，该表包含了所有进入到ck的sql语句。<br>该表包含字段如下：</p>
<ul>
<li>type (Enum8) — 执行查询时的事件类型. 值:<ul>
<li>‘QueryStart’ = 1 — 查询成功启动.</li>
<li>‘QueryFinish’ = 2 — 查询成功完成.</li>
</ul>
</li>
<li>‘ExceptionBeforeStart’ = 3 — 查询执行前有异常.</li>
<li>‘ExceptionWhileProcessing’ = 4 — 查询执行期间有异常.</li>
<li>event_date (Date) — 查询开始日期.</li>
<li>event_time (DateTime) — 查询开始时间.</li>
<li>event_time_microseconds (DateTime64) — 查询开始时间（毫秒精度）.</li>
<li>query_start_time (DateTime) — 查询执行的开始时间.</li>
<li>query_start_time_microseconds (DateTime64) — 查询执行的开始时间（毫秒精度）.</li>
<li>query_duration_ms (UInt64) — 查询消耗的时间（毫秒）.</li>
<li>read_rows (UInt64) — 从参与了查询的所有表和表函数读取的总行数. 包括：普通的子查询, IN 和 JOIN的子查询. 对于分布式查询 read_rows 包括在所有副本上读取的行总数。 每个副本发送它的 read_rows 值，并且查询的服务器-发起方汇总所有接收到的和本地的值。 缓存卷不会影响此值。</li>
<li>read_bytes (UInt64) — 从参与了查询的所有表和表函数读取的总字节数. 包括：普通的子查询, IN 和 JOIN的子查询. 对于分布式查询 read_bytes 包括在所有副本上读取的字节总数。 每个副本发送它的 read_bytes 值，并且查询的服务器-发起方汇总所有接收到的和本地的值。 缓存卷不会影响此值。</li>
<li>written_rows (UInt64) — 对于 INSERT 查询，为写入的行数。 对于其他查询，值为0。</li>
<li>written_bytes (UInt64) — 对于 INSERT 查询时，为写入的字节数。 对于其他查询，值为0。</li>
<li>result_rows (UInt64) — SELECT 查询结果的行数，或INSERT 的行数。</li>
<li>result_bytes (UInt64) — 存储查询结果的RAM量.</li>
<li>memory_usage (UInt64) — 查询使用的内存.</li>
<li>query (String) — 查询语句.</li>
<li>exception (String) — 异常信息.</li>
<li>exception_code (Int32) — 异常码.</li>
<li>stack_trace (String) — Stack Trace. 如果查询成功完成，则为空字符串。</li>
<li>is_initial_query (UInt8) — 查询类型. 可能的值:<ul>
<li>1 — 客户端发起的查询.</li>
<li>0 — 由另一个查询发起的，作为分布式查询的一部分.</li>
</ul>
</li>
<li>user (String) — 发起查询的用户.</li>
<li>query_id (String) — 查询ID.</li>
<li>address (IPv6) — 发起查询的客户端IP地址.</li>
<li>port (UInt16) — 发起查询的客户端端口.</li>
<li>initial_user (String) — 初始查询的用户名（用于分布式查询执行）.</li>
<li>initial_query_id (String) — 运行初始查询的ID（用于分布式查询执行）.</li>
<li>initial_address (IPv6) — 运行父查询的IP地址.</li>
<li>initial_port (UInt16) — 发起父查询的客户端端口.</li>
<li>interface (UInt8) — 发起查询的接口. 可能的值:<ul>
<li>1 — TCP.</li>
<li>2 — HTTP.</li>
</ul>
</li>
<li>os_user (String) — 运行 clickhouse-client的操作系统用户名.</li>
<li>client_hostname (String) — 运行clickhouse-client 或其他TCP客户端的机器的主机名。</li>
<li>client_name (String) — clickhouse-client 或其他TCP客户端的名称。</li>
<li>client_revision (UInt32) — clickhouse-client 或其他TCP客户端的Revision。</li>
<li>client_version_major (UInt32) — clickhouse-client 或其他TCP客户端的Major version。</li>
<li>client_version_minor (UInt32) — clickhouse-client 或其他TCP客户端的Minor version。</li>
<li>client_version_patch (UInt32) — clickhouse-client 或其他TCP客户端的Patch component。</li>
<li>http_method (UInt8) — 发起查询的HTTP方法. 可能值:<ul>
<li>0 — TCP接口的查询.</li>
<li>1 — GET</li>
<li>2 — POST</li>
</ul>
</li>
<li>http_user_agent (String) — http请求的客户端参数</li>
<li>quota_key (String) — 在quotas 配置里设置的“quota key” （见 keyed).</li>
<li>revision (UInt32) — ClickHouse revision.</li>
<li>ProfileEvents (Map(String, UInt64))) — 不同指标的计数器 </li>
<li>Settings (Map(String, String)) — 当前请求里的setting部分参数</li>
<li>thread_ids (Array(UInt64)) — 参与查询的线程数.</li>
<li>Settings.Names (Array（String)) — 客户端运行查询时更改的设置的名称。 要启用对设置的日志记录更改，请将log_query_settings参数设置为1。</li>
<li>Settings.Values (Array（String)) — Settings.Names 列中列出的设置的值。</li>
</ul>
</blockquote>
<h3 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h3><ul>
<li>查询当前时间内耗cpu最高的sql前10条<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select initial_user, event_time, query,</span><br><span class="line">read_rows, read_bytes,</span><br><span class="line">written_rows, written_bytes,</span><br><span class="line">result_rows, result_bytes,</span><br><span class="line">memory_usage, length(thread_ids) as thread_count</span><br><span class="line">from system.query_log</span><br><span class="line">WHERE event_time &gt; &#39;2022-10-27 18:30:00&#39; AND event_time &lt; &#39;2022-10-27 18:35:00&#39; </span><br><span class="line">and initial_user&lt;&gt;&#39;default&#39;</span><br><span class="line">order by thread_count desc</span><br><span class="line">limit 10;</span><br></pre></td></tr></table></figure></li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>vscode代码自动提示利器eslint</title>
    <url>/2019/11/22/esLint/</url>
    <content><![CDATA[<h2 id="eslint安装"><a href="#eslint安装" class="headerlink" title="eslint安装"></a>eslint安装</h2><p>eslint：Find and fix problems in your JavaScript code</p>
<ul>
<li>打开Teminal，进入到你的项目根目录后，输入下面命令<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install eslint --save-dev</span><br></pre></td></tr></table></figure></li>
<li>vscode安装eslint插件<br>如上面截图的logo，请安装对应的eslint插件</li>
<li>验证安装成功<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;node_modules&#x2F;.bin&#x2F;eslint -v</span><br></pre></td></tr></table></figure></li>
<li>生成eslintrc.js配置文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;node_modules&#x2F;.bin&#x2F;eslint --init</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 下面是安装流程提示文字</span><br><span class="line">? How would you like to use ESLint? </span><br><span class="line">To check syntax and find problems</span><br><span class="line">? What type of modules does your project use? </span><br><span class="line">JavaScript modules (import&#x2F;export)</span><br><span class="line">? Which framework does your project use? </span><br><span class="line">Vue.js</span><br><span class="line">? Does your project use TypeScript? </span><br><span class="line">No</span><br><span class="line">? Where does your code run? </span><br><span class="line">Browser</span><br><span class="line">? What format do you want your config file to be in? </span><br><span class="line">JavaScript</span><br><span class="line">The config that you&#39;ve selected requires the following dependencies:</span><br></pre></td></tr></table></figure></li>
<li>最终生成eslintrc.js文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">module.exports &#x3D; &#123;</span><br><span class="line">    &quot;env&quot;: &#123;</span><br><span class="line">        &quot;browser&quot;: true,</span><br><span class="line">        &quot;es6&quot;: true</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;extends&quot;: [</span><br><span class="line">        &quot;eslint:recommended&quot; &#x2F;&#x2F; eslint</span><br><span class="line">    ],</span><br><span class="line">    &quot;globals&quot;: &#123;</span><br><span class="line">        &quot;Atomics&quot;: &quot;readonly&quot;,</span><br><span class="line">        &quot;SharedArrayBuffer&quot;: &quot;readonly&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;parserOptions&quot;: &#123;</span><br><span class="line">        &quot;ecmaVersion&quot;: 2018,</span><br><span class="line">        &quot;sourceType&quot;: &quot;module&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;plugins&quot;: [</span><br><span class="line">        &quot;vue&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;rules&quot;: &#123;</span><br><span class="line">        &quot;semi&quot;: [&quot;error&quot;, &quot;always&quot;],</span><br><span class="line">        &quot;quotes&quot;: [&quot;error&quot;, &quot;double&quot;],</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>eslintrc配置规则（rules）<br>“off” or 0 - turn the rule off<br>“warn” or 1 - turn the rule on as a warning (doesn’t affect exit code)<br>“error” or 2 - turn the rule on as an error (exit code will be 1)</p>
</blockquote>
</li>
<li>安装eslint-plugin-vue<br>Official ESLint plugin for Vue.js.<br>This plugin allows us to check the template and script of .vue files with ESLint.<br>Finds syntax errors.<br>Finds the wrong use of Vue.js Directives.<br>Finds the violation for Vue.js Style Guide.<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save-dev eslint-plugin-vue</span><br></pre></td></tr></table></figure>
++ 修改eslintrc.js文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; ... other options</span><br><span class="line">extends: [</span><br><span class="line">    &quot;plugin:vue&#x2F;essential&quot; &#x2F;&#x2F;eslint规则</span><br><span class="line">    &#39;plugin:vue&#x2F;recommended&#39; &#x2F;&#x2F;eslint-plugin-vue规则</span><br><span class="line">  ],</span><br></pre></td></tr></table></figure></li>
<li>安装eslint-loader<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install eslint-loader eslint-friendly-formatter --save-dev</span><br></pre></td></tr></table></figure>
++ 修改webpack配置<br>这样你的 .vue 文件会在开发期间每次保存时自动检验。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; webpack.base.config.js</span><br><span class="line">module.exports &#x3D; &#123;</span><br><span class="line">  &#x2F;&#x2F; ... other options</span><br><span class="line">  module: &#123;</span><br><span class="line">    rules: [</span><br><span class="line">      &#123;</span><br><span class="line">        test: &#x2F;\.(js|vue)$&#x2F;,</span><br><span class="line">        loader: &quot;eslint-loader&quot;,</span><br><span class="line">        exclude: &#x2F;node_modules&#x2F;</span><br><span class="line">        enforce: &quot;pre&quot;,</span><br><span class="line">        include: [resolve(&quot;src&quot;), resolve(&quot;test&quot;)],</span><br><span class="line">        options: &#123;</span><br><span class="line">          formatter: require(&quot;eslint-friendly-formatter&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>修改.vscode/settings.json<br>You have to configure the eslint.validate option of the extension to check .vue files because the extension targets only <em>.js or </em>.jsx files by default.<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;editor.formatOnSave&quot;: true, &#x2F;&#x2F;保存时自动格式化</span><br><span class="line">&quot;eslint.validate&quot;: [</span><br><span class="line">  &quot;javascript&quot;,</span><br><span class="line">  &quot;javascriptreact&quot;,</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;language&quot;: &quot;html&quot;,</span><br><span class="line">    &quot;autoFix&quot;: true</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;language&quot;: &quot;vue&quot;,</span><br><span class="line">    &quot;autoFix&quot;: true</span><br><span class="line">  &#125;</span><br><span class="line">],</span><br><span class="line">&quot;eslint.autoFixOnSave&quot;: true</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先推荐使用vscode这个编辑器来开发vuejs项目，最优秀的轻量级编辑器，迅速加载项目，即使你的项目里有数百个node_modules。<br>其实eslint可以帮助你解决日常开发中遇到的代码bug，有友好的提示效果。<br>vue官方推荐使用eslint-plugin-vue插件来兼容eslint对于vue代码的检查。<br>另外想要关闭eslint的检查，可以在文件顶部加入<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">You may use special comments to disable some warnings.</span><br><span class="line">Use &#x2F;&#x2F; eslint-disable-next-line to ignore the next line.</span><br><span class="line">Use &#x2F;* eslint-disable *&#x2F; to ignore all warnings in a file.</span><br></pre></td></tr></table></figure><br>参考地址如下：<br><a href="https://vue-loader-v14.vuejs.org/zh-cn/workflow/linting.html" target="_blank" rel="noopener">https://vue-loader-v14.vuejs.org/zh-cn/workflow/linting.html</a><br><a href="https://eslint.org/docs/user-guide/getting-started" target="_blank" rel="noopener">https://eslint.org/docs/user-guide/getting-started</a><br><a href="https://eslint.vuejs.org/user-guide/#faq" target="_blank" rel="noopener">https://eslint.vuejs.org/user-guide/#faq</a></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>vscode</tag>
        <tag>vuejs</tag>
        <tag>eslint</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊go环境安装及go.mod的使用</title>
    <url>/2019/12/05/go-mod-hello/</url>
    <content><![CDATA[<p>下面流程安装在<strong><em>unix（MacBook）环境</em></strong></p>
<h2 id="go的开发环境"><a href="#go的开发环境" class="headerlink" title="go的开发环境"></a>go的开发环境</h2><ul>
<li>安装go<blockquote>
<p>推荐使用go1.12+版本  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 安装homebrew：</span><br><span class="line">ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot;</span><br><span class="line">&#x2F;&#x2F; 安装go</span><br><span class="line">brew install go</span><br><span class="line">&#x2F;&#x2F; 将go的配置加入到系统环境</span><br><span class="line">vim ~&#x2F;.bask_profile</span><br><span class="line">&#x2F;&#x2F; 复制下面的内容</span><br><span class="line">export GOPATH&#x3D;&quot;$&#123;HOME&#125;&#x2F;.go&quot;</span><br><span class="line">export GOROOT&#x3D;&quot;$(brew --prefix golang)&#x2F;libexec&quot;</span><br><span class="line">export PATH&#x3D;$PATH:$GOROOT&#x2F;bin:$GOPATH&#x2F;bin</span><br><span class="line">export GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.io</span><br><span class="line">export GO111MODULE&#x3D;on</span><br><span class="line">&#x2F;&#x2F; 生效</span><br><span class="line">source ~&#x2F;.bash_profile</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li>GO111MODULE<br>在 1.12 版本之前，使用 Go modules 之前需要环境变量 GO111MODULE：<ul>
<li>GO111MODULE=off: 不使用 Module-aware mode。</li>
<li>GO111MODULE=on: 使用 Module-aware mode，不会去 GOPATH 下面查找依赖包。</li>
<li>GO111MODULE=auto或unset: Golang 自己检测是不是使用Module-aware mode。  <blockquote>
<p>根据官方描述在不设置GO111MODULE的情况下或者设为auto的时候，如果在当前目录或者父目录中有go.mod文件，那么就使用Module-aware mode， 而go1.12中，如果包位于GOPATH/src下，且GO111MODULE=auto, 即使有go.mod的存在，go仍然使用GOPATH mode:</p>
</blockquote>
</li>
</ul>
</li>
<li><p>GO PROXY<br>GOPROXY环境变量是伴随着modules而生，在go1.13中得到了增强，可以设置为逗号分隔的url列表来指定多个代理，其默认值为<a href="https://proxy.golang.org,direct。" target="_blank" rel="noopener">https://proxy.golang.org,direct。</a><br>direct：表示直接连接，所有direct后面逗号隔开都proxy都不会被使用。</p>
<blockquote>
<p>这里可以设置GOPROXY=<a href="https://goproxy.io" target="_blank" rel="noopener">https://goproxy.io</a> </p>
</blockquote>
</li>
<li><p>go env命令查看所有go的系统环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GO111MODULE&#x3D;&quot;on&quot;</span><br><span class="line">GOARCH&#x3D;&quot;amd64&quot;</span><br><span class="line">GOBIN&#x3D;&quot;&quot;</span><br><span class="line">GOCACHE&#x3D;&quot;&#x2F;Users&#x2F;xx&#x2F;Library&#x2F;Caches&#x2F;go-build&quot;</span><br><span class="line">GOENV&#x3D;&quot;&#x2F;Users&#x2F;xx&#x2F;Library&#x2F;Application Support&#x2F;go&#x2F;env&quot;</span><br><span class="line">GOEXE&#x3D;&quot;&quot;</span><br><span class="line">GOFLAGS&#x3D;&quot;&quot;</span><br><span class="line">GOHOSTARCH&#x3D;&quot;amd64&quot;</span><br><span class="line">GOHOSTOS&#x3D;&quot;darwin&quot;</span><br><span class="line">GOOS&#x3D;&quot;darwin&quot;</span><br><span class="line">GOPATH&#x3D;&quot;&#x2F;Users&#x2F;xx&#x2F;Documents&#x2F;go&quot;</span><br><span class="line">&#x2F;&#x2F; 省略其他的</span><br></pre></td></tr></table></figure>
<h2 id="go-mod的使用"><a href="#go-mod的使用" class="headerlink" title="go.mod的使用"></a>go.mod的使用</h2></li>
<li>创建项目<br>在GOPATH目录之外任意创建一个项目<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; GOPATH&#x3D;&quot;&#x2F;Users&#x2F;xx&#x2F;Documents&#x2F;go&quot;</span><br><span class="line">cd &#x2F;Users&#x2F;xx&#x2F;Documents&#x2F;code</span><br><span class="line">mkdir hello-go-mod</span><br></pre></td></tr></table></figure></li>
<li>初始化go.mod<br>进入到项目根目录<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;Users&#x2F;xx&#x2F;Documents&#x2F;code&#x2F;hello-go-mod</span><br><span class="line">go mod init hello-go-mod</span><br><span class="line">&#x2F;&#x2F;提示创建成功： go: creating new go.mod: module hello-go-mod</span><br><span class="line">ll </span><br><span class="line">&#x2F;&#x2F; 看到根目录下多了go.mod文件</span><br></pre></td></tr></table></figure></li>
<li>go run触发modules工作<br>在项目的根目录下创建一个main.go文件，复制下面的内容到文件里<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import(</span><br><span class="line">    &quot;fmt&quot;</span><br><span class="line">    &quot;github.com&#x2F;valyala&#x2F;fasthttp&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">   fmt.Print(&quot;hello go mod&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<strong><em>go run main.go</em></strong><br>发现项目目录下多了一个 go.sum<br>go.sum用来记录每个 package 的版本和哈希值。<br>go.mod 文件正常情况会包含 module 和 require 模块，除此之外还可以包含 replace 和 exclude 模块</li>
</ul>
<h2 id="调教GoLang"><a href="#调教GoLang" class="headerlink" title="调教GoLang"></a>调教GoLang</h2><ol>
<li>开启go-mod<br><img src="/images/go-mod.png" alt="go-mod"></li>
</ol>
<h2 id="golint使用"><a href="#golint使用" class="headerlink" title="golint使用"></a>golint使用</h2><blockquote>
<p>目录cd到$GOPATH/src/github.com  </p>
</blockquote>
<ul>
<li>clone golint<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;lint.git</span><br></pre></td></tr></table></figure></li>
<li>clone gotool<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;tools.git</span><br></pre></td></tr></table></figure></li>
<li>go install<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd lint&#x2F;golint</span><br><span class="line">go install</span><br></pre></td></tr></table></figure></li>
<li><p>调教GoLang</p>
<ul>
<li>配置golint扩展<br><img src="/images/golint.png" alt="go-lint"></li>
<li>配置golint快捷键<br><img src="/images/golint-shortcut.png" alt="go-lint-shortcut"><blockquote>
<p>现在可以在GoLang中使用option+command+l 进行lint了</p>
</blockquote>
</li>
</ul>
</li>
<li><p>错误提示<br><a href="/images/gotip.png">go-error</a><br>错误参考：<br><a href="https://github.com/golang/lint/tree/master/testdata" target="_blank" rel="noopener">https://github.com/golang/lint/tree/master/testdata</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>前端基于docker的生产环境部署方案</title>
    <url>/2020/07/20/frontend-docker-product/</url>
    <content><![CDATA[<ul>
<li>docker安装<ul>
<li>brew install  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install docker</span><br></pre></td></tr></table></figure></li>
<li>Docker Desktop install<br><a href="https://hub.docker.com/editions/community/docker-ce-desktop-mac/" target="_blank" rel="noopener">download</a></li>
</ul>
</li>
<li>Dockerfile  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基础镜像</span><br><span class="line">FROM node as build</span><br><span class="line"></span><br><span class="line"># 设置工作目录</span><br><span class="line">WORKDIR &#x2F;app</span><br><span class="line"></span><br><span class="line"># 把 &#96;&#x2F;app&#x2F;node_modules&#x2F;.bin&#96; 加到$PATH中</span><br><span class="line">ENV PATH &#x2F;app&#x2F;node_modules&#x2F;.bin:$PATH</span><br><span class="line"></span><br><span class="line"># 安装并缓存应用依赖</span><br><span class="line">COPY .&#x2F;package.json &#x2F;app&#x2F;package.json</span><br><span class="line">COPY .&#x2F;package-lock.json &#x2F;app&#x2F;package-lock.json</span><br><span class="line"># 切换npm源</span><br><span class="line">RUN npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org</span><br><span class="line"># 安装npm包</span><br><span class="line">RUN npm install</span><br><span class="line"></span><br><span class="line"># 编译应用</span><br><span class="line">COPY . &#x2F;app</span><br><span class="line">RUN npm run build</span><br><span class="line"></span><br><span class="line"># 删除无用文件</span><br><span class="line">RUN rm -fr &#x2F;app&#x2F;src</span><br><span class="line">RUN rm -fr &#x2F;app&#x2F;public</span><br><span class="line">RUN rm -fr &#x2F;app&#x2F;node_modules</span><br><span class="line"></span><br><span class="line"># production environment</span><br><span class="line">FROM nginx</span><br><span class="line">COPY --from&#x3D;build &#x2F;app&#x2F;build &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br><span class="line">COPY .&#x2F;nginx.conf &#x2F;etc&#x2F;nginx&#x2F;conf.d</span><br><span class="line">EXPOSE 8082</span><br><span class="line">CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line">+ nginx.conf配置</span><br></pre></td></tr></table></figure>
<p>server {</p>
<p>  listen 8082;</p>
<h1 id="访问根目录强制到index-html"><a href="#访问根目录强制到index-html" class="headerlink" title="访问根目录强制到index.html"></a>访问根目录强制到index.html</h1><p>  location / {<br>    root   /usr/share/nginx/html;<br>    index  index.html index.htm;<br>    try_files $uri $uri/ /index.html;<br>  }</p>
<h1 id="访问v1前缀都反向代理到server端地址"><a href="#访问v1前缀都反向代理到server端地址" class="headerlink" title="访问v1前缀都反向代理到server端地址"></a>访问v1前缀都反向代理到server端地址</h1><p>  location ~ ^/v1/ {<br>    rewrite ^/(.*)$ /$1 break;<br>    proxy_pass <a href="http://server:8081" target="_blank" rel="noopener">http://server:8081</a>;<br>  }<br>}<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+ Makefile</span><br></pre></td></tr></table></figure><br>.PHONY: clean build</p>
<p>SHELL := /bin/bash</p>
<p>NAME=aere<br>VERSION=0.1<br>MODULE=git.xxx.com/xx/frontend<br>BUILD_DATE=$(shell date ‘+%Y%m%d’)<br>BUILD_VERSION=$(shell git log -1 —pretty=format:%h)<br>REGISTRY=10.xx.xx.17:8001</p>
<p>release:<br>    docker build —no-cache -f Dockerfile -t $(REGISTRY)/$(NAME)/frontend:$(BUILD_DATE)-$(BUILD_VERSION) .<br>    docker tag $(REGISTRY)/$(NAME)/frontend:$(BUILD_DATE)-$(BUILD_VERSION) $(REGISTRY)/$(NAME)/frontend</p>
<p>push:<br>    docker push $(REGISTRY)/$(NAME)/frontend:$(BUILD_DATE)-$(BUILD_VERSION)<br>    docker push $(REGISTRY)/$(NAME)/frontend<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+ how to use  </span><br><span class="line"></span><br><span class="line">    + 本地开发环境编排容器</span><br></pre></td></tr></table></figure><br>    make release<br>    make push<br>    <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+ 生产环境运行docker</span><br></pre></td></tr></table></figure></p>
<pre><code>    # 注意docker run的参数,具体参数定义自行查找
    docker run -it --rm -p 8082:8082 10.xx.xx.17:8001/aere/frontend
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ 浏览器访问</span><br></pre></td></tr></table></figure>
http://ip:8082
```
</code></pre><ul>
<li>问题与思考<ul>
<li>npm打包太慢，每次build都得好几分钟，不知道各位有没有好办法进行优化</li>
<li>可以使用docker compose进行编排，就不需要每次在生产环境输入长串命令</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>grafana开发环境搭建（MacBook）</title>
    <url>/2020/05/12/grafana-develop-environment/</url>
    <content><![CDATA[<ul>
<li>安装go<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install go</span><br></pre></td></tr></table></figure></li>
<li>安装nodejs<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install nodejs</span><br><span class="line"># npm切换淘宝源</span><br><span class="line">npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org</span><br></pre></td></tr></table></figure></li>
<li>安装yarn<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g yarn</span><br></pre></td></tr></table></figure></li>
<li>clone项目<br>git项目地址：<a href="https://github.com/grafana/grafana" target="_blank" rel="noopener">https://github.com/grafana/grafana</a><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go get github.com&#x2F;grafana&#x2F;grafana</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果无法get下来，就直接clone 项目后，放到$GOPATH/src/github.com/grafana/grafana</p>
</blockquote>
</li>
<li>前端环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd $GOPATH&#x2F;src&#x2F;github.com&#x2F;grafana&#x2F;grafana</span><br><span class="line">npm install -g node-gyp</span><br><span class="line"># 安装依赖</span><br><span class="line">yarn install --pure-lockfile</span><br><span class="line"># 执行编译</span><br><span class="line">yarn start</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编译完成后，在public文件夹会看到多了个build文件夹</p>
</blockquote>
</li>
<li>后端环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd $GOPATH&#x2F;src&#x2F;github.com&#x2F;grafana&#x2F;grafana</span><br><span class="line">go run build.go setup</span><br><span class="line">go run build.go build</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编译完成后，会看到多了个bin文件夹</p>
</blockquote>
</li>
<li><p>运行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;grafana-server start</span><br></pre></td></tr></table></figure>
</li>
<li><p>打包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go run build.go build package</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i grafana_xxxx.deb</span><br><span class="line">&#x2F;&#x2F; 项目文件</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;grafana</span><br><span class="line">&#x2F;&#x2F; 配置文件</span><br><span class="line">&#x2F;etc&#x2F;grafana&#x2F;grafana.ini</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title>grafana持久化用户操作日志</title>
    <url>/2020/05/20/grafana-open-log-file/</url>
    <content><![CDATA[<blockquote>
<p>Grafana v6.6.2 (3fa63cfc34)</p>
</blockquote>
<ul>
<li>[log]<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Either &quot;console&quot;, &quot;file&quot;, &quot;syslog&quot;. Default is console and file</span><br><span class="line"># Use space to separate multiple modes, e.g. &quot;console file&quot;</span><br><span class="line">mode &#x3D; console file</span><br></pre></td></tr></table></figure></li>
<li>[paths]<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Directory where grafana can store logs</span><br><span class="line">logs &#x3D; data&#x2F;log</span><br></pre></td></tr></table></figure></li>
<li><p>[server]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Path to where grafana can store temp files, sessions, and the sqlite3 db (if that is used)</span><br><span class="line">data &#x3D; data</span><br><span class="line"># Log web requests</span><br><span class="line">router_logging &#x3D; false</span><br></pre></td></tr></table></figure>
</li>
<li><p>docker启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker run -d --name grafana-log   \</span><br><span class="line">-p 3000:3000 \</span><br><span class="line">-e GF_LOG_MODE&#x3D;&quot;console file&quot; \</span><br><span class="line">-e GF_PATHS_LOGS&#x3D;&#39;&#x2F;var&#x2F;log&#x2F;grafana&#39;   \</span><br><span class="line">-e GF_SERVER_ROUTER_LOGGING&#x3D;true \</span><br><span class="line">-v &#x2F;Users&#x2F;blank&#x2F;grafana:&#x2F;var&#x2F;lib&#x2F;grafana   \</span><br><span class="line">-v &#x2F;Users&#x2F;blank&#x2F;grafana&#x2F;log:&#x2F;var&#x2F;log&#x2F;grafana   \</span><br><span class="line">grafana</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果错误提示：【Failed to start grafana. error: failed to initialize file handler: open /var/log/grafana/grafana.log: permission denied】请配置目录/Users/blank/grafana权限为777</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title>grafana迁移sqlite3到mysql</title>
    <url>/2020/05/12/grafana-sqlite3-mysql/</url>
    <content><![CDATA[<ul>
<li>grafana版本<br>生产环境：Grafana v6.6.2<br>本地docker安装相同版本：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker run -d --name grafana-662-1 \</span><br><span class="line">-p 3000:3000 \</span><br><span class="line">-e GF_DATABASE_TYPE&#x3D;mysql   \</span><br><span class="line">-e GF_DATABASE_HOST&#x3D;ip:port   \</span><br><span class="line">-e GF_DATABASE_NAME&#x3D;grafana   \</span><br><span class="line">-e GF_DATABASE_USER&#x3D;grafana   \</span><br><span class="line">-e GF_DATABASE_PASSWORD&#x3D;mysql   \</span><br><span class="line">-e GF_DATABASE_URL&#x3D;mysql:&#x2F;&#x2F;grafana:pwd@ip:port&#x2F;grafana   \</span><br><span class="line">-v &#x2F;data1&#x2F;docker&#x2F;grafana:&#x2F;var&#x2F;lib&#x2F;grafana   \</span><br><span class="line">grafana&#x2F;grafana:6.6.2</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>-e GF_xx，这个xx对应的是conf/grafana.ini(默认是default.ini)的[xx]</p>
</blockquote>
<p><img src="/images/grafana-mysql.png" alt="grafana-mysql"></p>
<blockquote>
<p>以上是用docker方式配置mysql启动grafana</p>
</blockquote>
<ul>
<li><p>确认mysql的35个表已经创建成功，暂停grafana</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker stop $(sudo docker ps -a | grep grafana-662-1 | awk &#39;&#123;print $1&#125;&#39;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>从本地mysql数据库导出表结构到生产环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p -D grafana &gt; grafana.sql</span><br></pre></td></tr></table></figure></li>
<li>生产环境导入表结构<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE DATABASE grafana CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;</span><br><span class="line">mysql -uroot -p -D grafana &lt; grafana.sql</span><br></pre></td></tr></table></figure></li>
<li>另存脚本sqlitedump.sh<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">DB&#x3D;$1</span><br><span class="line">TABLES&#x3D;$(sqlite3 $DB .tables | sed -r &#39;s&#x2F;(\S+)\s+(\S)&#x2F;\1\n\2&#x2F;g&#39; | grep -v migration_log)</span><br><span class="line">for t in $TABLES; do</span><br><span class="line">    echo &quot;TRUNCATE TABLE $t;&quot;</span><br><span class="line">done</span><br><span class="line">for t in $TABLES; do</span><br><span class="line">    echo -e &quot;.mode insert $t\nselect * from $t;&quot;</span><br><span class="line">done | sqlite3 $DB</span><br></pre></td></tr></table></figure></li>
<li><p>找到grafana.db文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data1&#x2F;docker&#x2F;grafana</span><br><span class="line">sh sqlitedump.sh grafana.db &gt; insert.sql</span><br></pre></td></tr></table></figure>
</li>
<li><p>生产环境导入insert.sql</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p -D grafana &lt; 生产环境导入insert.sql</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动grafana的docker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker start $(sudo docker ps -a | grep grafana-662-1 | awk &#39;&#123;print $1&#125;&#39;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证<br>打开web进行验证  </p>
</li>
<li><p>sqlite_master表</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sqlite3存在系统表sqlite_master,结构如下：</span><br><span class="line">sqlite_master(</span><br><span class="line">    type TEXT,      #类型:table-表,index-索引,view-视图</span><br><span class="line">    name TEXT,      #名称:表名,索引名,视图名</span><br><span class="line">    tbl_name TEXT,</span><br><span class="line">    rootpage INTEGER,</span><br><span class="line">    sql TEXT</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
</li>
<li><p>slite3转mysql的python3脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line">import json</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class Sqlite3ToMysql():</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        dir &#x3D; &quot;grafana.db&quot;</span><br><span class="line">        conn &#x3D; sqlite3.connect(dir)</span><br><span class="line">        self.cur &#x3D; conn.cursor()</span><br><span class="line"></span><br><span class="line">    def get_table_list(self):</span><br><span class="line">        self.cur.execute(&quot;select NAME from SQLITE_MASTER where TYPE&#x3D;&#39;table&#39; order by NAME;&quot;)</span><br><span class="line">        rows &#x3D; self.cur.fetchall()</span><br><span class="line">        return rows</span><br><span class="line"></span><br><span class="line">    def get_table_column(self, tableName):</span><br><span class="line">        self.cur.execute(&quot;pragma table_info(&#39;&#123;&#125;&#39;);&quot;.format(tableName))</span><br><span class="line">        rows &#x3D; self.cur.fetchall()</span><br><span class="line">        list &#x3D; []</span><br><span class="line">        for (columnID, columnName, columnType,columnNotNull, columnDefault, columnPK) in rows:</span><br><span class="line">            dict &#x3D; &#123;</span><br><span class="line">                &quot;name&quot;: columnName,</span><br><span class="line">                &quot;type&quot;: columnType,</span><br><span class="line">                &quot;null&quot;: &quot;NOT NULL&quot; if columnNotNull else &quot;&quot;,</span><br><span class="line">                &quot;default&quot;: &quot;default &#39;&#123;&#125;&#39;&quot;.format(columnDefault) if columnDefault else &quot;&quot;,</span><br><span class="line">                &quot;pk&quot;: columnPK,</span><br><span class="line">            &#125;</span><br><span class="line">            list.append(dict)</span><br><span class="line">        return list</span><br><span class="line"></span><br><span class="line">    def get_table(self, tableName):</span><br><span class="line">        self.cur.execute(&quot;SELECT * FROM &#96;&#123;&#125;&#96;;&quot;.format(tableName))</span><br><span class="line">        rows &#x3D; self.cur.fetchall()</span><br><span class="line">        return rows</span><br><span class="line"></span><br><span class="line">    def get_table_index(self, tableName):</span><br><span class="line">        sql &#x3D; &quot;select sql from sqlite_master where tbl_name&#x3D;&#39;&#123;&#125;&#39; and type&#x3D;&#39;index&#39;;&quot;.format(tableName)</span><br><span class="line">        self.cur.execute(sql)</span><br><span class="line">        rows &#x3D; self.cur.fetchall()</span><br><span class="line">        if len(rows) &#x3D;&#x3D; 0:</span><br><span class="line">            return &#123;&#125;</span><br><span class="line">        list &#x3D; []</span><br><span class="line">        need &#x3D; []</span><br><span class="line">        for row in rows:</span><br><span class="line">            value &#x3D; str(row[0])</span><br><span class="line">            value &#x3D; str.replace(value, &quot;CREATE INDEX&quot;, &quot;KEY&quot;)</span><br><span class="line">            value &#x3D; str.replace(value, &quot;CREATE UNIQUE INDEX&quot;, &quot;UNIQUE KEY&quot;)</span><br><span class="line">            value &#x3D; str.replace(value, &quot;ON &#96;&#123;&#125;&#96;&quot;.format(tableName), &quot;&quot;)</span><br><span class="line">            matchObj &#x3D; re.findall(r&quot;KEY\s*&#96;.*&#96;\s*\((.*)\)&quot;, value)</span><br><span class="line">            if len(matchObj) &gt; 0:</span><br><span class="line">                tmp &#x3D; matchObj[0].split(&quot;,&quot;)</span><br><span class="line">                for i in tmp:</span><br><span class="line">                    i &#x3D; str.replace(i, &quot;&#96;&quot;, &quot;&quot;)</span><br><span class="line">                    need.append(i)</span><br><span class="line">            list.append(&quot;  &quot;+value)</span><br><span class="line">        return &#123;&quot;sql&quot;: &quot;,\n&quot;.join(list) + &quot;,\n&quot;, &quot;need&quot;: need&#125;</span><br><span class="line"></span><br><span class="line">    def ddl(self):</span><br><span class="line">        handle &#x3D; open(&quot;ddl.sql&quot;,&quot;w&quot;)</span><br><span class="line">        rows &#x3D; self.get_table_list()</span><br><span class="line">        for (tableName,) in rows:</span><br><span class="line">            handle.write(&quot;DROP TABLE IF EXISTS &#96;&#123;&#125;&#96;;\n&quot;.format(tableName))</span><br><span class="line">            handle.write(&quot;CREATE TABLE &#96;&#123;&#125;&#96;(\n&quot;.format(tableName))</span><br><span class="line">            tmp &#x3D; self.get_table_column(tableName)</span><br><span class="line">            pk &#x3D; &quot;&quot;</span><br><span class="line">            indexTmp &#x3D; self.get_table_index(tableName)</span><br><span class="line">            for item in tmp:</span><br><span class="line">                # 对索引字段为text需要指定长度</span><br><span class="line">                typeStr &#x3D; item[&quot;type&quot;]</span><br><span class="line">                if len(indexTmp.keys()) &gt; 0 and len(indexTmp[&quot;need&quot;]) &gt; 0 and typeStr &#x3D;&#x3D; &#39;TEXT&#39; and indexTmp[&quot;need&quot;].count(item[&quot;name&quot;]) &gt; 0:</span><br><span class="line">                    typeStr &#x3D; &quot;varchar(250)&quot;</span><br><span class="line">                handle.write(&quot;  &#96;&#123;name&#125;&#96; &#123;type&#125; &#123;null&#125; &#123;default&#125;,\n&quot;.format(</span><br><span class="line">                    name&#x3D;item[&quot;name&quot;],</span><br><span class="line">                    type&#x3D;typeStr,</span><br><span class="line">                    null&#x3D;item[&quot;null&quot;],</span><br><span class="line">                    default&#x3D;item[&quot;default&quot;],</span><br><span class="line">                ))</span><br><span class="line">                if item[&quot;pk&quot;]:</span><br><span class="line">                    pk &#x3D; item[&quot;name&quot;]</span><br><span class="line">            if len(indexTmp.keys()) &#x3D;&#x3D; 0:</span><br><span class="line">                continue</span><br><span class="line">            else:</span><br><span class="line">                handle.write(indexTmp[&quot;sql&quot;])</span><br><span class="line">            if (len(pk) &gt; 0):</span><br><span class="line">                handle.write(&quot;  PRIMARY KEY (&#96;&#123;&#125;&#96;)\n&quot;.format(pk))</span><br><span class="line">            handle.write(&quot;) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 COLLATE&#x3D;utf8mb4_unicode_ci;\n\n&quot;)</span><br><span class="line">        handle.close()</span><br><span class="line"></span><br><span class="line">    def dml(self):</span><br><span class="line">        handle &#x3D; open(&quot;dml.sql&quot;,&quot;w&quot;)</span><br><span class="line">        rows &#x3D; self.get_table_list()</span><br><span class="line">        for (tableName,) in rows:</span><br><span class="line">            list &#x3D; self.get_table(tableName)</span><br><span class="line">            if len(list) &#x3D;&#x3D; 0:</span><br><span class="line">                continue</span><br><span class="line">            handle.write(&quot;INSERT INTO &#96;&#123;&#125;&#96; VALUES \n&quot;.format(tableName))</span><br><span class="line">            itemList &#x3D; []</span><br><span class="line">            for item in list:</span><br><span class="line">                valueList &#x3D; []</span><br><span class="line">                for value in item:</span><br><span class="line">                    if type(value) &#x3D;&#x3D; bytes:</span><br><span class="line">                        value &#x3D; value.decode(&quot;utf-8&quot;)</span><br><span class="line">                    if type(value) in [int, float, bool]:</span><br><span class="line">                        value &#x3D; &quot;&#39;&quot; + str(value) + &quot;&#39;&quot;</span><br><span class="line">                    elif type(value) in [str]:</span><br><span class="line">                        value &#x3D; &quot;&#39;&quot; + value + &quot;&#39;&quot;</span><br><span class="line">                    elif type(value) in [dict, list, tuple, set]:</span><br><span class="line">                        value &#x3D; &quot;&#39;&quot; + json.dumps(value) + &quot;&#39;&quot;</span><br><span class="line">                    elif value is None:</span><br><span class="line">                        value &#x3D; &quot;&#39;&#39;&quot;</span><br><span class="line">                    valueList.append(value)</span><br><span class="line">                strTmp &#x3D; &quot;(&quot; + &quot;,&quot; . join(valueList) + &quot;)&quot;</span><br><span class="line">                itemList.append(strTmp)</span><br><span class="line">            handle.write(&quot;,&quot;.join(itemList))</span><br><span class="line">            handle.write(&quot;\n\n&quot;)</span><br><span class="line">        handle.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    obj &#x3D; Sqlite3ToMysql()</span><br><span class="line">    obj.ddl()</span><br><span class="line">    obj.dml()</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7下安装mysql5.7</title>
    <url>/2020/05/13/install-mysql/</url>
    <content><![CDATA[<h2 id="使用rpm包方式安装mysql"><a href="#使用rpm包方式安装mysql" class="headerlink" title="使用rpm包方式安装mysql"></a>使用rpm包方式安装mysql</h2><ul>
<li>卸载旧rpm包<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qa |grep -i mysql</span><br><span class="line">MySQL-client-5.6.23-1.sles11.x86_64</span><br><span class="line">MySQL-server-5.6.23-1.sles11.x86_64</span><br><span class="line">MySQL-shared-5.6.23-1.sles11.x86_64</span><br><span class="line">MySQL-devel-5.6.23-1.sles11.x86_64</span><br><span class="line">————————————————</span><br><span class="line">&#x2F;&#x2F; 逐个卸载</span><br><span class="line">rpm -e --nodeps MySQL-client-5.6.23-1.sles11.x86_64</span><br><span class="line">rpm -e --nodeps MySQL-server-5.6.23-1.sles11.x86_64</span><br><span class="line">rpm -e --nodeps MySQL-shared-5.6.23-1.sles11.x86_64</span><br><span class="line">rpm -e --nodeps MySQL-devel-5.6.23-1.sles11.x86_64</span><br><span class="line">&#x2F;&#x2F; 确认卸载完成</span><br><span class="line">rpm -qa |grep -i mysql</span><br><span class="line">&#x2F;&#x2F;my.cnf也可以删了</span><br><span class="line">rm -fr &#x2F;etc&#x2F;my.cnf</span><br><span class="line">&#x2F;&#x2F;为空</span><br></pre></td></tr></table></figure></li>
<li>下载rpm包<br><a href="http://repo.mysql.com/" target="_blank" rel="noopener">地址1</a><br><a href="https://centos.pkgs.org/7/mysql-5.7-x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpm.html" target="_blank" rel="noopener">地址2</a><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;repo.mysql.com&#x2F;mysql57-community-release-fc27.rpm</span><br></pre></td></tr></table></figure></li>
<li>安装rpm包<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rpm -ivh mysql57-community-release-fc27.rpm</span><br></pre></td></tr></table></figure></li>
<li>查看yum repo源<blockquote>
<p>会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo</p>
</blockquote>
</li>
<li>install mysql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install mysql-server</span><br></pre></td></tr></table></figure></li>
<li>查看mysql安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep mysql</span><br></pre></td></tr></table></figure>
<blockquote>
<p>rpm -qa | grep mysql-community<br>mysql-community-server-5.7.27-2.el7.x86_64<br>mysql-community-release-el7-5.noarch<br>mysql-community-libs-5.7.27-2.el7.x86_64<br>mysql-community-common-57.27-2.el7.x86_64<br>mysql-community-devel-5.7.27-2.el7.x86_64<br>mysql-community-client-5.7.27-2.el7.x86_64</p>
</blockquote>
</li>
</ul>
<h2 id="使用源码安装mysql"><a href="#使用源码安装mysql" class="headerlink" title="使用源码安装mysql"></a>使用源码安装mysql</h2><ul>
<li><p>获取源码安装包</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget  https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;Downloads&#x2F;MySQL-5.7&#x2F;mysql-boost-5.7.20.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装系统所需依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y cmake gcc-c++ gcc ncurses-devel perl-Data-Dumper boost boost-doc boost-devel</span><br></pre></td></tr></table></figure></li>
<li>创建mysql用户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd mysql  -s &#x2F;sbin&#x2F;nologin</span><br><span class="line">mkdir -pv &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata</span><br><span class="line">mkdir -pv &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;conf</span><br><span class="line">chown -R mysql:mysql &#x2F;usr&#x2F;local&#x2F;mysql</span><br></pre></td></tr></table></figure></li>
<li>删除mariadbd的my.cnf文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -fr &#x2F;etc&#x2F;my.cnf</span><br></pre></td></tr></table></figure></li>
<li>解压源码包并安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf mysql-boost-5.7.20.tar.gz</span><br><span class="line"></span><br><span class="line">cmake \</span><br><span class="line">-DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql \</span><br><span class="line">-DMYSQL_DATADIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata \</span><br><span class="line">-DSYSCONFDIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;conf \</span><br><span class="line">-DMYSQL_USER&#x3D;mysql \</span><br><span class="line">-DWITH_MYISAM_STORAGE_ENGINE&#x3D;1 \</span><br><span class="line">-DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 \</span><br><span class="line">-DMYSQL_UNIX_ADDR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mysql.sock \</span><br><span class="line">-DMYSQL_TCP_PORT&#x3D;3306 \</span><br><span class="line">-DEXTRA_CHARSETS&#x3D;all \</span><br><span class="line">-DDEFAULT_CHARSET&#x3D;utf8 \</span><br><span class="line">-DDEFAULT_COLLATION&#x3D;utf8_general_ci \</span><br><span class="line">-DWITH_DEBUG&#x3D;0 \</span><br><span class="line">-DMYSQL_MAINTAINER_MODE&#x3D;0 \</span><br><span class="line">-DWITH_SSL:STRING&#x3D;bundled \</span><br><span class="line">-DWITH_ZLIB:STRING&#x3D;bundled \</span><br><span class="line">-DDOWNLOAD_BOOST&#x3D;1 \</span><br><span class="line">-DWITH_BOOST&#x3D;.&#x2F;boost</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure></li>
<li>创建my.cnf<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.cnf</span><br><span class="line"># 复制下面内容</span><br><span class="line">[mysqld]</span><br><span class="line">datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata  </span><br><span class="line">socket&#x3D;&#x2F;tmp&#x2F;mysql.sock</span><br></pre></td></tr></table></figure></li>
<li><p>把mysql添加到系统服务并设置开机启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld</span><br><span class="line">chmod +x &#x2F;etc&#x2F;init.d&#x2F;mysqld</span><br><span class="line">chkconfig --add mysqld</span><br><span class="line">chkconfig mysqld on</span><br><span class="line">cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F; &#x2F;usr&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化mysql</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;version &lt;5.7</span><br><span class="line">mysql_install_db</span><br><span class="line">&#x2F;&#x2F;version &gt;&#x3D;5.7</span><br><span class="line">mysqld --initialize --user&#x3D;mysql --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql --datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata</span><br></pre></td></tr></table></figure></li>
<li>修改my.cnf<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.cnf</span><br><span class="line">&#x2F;&#x2F; 在下面制定启动用户是mysql</span><br><span class="line">[mysqld]</span><br><span class="line">user&#x3D;mysql</span><br><span class="line">datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata      </span><br><span class="line">socket&#x3D;&#x2F;tmp&#x2F;mysql.sock</span><br></pre></td></tr></table></figure></li>
<li><p>启动mysqld</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqld</span><br><span class="line">&#x2F;&#x2F; 若未做上一步，则启动时--user&#x3D;mysql</span><br><span class="line"># 或者</span><br><span class="line">service mysqld start</span><br></pre></td></tr></table></figure>
</li>
<li><p>新建软链接</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s &#x2F;tmp&#x2F;mysql.sock &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mysql.sock</span><br><span class="line">service mysqld restart</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改mysq.cnf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">user&#x3D;mysql</span><br><span class="line">datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mydata      </span><br><span class="line">socket&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;mysql.sock</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改root用户密码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">&#x2F;&#x2F; 首次登陆密码是空的，直接进入</span><br><span class="line">use mysql</span><br><span class="line">update user set password&#x3D;password(&#39;new password&#39;) where user&#x3D;&#39;root&#39;;</span><br><span class="line">flush privileges;</span><br><span class="line">exit;</span><br></pre></td></tr></table></figure></li>
<li>创建一个远程访问用户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;创建用户</span><br><span class="line">create user &#39;somebody&#39; identified by &#39;password’;</span><br><span class="line">&#x2F;&#x2F;给用户授权</span><br><span class="line">Grant ALL PRIVILEGES on *.* to somebody@‘%’;</span><br><span class="line">&#x2F;&#x2F;刷新</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>java应用cpu打满排查过程</title>
    <url>/2021/07/13/java-cpu-high/</url>
    <content><![CDATA[<h3 id="查询cpu的过程"><a href="#查询cpu的过程" class="headerlink" title="查询cpu的过程"></a>查询cpu的过程</h3><ul>
<li><ol>
<li>查看应用的pid,我的应用名称是以dlap开头<br>jps的命令参数如下，<code>jps [options] [hostid]</code> <ul>
<li>-q 不输出类名、Jar名和传入main方法的参数</li>
<li>-m 输出传入main方法的参数</li>
<li>-l 输出main类或Jar的全限名</li>
<li>-v 输出传入JVM的参数<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jps -m -l</span><br><span class="line">或者</span><br><span class="line">ps -ef | grep dlap | grep -v grep</span><br><span class="line">或者</span><br><span class="line">ps aux | grep dlap | grep -v greppid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/1.png" alt="avatar"></li>
</ul>
</li>
</ol>
</li>
<li><ol>
<li>查看系统资源占用信息，使用<code>top</code>查一下当前进程<code>pid</code>占用较高的<code>cpu</code>线程<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top -Hp pid</span><br><span class="line">&#x2F;&#x2F; 也可以用以下两个命令</span><br><span class="line">ps -Lfp pid</span><br><span class="line">&#x2F;&#x2F; 或者</span><br><span class="line">ps -mp pid -o THREAD, tid, time | sort -rn</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/2.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>将需要的线程<code>ID</code>转换为<code>16</code>进制格式，可以使用<code>printf &quot;%x\n&quot; tid</code>命令<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">printf &quot;%x\n&quot; tid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/3.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>打印线程堆栈信息，可以使用命令<code>jstack pid | grep tid</code>，注意这里的tid是线程ID的16进制值<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jstack pid | grep tid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/4.png" alt="avatar"></li>
</ol>
</li>
</ul>
<h3 id="jmap命令介绍"><a href="#jmap命令介绍" class="headerlink" title="jmap命令介绍"></a>jmap命令介绍</h3><blockquote>
<p>jmap可以导出堆内容，然后使用jhat进行分析，语法如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME</span><br><span class="line">       jmap - Prints shared object memory maps or heap memory details for a process, core file, or remote debug server. This command is</span><br><span class="line">       experimental and unsupported.</span><br><span class="line"></span><br><span class="line">SYNOPSIS</span><br><span class="line">       jmap [ options ] pid</span><br><span class="line">       jmap [ options ] executable core</span><br><span class="line">       jmap [ options ] [ pid ] server-id@ ] remote-hostname-or-IP</span><br></pre></td></tr></table></figure></p>
<ul>
<li>根据pid查看堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -heap pid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/5.png" alt="avatar"></li>
</ul>
</blockquote>
<ul>
<li>根据pid查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -histo:live pid | more</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/6.png" alt="avatar"><blockquote>
<p>class name是对象类型，说明如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">B  byte</span><br><span class="line">C  char</span><br><span class="line">D  double</span><br><span class="line">F  float</span><br><span class="line">I  int</span><br><span class="line">J  long</span><br><span class="line">Z  boolean</span><br><span class="line">[  数组，如[I表示int[]</span><br><span class="line">[L+类名 其他对象</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li>用jmap把进程内存使用情况dump到文件中，再用jhat分析查看<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -dump:format&#x3D;b,file&#x3D;dumpFileName pid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/7.png" alt="avatar"></li>
<li>用jhat查看<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jhat -port 9998 &#x2F;tmp&#x2F;dump.dat</span><br><span class="line">&#x2F;&#x2F; 注意如果Dump文件太大，可能需要加上-J-Xmx512m这种参数指定最大堆内存</span><br><span class="line">jhat -J-Xmx512m -port 9998 &#x2F;tmp&#x2F;dump.dat</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/8.png" alt="avatar"><blockquote>
<p>然后用浏览器打开，<a href="http://ip:9998" target="_blank" rel="noopener">http://ip:9998</a></p>
</blockquote>
</li>
</ul>
<h3 id="jstat-JVM统计监测工具"><a href="#jstat-JVM统计监测工具" class="headerlink" title="jstat(JVM统计监测工具)"></a>jstat(JVM统计监测工具)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME</span><br><span class="line">       jstat - Monitors Java Virtual Machine (JVM) statistics. This command is experimental and unsupported.</span><br><span class="line"></span><br><span class="line">SYNOPSIS</span><br><span class="line">           jstat [ generalOption | outputOptions vmid [ interval[s|ms] [ count ] ]</span><br><span class="line"></span><br><span class="line">       generalOption</span><br><span class="line">           A single general command-line option -help or -options. See General Options.</span><br><span class="line"></span><br><span class="line">       outputOptions</span><br><span class="line">           One or more output options that consist of a single statOption, plus any of the -t, -h, and -J options. See Output Options.</span><br><span class="line"></span><br><span class="line">       vmid</span><br><span class="line">           Virtual machine identifier, which is a string that indicates the target JVM. The general syntax is the following:</span><br><span class="line"></span><br><span class="line">               [protocol:][&#x2F;&#x2F;]lvmid[@hostname[:port]&#x2F;servername]</span><br><span class="line"></span><br><span class="line">           The syntax of the vmid string corresponds to the syntax of a URI. The vmid string can vary from a simple integer that</span><br><span class="line">           represents a local JVM to a more complex construction that specifies a communications protocol, port number, and other</span><br><span class="line">           implementation-specific values. See Virtual Machine Identifier.</span><br><span class="line"></span><br><span class="line">       interval [s|ms]</span><br><span class="line">           Sampling interval in the specified units, seconds (s) or milliseconds (ms). Default units are milliseconds. Must be a positive</span><br><span class="line">           integer. When specified, the jstat command produces its output at each interval.</span><br><span class="line"></span><br><span class="line">       count</span><br><span class="line">           Number of samples to display. The default value is infinity which causes the jstat command to display statistics until the</span><br><span class="line">           target JVM terminates or the jstat command is terminated. This value must be a positive integer.</span><br></pre></td></tr></table></figure>
<ul>
<li>根据pid 间隔250ms 采样条数4 输出GC信息<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jstat -gc pid 250 4</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/9.png" alt="avatar"><blockquote>
<p>jvm 堆内容布局<br><img src="/images/java_high_cpu/10.png" alt="avatar"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">堆内存 &#x3D; 年轻代 + 年老代 + 永久代  </span><br><span class="line">年轻代 &#x3D; Eden区 + 两个Survivor区（From和To）</span><br></pre></td></tr></table></figure>
<p>各列含义</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">S0C、S1C、S0U、S1U：Survivor 0&#x2F;1区容量（Capacity）和使用量（Used）</span><br><span class="line">EC、EU：Eden区容量和使用量</span><br><span class="line">OC、OU：年老代容量和使用量</span><br><span class="line">PC、PU：永久代容量和使用量</span><br><span class="line">YGC、YGT：年轻代GC次数和GC耗时</span><br><span class="line">FGC、FGCT：Full GC次数和Full GC耗时</span><br><span class="line">GCT：GC总耗时</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<h3 id="hprof用法"><a href="#hprof用法" class="headerlink" title="hprof用法"></a>hprof用法</h3><blockquote>
<p>hprof 能展现cpu使用率，堆内存使用情况，语法格式如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -agentlib:hprof[&#x3D;options] ToBeProfiledClass</span><br><span class="line">java -Xrunprof[:options] ToBeProfiledClass</span><br><span class="line">javac -J-agentlib:hprof[&#x3D;options] ToBeProfiledClass</span><br></pre></td></tr></table></figure><br>完整的命令格式<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Option Name and Value  Description                    Default</span><br><span class="line">---------------------  -----------                    -------</span><br><span class="line">heap&#x3D;dump|sites|all    heap profiling                 all</span><br><span class="line">cpu&#x3D;samples|times|old  CPU usage                      off</span><br><span class="line">monitor&#x3D;y|n            monitor contention             n</span><br><span class="line">format&#x3D;a|b             text(txt) or binary output     a</span><br><span class="line">file&#x3D;&lt;file&gt;            write data to file             java.hprof[.txt]</span><br><span class="line">net&#x3D;&lt;host&gt;:&lt;port&gt;      send data over a socket        off</span><br><span class="line">depth&#x3D;&lt;size&gt;           stack trace depth              4</span><br><span class="line">interval&#x3D;&lt;ms&gt;          sample interval in ms          10</span><br><span class="line">cutoff&#x3D;&lt;value&gt;         output cutoff point            0.0001</span><br><span class="line">lineno&#x3D;y|n             line number in traces?         y</span><br><span class="line">thread&#x3D;y|n             thread in traces?              n</span><br><span class="line">doe&#x3D;y|n                dump on exit?                  y</span><br><span class="line">msa&#x3D;y|n                Solaris micro state accounting n</span><br><span class="line">force&#x3D;y|n              force output to &lt;file&gt;         y</span><br><span class="line">verbose&#x3D;y|n            print messages about dumps     y</span><br></pre></td></tr></table></figure></p>
<ul>
<li>每隔20毫秒采样CPU消耗信息，堆栈深度为3<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -agentlib:hprof&#x3D;cpu&#x3D;samples,interval&#x3D;20,depth&#x3D;3 Hello.java</span><br></pre></td></tr></table></figure></li>
<li>获取CPU消耗信息，能够细到每个方法调用的开始和结束，它的实现使用了字节码注入技术（BCI）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">javac -J-agentlib:hprof&#x3D;cpu&#x3D;times Hello.java</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">javac -J-agentlib:hprof&#x3D;heap&#x3D;sites Hello.java</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">javac -J-agentlib:hprof&#x3D;heap&#x3D;dump Hello.java</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意在JVM启动参数中加入-Xrunprof:heap=sites参数可以生成CPU/Heap Profile文件，但对JVM性能影响非常大，不建议在线上服务器环境使用</p>
</blockquote>
<h3 id="jinfo查看jvm启动参数"><a href="#jinfo查看jvm启动参数" class="headerlink" title="jinfo查看jvm启动参数"></a>jinfo查看jvm启动参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 看出所有参数</span><br><span class="line">jinfo -flags pid</span><br><span class="line">&#x2F;&#x2F; 查看某个具体参数,例如InitialHeapSize</span><br><span class="line">jinfo -flag InitialHeapSize pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_high_cpu/11.png" alt="avatar"></p>
<ul>
<li>开启/关闭某个jvm参数<blockquote>
<p>使用jinnfo可以在不重启虚拟机的情况下，动态修改jvm的参数，这个方法在生产环境尤其特别有用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; jinfo -flag [+|-]name pid</span><br><span class="line">jinfo -flag +PrintGC pid</span><br><span class="line">jinfo -flag -PrintGC pid</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li>修改某个JVM进程的值<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; jinfo -flag name&#x3D;value pid</span><br><span class="line">jinfo -flag InitialHeapSize&#x3D;64g pid</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意并不是所有参数都支持动态修改</p>
</blockquote>
</li>
<li>查看当前jvm进程所有的系统属性<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jinfo -sysprops pid</span><br></pre></td></tr></table></figure>
<img src="/images/java_high_cpu/12.png" alt="avatar"></li>
</ul>
<h3 id="free命令查看机器物理内存"><a href="#free命令查看机器物理内存" class="headerlink" title="free命令查看机器物理内存"></a>free命令查看机器物理内存</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">OPTIONS</span><br><span class="line">       -b, --bytes</span><br><span class="line">              Display the amount of memory in bytes.</span><br><span class="line"></span><br><span class="line">       -k, --kilo</span><br><span class="line">              Display the amount of memory in kilobytes.  This is the default.</span><br><span class="line"></span><br><span class="line">       -m, --mega</span><br><span class="line">              Display the amount of memory in megabytes.</span><br><span class="line"></span><br><span class="line">       -g, --giga</span><br><span class="line">              Display the amount of memory in gigabytes.</span><br><span class="line"></span><br><span class="line">       --tera Display the amount of memory in terabytes.</span><br><span class="line"></span><br><span class="line">       -h, --human</span><br><span class="line">              Show all output fields automatically scaled to shortest three digit unit and display the units of print out.  Following units are used.</span><br><span class="line"></span><br><span class="line">                B &#x3D; bytes</span><br><span class="line">                K &#x3D; kilos</span><br><span class="line">                M &#x3D; megas</span><br><span class="line">                G &#x3D; gigas</span><br><span class="line">                T &#x3D; teras</span><br><span class="line"></span><br><span class="line">              If unit is missing, and you have petabyte of RAM or swap, the number is in terabytes and columns might not be aligned with header.</span><br><span class="line"></span><br><span class="line">       -w, --wide</span><br><span class="line">              Switch to the wide mode. The wide mode produces lines longer than 80 characters. In this mode buffers and cache are reported in two separate columns.</span><br><span class="line"></span><br><span class="line">       -c, --count count</span><br><span class="line">              Display the result count times.  Requires the -s option.</span><br><span class="line"></span><br><span class="line">       -l, --lohi</span><br><span class="line">              Show detailed low and high memory statistics.</span><br><span class="line"></span><br><span class="line">       -s, --seconds seconds</span><br><span class="line">              Continuously display the result delay seconds apart.  You may actually specify any floating point number for delay, usleep(3) is used for microsecond  resolu‐</span><br><span class="line">              tion delay times.</span><br><span class="line"></span><br><span class="line">       --si   Use power of 1000 not 1024.</span><br><span class="line"></span><br><span class="line">       -t, --total</span><br><span class="line">              Display a line showing the column totals.</span><br><span class="line"></span><br><span class="line">       --help Print help.</span><br><span class="line"></span><br><span class="line">       -V, --version</span><br><span class="line">              Display version information.</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_high_cpu/13.png" alt="avatar"></p>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>cpu</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么需要关闭连接</title>
    <url>/2022/03/21/java-why-need-close-connection/</url>
    <content><![CDATA[<p><a href="https://stackoverflow.com/questions/25864235/why-we-should-close-the-connection-in-jdbc-if-we-dont-do-it-what-will-happen" target="_blank" rel="noopener">链接</a></p>
<h3 id="TCP标志"><a href="#TCP标志" class="headerlink" title="TCP标志"></a>TCP标志</h3><p>SYN: (同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。</p>
<p>ACK: (确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。</p>
<p>FIN: (结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。</p>
<h3 id="TCP状态"><a href="#TCP状态" class="headerlink" title="TCP状态"></a>TCP状态</h3><blockquote>
<p>TCP状态在系统里都有对应的解释或设置,可见<code>man tcp</code>，以下介绍主要常见的几种</p>
</blockquote>
<p>1)、LISTEN: 首先服务端需要打开一个socket进行监听，状态为LISTEN.<br>/<em> The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 </em>/</p>
<p>2)、SYN_SENT: 客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT.<br>/<em>The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 </em>/</p>
<p>3)、SYN_RECV: 服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN. 之后状态置为SYN_RECV<br>/<em> A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 </em>/</p>
<p>4)、ESTABLISHED: 代表一个打开的连接，双方可以进行或已经在数据交互了。<br>/<em> The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 </em>/</p>
<p>5)、FIN_WAIT1:主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态.<br>/<em> The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 </em>/</p>
<p>6)、CLOSE_WAIT: 被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT.<br>/<em> The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 </em>/</p>
<p>7)、FIN_WAIT2: 主动关闭端接到ACK后，就进入了FIN-WAIT-2 .<br>/<em> Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 </em>/</p>
<p>8)、LAST_ACK: 被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK .<br>/<em> The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 </em>/</p>
<p>9)、TIME_WAIT: 只发生在主动关闭连接的一方。主动关闭方在接收到被动关闭方的FIN请求后，发送成功给对方一个ACK后,将自己的状态由FIN_WAIT2修改为TIME_WAIT，而必须再等2倍 的MSL(Maximum Segment Lifetime,MSL是一个数据报在internetwork中能存在的时间)时间之后双方才能把状态 都改为CLOSED以关闭连接。目前RHEL里保持TIME_WAIT状态的时间为60秒。<br>/<em> The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 </em>/</p>
<p>10)、CLOSING: 比较少见.<br>/<em> Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 </em>/</p>
<p>11)、CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束.<br>/<em> The socket is not being used. 没有任何连接状态 </em>/</p>
<h3 id="为什么创建的连接需要关闭？"><a href="#为什么创建的连接需要关闭？" class="headerlink" title="为什么创建的连接需要关闭？"></a>为什么创建的连接需要关闭？</h3><p>如果不关闭连接，这些系统资源将一直在内存中，等待下一次系统gc时才会被回收，而如果系统频繁的fgc将会导致你的程序明显卡顿，如果一直没有gc，也会导致你的内存泄漏</p>
<h3 id="如果一定要关闭，那是不是可以使用单例模式在所有地方使用？"><a href="#如果一定要关闭，那是不是可以使用单例模式在所有地方使用？" class="headerlink" title="如果一定要关闭，那是不是可以使用单例模式在所有地方使用？"></a>如果一定要关闭，那是不是可以使用单例模式在所有地方使用？</h3><h3 id="是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？"><a href="#是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？" class="headerlink" title="是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？"></a>是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？</h3>]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java面试常见问题</title>
    <url>/2021/10/10/java-interview/</url>
    <content><![CDATA[<h3 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h3><h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><ul>
<li>目的：参数化类型</li>
<li>用法：泛型类、泛型接口、泛型方法<ul>
<li>泛型类<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 简单范型</span><br><span class="line">class Test&lt;T&gt; &#123;</span><br><span class="line">  private T var;</span><br><span class="line">  public T getVar() &#123;</span><br><span class="line">    return var;</span><br><span class="line">  &#125;</span><br><span class="line">  public void setVar(T var) &#123;</span><br><span class="line">    this.var &#x3D; var;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; </span><br><span class="line">&#x2F;&#x2F; 多元泛型</span><br><span class="line">class TestKV&lt;K,V&gt; &#123;</span><br><span class="line">  private K key;</span><br><span class="line">  private V value;</span><br><span class="line">  public K getKey() &#123;</span><br><span class="line">    return key;</span><br><span class="line">  &#125;</span><br><span class="line">  public void setKey(K key) &#123;</span><br><span class="line">    this.key &#x3D; key;</span><br><span class="line">  &#125;</span><br><span class="line">  public V getValue() &#123;</span><br><span class="line">    return value;</span><br><span class="line">  &#125;</span><br><span class="line">  public void setValue(V value) &#123;</span><br><span class="line">    this.value &#x3D; value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class Demo &#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    Test&lt;String&gt; test &#x3D; new Test&lt;String&gt;();</span><br><span class="line">    test.setVar(&quot;aa&quot;);</span><br><span class="line">    System.out.println(test.getVar());</span><br><span class="line"></span><br><span class="line">    TestKV&lt;String, String&gt; testKV &#x3D; new TestKV&lt;String, String&gt;();</span><br><span class="line">    testKV.setKey(&quot;hello&quot;);</span><br><span class="line">    testKV.setValue(&quot;world&quot;);</span><br><span class="line">    System.out.println(testKV.getKey() +&quot;:&quot;+testKV.getValue());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>泛型接口<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">interface Test&lt;T&gt; &#123;</span><br><span class="line">  public T getVar();</span><br><span class="line">&#125;</span><br><span class="line">class TestImpl&lt;T&gt; implement Test&lt;T&gt; &#123;</span><br><span class="line">  private T var;</span><br><span class="line">  public TEstImpl(T var) &#123;</span><br><span class="line">    this.var &#x3D; var;</span><br><span class="line">  &#125;</span><br><span class="line">  public T getVar() &#123;</span><br><span class="line">    return var;</span><br><span class="line">  &#125;</span><br><span class="line">  public void setVar(T var) &#123;</span><br><span class="line">    this.var &#x3D; var;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">public class Demo&#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    Test&lt;String&gt; test &#x3D; new TestImpl&lt;String&gt;(&quot;tom&quot;);</span><br><span class="line">    System.out.pringln(test.getVar());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>泛型方法<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Demo &#123;</span><br><span class="line">  public &lt;T&gt; T getObject(Class&lt;T&gt; c) &#123;</span><br><span class="line">    T t &#x3D; c.newInstance();</span><br><span class="line">    retrun t;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3>]]></content>
      <categories>
        <category>interview</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>alibaba.druid配置</title>
    <url>/2022/03/21/java-druid-config/</url>
    <content><![CDATA[<h4 id="两种思路"><a href="#两种思路" class="headerlink" title="两种思路"></a>两种思路</h4><ul>
<li>后端服务主动淘汰空闲超时120s的连接，然后再主动创建连接。</li>
<li>后端服务对空闲连接保活，周期小于120秒进行一次mysql.ping或select 1操作。（确认过dba两个操作均可使dbproxy保活连接）</li>
</ul>
<h4 id="hikari连接池能否支持上述方案："><a href="#hikari连接池能否支持上述方案：" class="headerlink" title="hikari连接池能否支持上述方案："></a>hikari连接池能否支持上述方案：</h4><ul>
<li>idleTimeout：设置最大空闲时间小于120秒，空闲超时主动淘汰链接，并且hikari会自动创建新连接填充。实际发现该参数不能解决此问题，因为该参数优先级低于minimumIdle，若池中已经保持低于minimumIdle的连接数就不会再进行空闲连接淘汰。所以该参数不能解决问题。</li>
<li>maxLifetime：设置最大生存时间小于120秒，生存超时主动淘汰连接，并且hikari会自动创建新连接填充。能够解决该问题，但是会每120s就要淘汰且新建连接。</li>
</ul>
<h4 id="druid连接池能否支持上述方案："><a href="#druid连接池能否支持上述方案：" class="headerlink" title="druid连接池能否支持上述方案："></a>druid连接池能否支持上述方案：</h4><ul>
<li>testWhileIdle：设置true开启周期性健康检查 会主动淘汰掉失效的连接。</li>
<li>maxEvictableIdleTimeMillis：最大空闲时间设置小于120s，该参数不受minIdle参数约束，只要超过最大空闲时间就会自动淘汰连接。<br>看似上面两个参数均能解决，但是由于durid默认不会主动创建新链接，所以上面两个参数使连接清空后 查询时仍旧会因创建连接而耗时增加。</li>
<li>keepAlive：设置true开启保活机制，可解决该问题</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">druid:</span><br><span class="line"># 初始化大小</span><br><span class="line">initialSize: 10</span><br><span class="line"># 最大连接数</span><br><span class="line">maxActive: 30</span><br><span class="line"># 最小空闲数（周期性清除时保留的最小连接数）</span><br><span class="line">minIdle: 10</span><br><span class="line"># 最大空闲数（返还连接时若超过最大空闲连接数就丢弃）</span><br><span class="line">maxIdle: 20</span><br><span class="line"># 有效性校验</span><br><span class="line">validationQuery: select 1</span><br><span class="line"># 周期性check空闲连接</span><br><span class="line">testWhileIdle: true</span><br><span class="line"># 借出时check（影响性能）</span><br><span class="line">testOnBorrow: false</span><br><span class="line"># 返还时check（影响性能）</span><br><span class="line">testOnReturn: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 周期性检查的间隔时间，单位是毫秒</span><br><span class="line">timeBetweenEvictionRunsMillis: 60000</span><br><span class="line"># 连接的最小空闲时间，小于该时间不会被周期性check清除。单位是毫秒</span><br><span class="line">minEvictableIdleTimeMillis: 50000</span><br><span class="line"># 连接的最大空闲时间，大于该时间会被周期性check清除，且优先级大于minIdle。单位是毫秒</span><br><span class="line">maxEvictableIdleTimeMillis: 100000</span><br><span class="line"># 开启连接保活策略。作用：https:&#x2F;&#x2F;www.bookstack.cn&#x2F;read&#x2F;Druid&#x2F;d90f9643acdca5c0.md</span><br><span class="line">keepAlive: true</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm面试常见问题</title>
    <url>/2021/10/29/jvm-interview/</url>
    <content><![CDATA[<ul>
<li><p>jvm参数设置说明<br><img src="/images/java_interview/1.png" alt="avatar"></p>
</li>
<li><p>并行收集器相关参数<br><img src="/images/java_interview/2.png" alt="avatar"></p>
</li>
<li><p>JVM CMS相关参数<br><img src="/images/java_interview/3.png" alt="avatar"></p>
</li>
<li><p>JVM辅助信息参数设置<br><img src="/images/java_interview/4.png" alt="avatar"></p>
</li>
<li><p>java进程启动时，未指定最大堆大小和默认初始值时，系统如何分配</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\\ 直接启动，jvm的那些参数是如何分配的</span><br><span class="line">java xx.jar</span><br></pre></td></tr></table></figure>
<blockquote>
<p>首先可以通过jinfo -flags pid查看jvm参数，可以发现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-XX:CICompilerCount&#x3D;15 </span><br><span class="line">-XX:InitialHeapSize&#x3D;2147483648 </span><br><span class="line">-XX:MaxHeapSize&#x3D;32210157568 </span><br><span class="line">-XX:MaxNewSize&#x3D;10736369664 </span><br><span class="line">-XX:MinHeapDeltaBytes&#x3D;524288 </span><br><span class="line">-XX:NewSize&#x3D;715653120 </span><br><span class="line">-XX:OldSize&#x3D;1431830528 </span><br><span class="line">-XX:+UseCompressedClassPointers </span><br><span class="line">-XX:+UseCompressedOops </span><br><span class="line">-XX:+UseFastUnorderedTimeStamps </span><br><span class="line">-XX:+UseParallelGC</span><br></pre></td></tr></table></figure>
<p>知道答案是<code>-XX:InitialHeapSize=2147483648</code>和<code>-XX:MaxHeapSize=32210157568</code>。另外通过 <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/parallel.html#default_heap_size" target="_blank" rel="noopener">jvm默认配置</a>发现这一段<code>Server JVM Default Initial and Maximum Heap Sizes
The default initial and maximum heap sizes work similarly on the server JVM as it does on the client JVM, except that the default values can go higher. On 32-bit JVMs, the default maximum heap size can be up to 1 GB if there is 4 GB or more of physical memory. On 64-bit JVMs, the default maximum heap size can be up to 32 GB if there is 128 GB or more of physical memory. You can always set a higher or lower initial and maximum heap by specifying those values directly; see the next section.</code>中文意思就是32位系统默认最大值可以到1GB，如果物理内存大于或者等于4GB，而在64位系统默认最大堆内存可以达到32GB或者更多，如果物理内存大袋128GB或者更多时。<br>但是要注意过多的</p>
</blockquote>
</li>
</ul>
<ul>
<li><p>JVM GC垃圾回收器参数设置<br>JVM给出了3种选择：串行收集器、并行收集器、并发收集器。串行收集器只适用于小数据量的情况，所以生产环境的选择主要是并行收集器和并发收集器。<br>默认情况下JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行智能判断。<br>串行收集器<br>-XX:+UseSerialGC：设置串行收集器。<br>并行收集器（吞吐量优先）<br>-XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。<br>-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收。此值建议配置与CPU数目相等。<br>-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0开始支持对年老代并行收集。<br>-XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间（单位毫秒）。如果无法满足此时间，JVM会自动调整年轻代大小，以满足此时间。<br>-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动调整年轻代Eden区大小和Survivor区大小的比例，以达成目标系统规定的最低响应时间或者收集频率等指标。此参数建议在使用并行收集器时，一直打开。<br>并发收集器（响应时间优先）<br>-XX:+UseConcMarkSweepGC：即CMS收集，设置年老代为并发收集。CMS收集是JDK1.4后期版本开始引入的新GC算法。它的主要适合场景是对响应时间的重要性需求大于对吞吐量的需求，能够承受垃圾回收线程和应用线程共享CPU资源，并且应用中存在比较多的长生命周期对象。CMS收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存。<br>-XX:+UseParNewGC：设置年轻代为并发收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此参数。<br>-XX:CMSFullGCsBeforeCompaction=0：由于并发收集器不对内存空间进行压缩和整理，所以运行一段时间并行收集以后会产生内存碎片，内存使用效率降低。此参数设置运行0次Full GC后对内存空间进行压缩和整理，即每次Full GC后立刻开始压缩和整理内存。<br>-XX:+UseCMSCompactAtFullCollection：打开内存空间的压缩和整理，在Full GC后执行。可能会影响性能，但可以消除内存碎片。<br>-XX:+CMSIncrementalMode：设置为增量收集模式。一般适用于单CPU情况。<br>-XX:CMSInitiatingOccupancyFraction=70：表示年老代内存空间使用到70%时就开始执行CMS收集，以确保年老代有足够的空间接纳来自年轻代的对象，避免Full GC的发生。<br>其它垃圾回收参数<br>-XX:+ScavengeBeforeFullGC：年轻代GC优于Full GC执行。<br>-XX:-DisableExplicitGC：不响应 System.gc() 代码。<br>-XX:+UseThreadPriorities：启用本地线程优先级API。即使 java.lang.Thread.setPriority() 生效，不启用则无效。<br>-XX:SoftRefLRUPolicyMSPerMB=0：软引用对象在最后一次被访问后能存活0毫秒（JVM默认为1000毫秒）。<br>-XX:TargetSurvivorRatio=90：允许90%的Survivor区被占用（JVM默认为50%）。提高对于Survivor区的使用率。</p>
</li>
<li><p>JVM参数疑问解答<br>-Xmn，-XX:NewSize/-XX:MaxNewSize，-XX:NewRatio 3组参数都可以影响年轻代的大小，混合使用的情况下，优先级是什么？<br>如下：<br>高优先级：-XX:NewSize/-XX:MaxNewSize<br>中优先级：-Xmn（默认等效 -Xmn=-XX:NewSize=-XX:MaxNewSize=?）<br>低优先级：-XX:NewRatio<br>推荐使用-Xmn参数，原因是这个参数简洁，相当于一次设定 NewSize/MaxNewSIze，而且两者相等，适用于生产环境。-Xmn 配合 -Xms/-Xmx，即可将堆内存布局完成。<br>-Xmn参数是在JDK 1.4 开始支持。</p>
</li>
<li><p>JVM参数设置优化例子</p>
</li>
</ul>
<ol>
<li>承受海量访问的动态Web应用<br>服务器配置：8 CPU, 8G MEM, JDK 1.6.X<br>参数方案：<br>-server -Xmx3550m -Xms3550m -Xmn1256m -Xss128k -XX:SurvivorRatio=6 -XX:MaxPermSize=256m -XX:ParallelGCThreads=8 -XX:MaxTenuringThreshold=0 -XX:+UseConcMarkSweepGC<br>调优说明：<br>-Xmx 与 -Xms 相同以避免JVM反复重新申请内存。-Xmx 的大小约等于系统内存大小的一半，即充分利用系统资源，又给予系统安全运行的空间。<br>-Xmn1256m 设置年轻代大小为1256MB。此值对系统性能影响较大，Sun官方推荐配置年轻代大小为整个堆的3/8。<br>-Xss128k 设置较小的线程栈以支持创建更多的线程，支持海量访问，并提升系统性能。<br>-XX:SurvivorRatio=6 设置年轻代中Eden区与Survivor区的比值。系统默认是8，根据经验设置为6，则2个Survivor区与1个Eden区的比值为2:6，一个Survivor区占整个年轻代的1/8。<br>-XX:ParallelGCThreads=8 配置并行收集器的线程数，即同时8个线程一起进行垃圾回收。此值一般配置为与CPU数目相等。<br>-XX:MaxTenuringThreshold=0 设置垃圾最大年龄（在年轻代的存活次数）。如果设置为0的话，则年轻代对象不经过Survivor区直接进入年老代。对于年老代比较多的应用，可以提高效率；如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概率。根据被海量访问的动态Web应用之特点，其内存要么被缓存起来以减少直接访问DB，要么被快速回收以支持高并发海量请求，因此其内存对象在年轻代存活多次意义不大，可以直接进入年老代，根据实际应用效果，在这里设置此值为0。<br>-XX:+UseConcMarkSweepGC 设置年老代为并发收集。CMS（ConcMarkSweepGC）收集的目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代内存，适用于应用中存在比较多的长生命周期对象的情况。</li>
<li>内部集成构建服务器案例<br>高性能数据处理的工具应用<br>服务器配置：1 CPU, 4G MEM, JDK 1.6.X<br>参数方案：<br>-server -XX:PermSize=196m -XX:MaxPermSize=196m -Xmn320m -Xms768m -Xmx1024m<br>调优说明：<br>-XX:PermSize=196m -XX:MaxPermSize=196m 根据集成构建的特点，大规模的系统编译可能需要加载大量的Java类到内存中，所以预先分配好大量的持久代内存是高效和必要的。<br>-Xmn320m 遵循年轻代大小为整个堆的3/8原则。<br>-Xms768m -Xmx1024m 根据系统大致能够承受的堆内存大小设置即可。</li>
</ol>
]]></content>
      <categories>
        <category>interview</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊linux下的软硬链接</title>
    <url>/2022/02/16/linux-ln/</url>
    <content><![CDATA[<h3 id="链接概念"><a href="#链接概念" class="headerlink" title="链接概念"></a>链接概念</h3><p>Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。<br>默认情况下，ln命令产生硬链接。</p>
<h3 id="硬连接"><a href="#硬连接" class="headerlink" title="硬连接"></a>硬连接</h3><ul>
<li>硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。</li>
<li>硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。</li>
</ul>
<h3 id="软连接"><a href="#软连接" class="headerlink" title="软连接"></a>软连接</h3><p>另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#创建一个测试文件f1</span><br><span class="line">[oracle@Linux]$ touch f1</span><br><span class="line"></span><br><span class="line">#创建f1的一个硬连接文件f2</span><br><span class="line">[oracle@Linux]$ ln f1 f2</span><br><span class="line"></span><br><span class="line">#创建f1的一个符号连接文件f3</span><br><span class="line">[oracle@Linux]$ ln -s f1 f3</span><br><span class="line"></span><br><span class="line"># -i参数显示文件的inode节点信息</span><br><span class="line">[oracle@Linux]$ ls -li   </span><br><span class="line">total 0</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f1</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f2</span><br><span class="line">9797649 lrwxrwxrwx  1 oracle oinstall 2 Apr 21 08:11 f3 -&gt; f1</span><br></pre></td></tr></table></figure>
<p>从上面的结果中可以看出，硬连接文件f2与原文件f1的inode节点相同，均为9797648，然而符号连接文件的inode节点不同。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修改文件内容</span><br><span class="line">[oracle@Linux]$ echo &quot;I am f1 file&quot; &gt;&gt;f1</span><br><span class="line"></span><br><span class="line"># 打印f1文件内容</span><br><span class="line">[oracle@Linux]$ cat f1</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">I am f1 file</span><br><span class="line"># 删除f1</span><br><span class="line">[oracle@Linux]$ rm -f f1</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容，未受到影响，所以硬链接未受源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容，提示找不到该文件或者目录，所以软连接会受到源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">cat: f3: No such file or directory</span><br></pre></td></tr></table></figure>
<p>通过上面的测试可以看出：当删除原始文件f1后，硬连接f2不受影响，但是符号连接f1文件无效</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1).删除符号连接f3,对f1,f2无影响；<br>2).删除硬连接f2，对f1,f3也无影响；<br>3).删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效；<br>4).同时删除原文件f1,硬连接f2，整个文件会真正的被删除。</p>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linux机器cpu打满排查过程</title>
    <url>/2021/07/13/linux-cpu-high/</url>
    <content><![CDATA[<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>接收到告警短信，web应用登陆无响应，请求api均为504</p>
<h3 id="影响范围"><a href="#影响范围" class="headerlink" title="影响范围"></a>影响范围</h3><p>平台无法正常使用</p>
<h3 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h3><p>一般情况下，<code>cpp</code>应用占用<code>cpu</code>较高的原因大部分分为以下两个情况：</p>
<ul>
<li>应用属于计算密集型应用<br>使用大量 <code>CPU</code> 会导致平均负载升高，此时<code>system load</code>和<code>cpu</code>使用数率值上是一致的</li>
<li>应用中出现了<code>IO</code>密集型应用<br>等待 <code>I/O</code> 也会导致平均负载升高，但 <code>CPU</code> 使用率不一定很高，所以<code>system load</code>和<code>cpu</code>使用率并不会一致</li>
</ul>
<h4 id="查询该机器的系统负载-system-load"><a href="#查询该机器的系统负载-system-load" class="headerlink" title="查询该机器的系统负载(system load)"></a>查询该机器的系统负载(system load)</h4><ul>
<li><p>1.系统负载：<br>是指系统cpu繁忙程度的度量指标，即有多少个进程在等待被cpu调度，就是进程等待cpu的队列长度</p>
</li>
<li><p>2.平均负载：<br>是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 <code>CPU</code> 的进程，还包括等待 <code>CPU</code> 和等待 <code>I/O</code> 的进程，实际上是系统的平均活跃进程数统计</p>
</li>
<li><p>3.uptime详解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 观察uptime刷新，w命令&#x2F;top命令皆可查询到系统的平均负载</span><br><span class="line">watch -D uptime</span><br><span class="line">&#x2F;&#x2F; 得到结果</span><br><span class="line"> 11:10:17 up 628 days, 14:06,  2 users,  load average: 0.05, 3.53, 6.59</span><br><span class="line"> &#x2F;&#x2F; 11:10:17是指当前系统时间</span><br><span class="line"> &#x2F;&#x2F; up 628 days, 14:06 是指机器运行时间</span><br><span class="line"> &#x2F;&#x2F; 2 users：是指当前登陆有2个用户</span><br><span class="line"> &#x2F;&#x2F; load average: 0.05, 3.53, 6.59：是指当前1分钟&#x2F;5分钟&#x2F;15分钟的平均负载指</span><br></pre></td></tr></table></figure>
<p>假设平均负载是<code>2</code>，当前<code>cpu</code>数是<code>2cores</code>则说明<code>cpu</code>被<code>100%</code>使用，如果是<code>4cores</code>则说明<code>cpu</code>利用率是<code>50%</code>，如果是<code>1cores</code>，则说明有一半的进程都竞争得不到<code>cpu</code></p>
</li>
<li><p>3.如何查看机器的核心(core)呢</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;cpuinfo | grep cores | wc -l</span><br></pre></td></tr></table></figure></li>
<li>4.如何查看机器是否开启超线程呢？<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 如何得到的值和grep cores后得到的核心数一致，则说明未开启</span><br><span class="line">cat &#x2F;proc&#x2F;cpuinfo | grep processor | wc -l</span><br></pre></td></tr></table></figure>
比如我们的机器2颗物理cpu，在每颗物理cpu上又做了6颗逻辑CPU，之后在每颗逻辑CPU上又实现了超线程后，假如此时你在系统中使用<strong>cat /proc/cpuinfo |grep ‘processor’|wc –l</strong>返回24颗，如果load值（15分钟的返回值作为参考依据）长期在24以上，说明系统已经很繁忙了。</li>
</ul>
<h4 id="具体分析系统瓶颈"><a href="#具体分析系统瓶颈" class="headerlink" title="具体分析系统瓶颈"></a>具体分析系统瓶颈</h4><blockquote>
<p>结合平均负载分析，假如我们当前已经知道load很高，但是仍然无法判断是cpu占用率高，还是系统I/O繁忙，又或者是内存不足导致的？<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vmstat 1</span><br></pre></td></tr></table></figure><br><img src="/images/linux-cpu-high/6.png" alt="cgi"></p>
<ul>
<li>1、procs列<br><strong>r</strong> 列表示运行和等待cpu时间片的进程数，如果长期大于cpu核心数，说明cpu不足，需要增加cpu。<br><strong>b</strong> 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等。</li>
</ul>
</blockquote>
<ul>
<li><p>2、system 显示采集间隔内发生的中断数<br><strong>in</strong> 列表示在某一时间间隔中观测到的每秒设备中断数。<br><strong>cs</strong> 列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。</p>
</li>
<li><p>3、memory列<br><strong>swpd</strong> 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，只要<br><strong>free</strong> 当前的空闲页面列表中内存数量(k表示)<br><strong>buff</strong> 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。<br><strong>cache</strong> 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。</p>
</li>
<li><p>4、swap列<br><strong>si</strong> 由内存进入内存交换区数量。<br><strong>so</strong> 由内存交换区进入内存数量。<br><strong>si</strong>、<strong>so</strong>的值长期为0，系统性能还是正常</p>
</li>
<li><p>5、IO列<br><strong>bi</strong> 从块设备读入数据的总量（读磁盘）（每秒kb）。<br><strong>bo</strong> 块设备写入数据的总量（写磁盘）（每秒kb）<br>这里我们设置的bi+bo参考值为1000，如果超过1000，而且wa值较大应该考虑均衡磁盘负载，可以结合iostat输出来分析。</p>
</li>
<li><p>6、cpu列<br><strong>cs</strong> 表示cpu的使用状态<br><strong>us</strong> 列显示了用户方式下所花费 CPU 时间的百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。<br><strong>sy</strong> 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足<br><strong>id</strong> 列显示了cpu处在空闲状态的时间百分比<br><strong>wa</strong> 列显示了IO等待所占用的CPU时间的百分比。这里wa的参考值为30%，如果wa超过30%，说明IO等待严重，这可能是磁盘大量随机访问造成的，也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。</p>
</li>
</ul>
<blockquote>
<p>通过以上分析，可以知道当前机器的瓶颈是cpu负载过高，那么如何知道哪个进程占用cpu资源呢？</p>
</blockquote>
<h4 id="查询该机器cpu占用最高的进程"><a href="#查询该机器cpu占用最高的进程" class="headerlink" title="查询该机器cpu占用最高的进程"></a>查询该机器<code>cpu</code>占用最高的进程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 每5秒统计一次</span><br><span class="line">pidstat -u 5 1</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux-cpu-high/1.png" alt="cgi"></p>
<blockquote>
<p>也可以使用<code>top</code>命令查询到<code>cpu</code>占用最高的进程</p>
</blockquote>
<h4 id="查询该机器的cpu使用情况"><a href="#查询该机器的cpu使用情况" class="headerlink" title="查询该机器的cpu使用情况"></a>查询该机器的<code>cpu</code>使用情况</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 每5秒刷新一次查看所有cpu的统计情况</span><br><span class="line">mpstat -P ALL 5</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux-cpu-high/2.png" alt="cgi"></p>
<h4 id="查看到进程ID后，可以通过ps-aux-grep-pid查看进程的详情"><a href="#查看到进程ID后，可以通过ps-aux-grep-pid查看进程的详情" class="headerlink" title="查看到进程ID后，可以通过ps aux | grep pid查看进程的详情"></a>查看到进程<code>ID</code>后，可以通过<code>ps aux | grep pid</code>查看进程的详情</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux-cpu-high/4.png" alt="cgi"></p>
<h4 id="定位到最耗cpu的进程后，使用top-Hp-pid命令查看线程列表，并找到占用cpu最高的线程"><a href="#定位到最耗cpu的进程后，使用top-Hp-pid命令查看线程列表，并找到占用cpu最高的线程" class="headerlink" title="定位到最耗cpu的进程后，使用top -Hp pid命令查看线程列表，并找到占用cpu最高的线程"></a>定位到最耗<code>cpu</code>的进程后，使用<code>top -Hp pid</code>命令查看线程列表，并找到占用cpu最高的线程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; &#96;tid&#96;表示线程&#96;ID&#96;，&#96;time&#96;表示线程已经运行的时间</span><br><span class="line">&#x2F;&#x2F; 这个命令也一样使用ps -mp pid -o THREAD,tid,time | sort -rn</span><br><span class="line">top -Hp pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux-cpu-high/5.png" alt="cgi"></p>
<h4 id="将需要的线程ID转换为16进制格式，可以使用printf-quot-x-n-quot-tid命令"><a href="#将需要的线程ID转换为16进制格式，可以使用printf-quot-x-n-quot-tid命令" class="headerlink" title="将需要的线程ID转换为16进制格式，可以使用printf &quot;%x\n&quot; tid命令"></a>将需要的线程<code>ID</code>转换为<code>16</code>进制格式，可以使用<code>printf &quot;%x\n&quot; tid</code>命令</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">printf &quot;%x\n&quot; tid</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>cpu</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>由于overlay占用磁盘空间导致磁盘告警</title>
    <url>/2022/02/15/linux-overlay-full/</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>早上突然收到告警短信，xxx服务磁盘使用率超过80%，如下图，赶紧上机器进行排查，下面是排查的过程<br><img src="/images/linux/disk_full/1.png" alt="avatar"></p>
<h3 id="查看机器整体磁盘使用情况"><a href="#查看机器整体磁盘使用情况" class="headerlink" title="查看机器整体磁盘使用情况"></a>查看机器整体磁盘使用情况</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -h</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 下面是结果</span><br><span class="line">root@xxx.docker.ys:~&#x2F;dlap-manager$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">overlay          20G   18G  2.7G  87% &#x2F;</span><br><span class="line">tmpfs            64M     0   64M   0% &#x2F;dev</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">&#x2F;dev&#x2F;sda3       219G   15G  193G   8% &#x2F;etc&#x2F;hosts</span><br><span class="line">shm              64M     0   64M   0% &#x2F;dev&#x2F;shm</span><br><span class="line">&#x2F;dev&#x2F;sdb1       4.4T  949G  3.5T  22% &#x2F;etc&#x2F;hostname</span><br><span class="line">tmpfs            63G   12K   63G   1% &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;acpi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;scsi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;firmware</span><br></pre></td></tr></table></figure>
<p>看到overlay这个文件目录占了<code>87%</code>，仔细研究下这个文件夹是什么</p>
<h4 id="overlay介绍"><a href="#overlay介绍" class="headerlink" title="overlay介绍"></a>overlay介绍</h4><p>OverlayFS是一种堆叠文件系统，它依赖并建立在其它的文件系统之上（例如ext4fs和xfs等等），并不直接参与磁盘空间结构的划分，仅仅将原来底层文件系统中不同的目录进行“合并”，然后向用户呈现，这也就是联合挂载技术，对比于AUFS，OverlayFS速度更快，实现更简单。 而Linux 内核为Docker提供的OverlayFS驱动有两种：overlay和overlay2。而overlay2是相对于overlay的一种改进，在inode利用率方面比overlay更有效。但是overlay有环境需求：docker版本17.06.02+，宿主机文件系统需要是ext4或xfs格式。<br>overlayfs通过三个目录：lower目录、upper目录、以及work目录实现，其中lower目录可以是多个，work目录为工作基础目录，挂载后内容会被清空，且在使用过程中其内容用户不可见，最后联合挂载完成给用户呈现的统一视图称为为merged目录<br><img src="/images/linux/disk_full/2.png" alt="avatar"><br>在上述图中可以看到三个层结构，即：lowerdir、uperdir、merged，其中lowerdir是只读的image layer，其实就是rootfs，对应的lowerdir是可以有多个目录。而upperdir则是在lowerdir之上的一层，这层是读写层，在启动一个容器时候会进行创建，所有的对容器数据更改都发生在这里层。最后merged目录是容器的挂载点，也就是给用户暴露的统一视角。</p>
<h4 id="overlay如何工作"><a href="#overlay如何工作" class="headerlink" title="overlay如何工作"></a>overlay如何工作</h4><p>当容器中发生数据修改时候overlayfs存储驱动又是如何进行工作的？以下将阐述其读写过程：</p>
<ul>
<li><ol>
<li>读：</li>
</ol>
<ul>
<li>如果文件在容器层（upperdir），直接读取文件；</li>
<li>如果文件不在容器层（upperdir），则从镜像层（lowerdir）读取；</li>
</ul>
</li>
<li><ol>
<li>写：</li>
</ol>
<ul>
<li>首次写入： 如果在upperdir中不存在，overlay和overlay2执行copy_up操作，把文件从lowdir拷贝到upperdir，由于overlayfs是文件级别的（即使文件只有很少的一点修改，也会产生的copy_up的行为），后续对同一文件的在此写入操作将对已经复制到容器的文件的副本进行操作。这也就是常常说的写时复制（copy-on-write）</li>
<li>删除文件和目录： 当文件在容器被删除时，在容器层（upperdir）创建whiteout文件，镜像层(lowerdir)的文件是不会被删除的，因为他们是只读的，但without文件会阻止他们显示，当目录在容器内被删除时，在容器层（upperdir）一个不透明的目录，这个和上面whiteout原理一样，阻止用户继续访问，即便镜像层仍然存在。 </li>
</ul>
</li>
<li><ol>
<li>注意事项</li>
</ol>
<ul>
<li>copy_up操作只发生在文件首次写入，以后都是只修改副本,</li>
<li>overlayfs只适用两层目录，相比于比AUFS，查找搜索都更快。</li>
<li>容器层的文件删除只是一个“障眼法”，是靠whiteout文件将其遮挡，image层并没有删除，这也就是为什么使用docker commit 提交保存的镜像会越来越大，无论在容器层怎么删除数据，image层都不会改变。</li>
</ul>
</li>
</ul>
<h4 id="overlay镜像存储结构"><a href="#overlay镜像存储结构" class="headerlink" title="overlay镜像存储结构"></a>overlay镜像存储结构</h4><p>从仓库拉取ubuntu镜像，结果显示总共拉取了6层镜像如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[hadoop@bigdata-xxx.ys ~]$ sudo docker pull ubuntu-test:xenial</span><br><span class="line">Trying to pull repository ubuntu-test ...</span><br><span class="line">xenial: Pulling from ubuntu-test</span><br><span class="line">58690f9b18fc: Pull complete</span><br><span class="line">b51569e7c507: Pull complete</span><br><span class="line">da8ef40b9eca: Pull complete</span><br><span class="line">fb15d46c38dc: Pull complete</span><br><span class="line">4c7a0de79adc: Pull complete</span><br><span class="line">5eff12cba838: Pull complete</span><br><span class="line">Digest: sha256:d21c70f1203a5b0fe1d8a1b60bd1924ca5458ba450828f6b88c4e973db84c8e8</span><br><span class="line">Status: Downloaded newer image for ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>此时6层镜像被存储在/var/lib/docker/overlay2下，将镜像运行起来一个容器，如下命令<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker run -itd --name ubuntu-test ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>运行容器之后，查询出容器的元数据<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取容器ID</span><br><span class="line">sudo docker ps -a | grep ubuntu</span><br><span class="line">&#x2F;&#x2F; 通过容器ID查看元数据</span><br><span class="line">sudo docker inspect container-id</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/4.png" alt="avatar"></p>
<p>进入容器创建一个文件，如下命令<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker exec -it ubuntu-test bash</span><br><span class="line">echo &#39;xxxxxx&#39; &gt; helloworld.txt</span><br></pre></td></tr></table></figure></p>
<p>通过tree命令查看新创建的文件出现在哪里<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tree -L 3 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;f90282cedadf6b7765ba06ea8983af306f78773baeca9ff1e418651d0b9d14f2&#x2F;diff</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/3.png" alt="avatar"></p>
<h3 id="回到问题本身"><a href="#回到问题本身" class="headerlink" title="回到问题本身"></a>回到问题本身</h3><p>overlay目录使用了87%的存储，触发了磁盘告警，overlay目录是我们的弹性云容器运行的目录，发现通过nohup启动的jar包将所有stdout/stderr都输出到了nohup.out文件，该文件也持久化存在/var/lib/docker/overlay2下，所以需要对nohup.out进行处理，不可直接删除，因为jar启动后所有的输出流都会转存到nohup.out，这个文件句柄已经打开，所有的stdout/stderr仍然会输出，只是输出在/proc/pid/fd/1或者/proc/pid/fd/2这些目录下。</p>
<blockquote>
<p>0描述符 标准输入<br>1描述符 标注输出<br>2描述符 标注错误输出  </p>
</blockquote>
<p><strong>linux一切到可以看作文件</strong>，/proc/pid/fd/1 就是pid进程的标准输出，/proc/pid/fd/1 就是pid进程的标准错误输出，我们通过测试可以看到下面结果，就算我们删除了nohup.out文件，任何会将stdout/stderro输出到这个文件。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[hadoop@xxx.ys ~]$ tree -L 3 &#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">&#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">├── 0 -&gt; &#x2F;dev&#x2F;null</span><br><span class="line">├── 1 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">├── 2 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">└── 3 -&gt; &#x2F;home&#x2F;hadoop&#x2F;test.txt</span><br><span class="line"></span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure></p>
<ul>
<li><ol>
<li>重启jar包，将所有错误/标准输出忽略<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; &gt;&#x2F;dev&#x2F;null是表示linux的空设备，是一个特殊的文件，写入到它的内容都会被丢弃(等同于 1&gt;&#x2F;dev&#x2F;null)</span><br><span class="line">&#x2F;&#x2F; 2&gt;&amp;1表示所有错误输出都重定向到标准输出</span><br><span class="line">&#x2F;&#x2F; 所以就是将错误输出重定向到标准输出，将标准输出重定向到空设备，就是禁止所有输出&#x2F;错误</span><br><span class="line">nohup java -jar xx.jar &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>删除nohup.out文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -f nohup.out</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h3 id="修改docker的根目录"><a href="#修改docker的根目录" class="headerlink" title="修改docker的根目录"></a>修改docker的根目录</h3><h4 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h4><ol>
<li>停止docker服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure></li>
<li><p>创建新的docker工作目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure>
<p>这个目录可以自定义，但是一定要保证在/root里面</p>
</li>
<li><p>迁移/var/lib/docker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -avz &#x2F;var&#x2F;lib&#x2F;docker &#x2F;data2&#x2F;docker&#x2F;</span><br></pre></td></tr></table></figure></li>
<li>配置devicemapper.conf<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 不存在就创建</span><br><span class="line">sudo mkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;</span><br><span class="line"># 不存在就创建</span><br><span class="line">sudo vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;devicemapper.conf</span><br></pre></td></tr></table></figure></li>
<li><p>在devicemapper.conf中添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd  --graph&#x3D;&#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启docker服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"> </span><br><span class="line">systemctl restart docker</span><br><span class="line"> </span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure>
</li>
<li><p>确认是否配置成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux/disk_full/5.png" alt="avatar"></p>
</li>
</ol>
<p>重新启动所有容器后，确认无误。即可删除/var/lib/docker里面所有文件。</p>
<h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>如果报错如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error response from daemon: Cannot restart container linyu: shim error: docker-runc not installed on system</span><br></pre></td></tr></table></figure></p>
<ul>
<li><ol>
<li>判断是否安装runc<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qi runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>未安装则先安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>创建软连接<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;</span><br><span class="line">sudo ln -s docker-runc-current docker-runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>重启服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker restart container_id</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql锁相关</title>
    <url>/2021/12/17/mysql-lock/</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><code>SpringBoot</code>的<code>schedule</code>模块可以支持定时脚本，原理其实就是<code>SchedulingTaskExecutor</code>类，它实现了<code>java.util.concurrent.Executor</code>接口，这个接口主要是定义了线程的执行，例如我们日常常用的线程池执行器<code>ThreadPoolExecutor</code>类就是实现了<code>Executor</code>接口。此文重点不是介绍<code>SpringBoot</code>的<code>schedule</code>模块，所以具体实现逻辑及源码部分解析，在此略过。但问题是<code>schedule</code>模块不支持分布式部署，而我们当前的业务需要部署在多个节点上，为了实现多个节点上在某个时刻只执行某个定时脚本，其他节点不重复执行，我们调研了<code>MYSQL</code>的锁，用以实现分布式锁场景。</p>
<h3 id="mysql锁"><a href="#mysql锁" class="headerlink" title="mysql锁"></a>mysql锁</h3><h4 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h4><ul>
<li>什么是乐观锁<blockquote>
<p>用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。</p>
</blockquote>
</li>
<li>实现过程<br>假设表结构如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE &#96;lock&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  &#96;name&#96; varchar(255) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;锁名称&#39;,</span><br><span class="line">  &#96;status&#96; tinyint(4) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;锁状态：0-空闲，1-运行&#39;,</span><br><span class="line">  &#96;version&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;版本&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin;</span><br></pre></td></tr></table></figure>
查询方式：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id,name,version from lock where id &#x3D; #&#123;id&#125;</span><br></pre></td></tr></table></figure>
加锁更新方式：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update lock set status &#x3D; 1，version&#x3D;version+1 where id &#x3D; #&#123;id&#125; and version &#x3D; #&#123;version&#125;</span><br></pre></td></tr></table></figure>
释放锁更新方式：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update lock set status &#x3D; 0 where id &#x3D; #&#123;id&#125; and status &#x3D; 1</span><br></pre></td></tr></table></figure>
<h4 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h4></li>
<li><p>什么是悲观锁</p>
<blockquote>
<p>与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟<code>java</code>中的<code>synchronized</code>很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。<br>说到这里，由悲观锁涉及到的另外两个锁概念就出来了，它们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。</p>
</blockquote>
</li>
<li><p>什么是共享锁</p>
<blockquote>
<p>共享锁又称读锁 (read lock)，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。当如果事务对读锁进行修改操作，很可能会造成死锁。</p>
</blockquote>
</li>
</ul>
<p>在查询语句后面增加 <code>LOCK IN SHARE MODE</code> ，<code>Mysql</code>会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。 其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。<br>加上共享锁后，对于<code>update</code>，<code>insert</code>，<code>delete</code>语句会自动加排它锁。</p>
<p>举例说明<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在A窗口输入</span><br><span class="line">select * from lock where id &#x3D; 1 lock in shard mode</span><br><span class="line"># 在B窗口输入</span><br><span class="line">update lock set version &#x3D; version + 1 where id &#x3D; 1</span><br><span class="line"># B窗口报错</span><br><span class="line">[Err] 1205 - Lock wait timeout exceeded; try restarting transaction</span><br></pre></td></tr></table></figure></p>
<ul>
<li>什么是排它锁<blockquote>
<p>排他锁 exclusive lock（也叫writer lock）又称写锁。<br>若某个事物对某一行加上了排他锁，只能这个事务对其进行读写，在此事务结束之前，其他事务不能对其进行加任何锁，其他进程可以读取,不能进行写操作，需等待其释放。排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。<br>若事务 1 对数据对象A加上X锁，事务 1 可以读A也可以修改A，其他事务不能再对A加任何锁，直到事物 1 释放A上的锁。这保证了其他事务在事物 1 释放A上的锁之前不能再读取和修改A。排它锁会阻塞所有的排它锁和共享锁</p>
</blockquote>
</li>
</ul>
<p>举例说明<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 要使用排他锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交</span><br><span class="line"># 在A窗口输入</span><br><span class="line">set autocommit &#x3D; 0;</span><br><span class="line">begin;</span><br><span class="line">select * from lock where id &#x3D; 1 for update;</span><br><span class="line">update lock set version &#x3D; version + 1 where id &#x3D; 1;</span><br><span class="line">commit;</span><br><span class="line"></span><br><span class="line"># 在B窗口输入，会看到一直在等待中,直到A窗口释放锁,B窗口才能获取结果</span><br><span class="line">select * from lock where id &#x3D; 1 for update;</span><br></pre></td></tr></table></figure></p>
<h4 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h4><p><code>InnoDB</code>的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。<br>行锁的劣势：开销大；加锁慢；会出现死锁<br>行锁的优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强<br>加锁的方式：自动加锁。对于<code>UPDATE</code>、<code>DELETE</code>和<code>INSERT</code>语句，<code>InnoDB</code>会自动给涉及数据集加排他锁；对于普通<code>SELECT</code>语句，<code>InnoDB</code>不会加任何锁；当然我们也可以显示的加锁</p>
<h4 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h4><p>当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，<code>InnoDB</code>会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，<code>InnoDB</code>也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（<code>Next-Key</code>锁）<br>例如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁</span><br><span class="line"># InnoDB使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求</span><br><span class="line"># 指同一个事务内多次查询返回的结果集不一样。比如同一个事务 A 第一次查询时候有 n 条记录，但是第二次同等条件下查询却有 n+1 条记录，这就好像产生了幻觉。发生幻读的原因也是另外一个事务新增或者删除或者修改了第一个事务结果集里面的数据，同一个记录的数据内容被修改了，所有数据行的记录就变多或者变少了</span><br><span class="line">Select * from  emp where empid &gt; 100 for update;</span><br></pre></td></tr></table></figure>
<h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>在<code>Innodb</code>引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候只锁住一行呢？ 只有通过<strong>索引条件</strong>检索数据，<code>InnoDB</code>才使用行级锁，否则，<code>InnoDB</code>将使用表锁，而检索条件是<code>unique key</code>、<code>primary key</code>时，一定会是<strong>行锁</strong>，而检索条件是<code>index</code>时，有可能是行锁 ，也有可能是表锁，取决于当“值重复率”低时，甚至接近主键或者唯一索引的效果，“普通索引”依然是行锁；当“值重复率”高时，<code>MySQL</code> 不会把这个“普通索引”当做索引，即造成了一个没有索引的 SQL，此时引发表锁</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>死锁（Deadlock）是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。<br>解除正在死锁的状态有两种方法：<br>第一种：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查询是否锁表</span><br><span class="line">show OPEN TABLES where In_use &gt; 0;</span><br><span class="line"># 查询进程（如果您有SUPER权限，您可以看到所有线程。否则，您只能看到您自己的线程）</span><br><span class="line">show processlist</span><br><span class="line"># 杀死进程id（就是上面命令的id列）</span><br><span class="line">kill id</span><br></pre></td></tr></table></figure></p>
<p>第二种：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看当前的事务</span><br><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;</span><br><span class="line"># 查看当前锁定的事务</span><br><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;</span><br><span class="line"># 查看当前等锁的事务</span><br><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;</span><br><span class="line"># 杀死进程</span><br><span class="line">kill 进程ID</span><br></pre></td></tr></table></figure></p>
<h3 id="MYISAM引擎-和-INNODB引擎的区别"><a href="#MYISAM引擎-和-INNODB引擎的区别" class="headerlink" title="MYISAM引擎 和 INNODB引擎的区别"></a>MYISAM引擎 和 INNODB引擎的区别</h3><h4 id="MYISAM-读锁"><a href="#MYISAM-读锁" class="headerlink" title="MYISAM 读锁"></a>MYISAM 读锁</h4><p>读锁 影响其他进程对该表进行写操作，但不影响其他进程对该表进行读操作<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lock myisam_table read;</span><br><span class="line">select * from myisam_table where id &#x3D; 1;</span><br><span class="line">UNLOCK TABLES;</span><br></pre></td></tr></table></figure></p>
<h4 id="MYISAM-写锁"><a href="#MYISAM-写锁" class="headerlink" title="MYISAM 写锁"></a>MYISAM 写锁</h4><p>写锁 影响其他进程对该表进行读和写操作<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lock myisam_table write;</span><br><span class="line">select * from myisam_table where id &#x3D; 1;</span><br><span class="line">UNLOCK TABLES;</span><br></pre></td></tr></table></figure><br>在自动加锁的情况下也基本如此，<code>MyISAM</code> 总是一次获得 <code>SQL</code> 语句所需要的全部锁。这也正是 <code>MyISAM</code> 表不会出现死锁(<code>Deadlock Free</code>)的原因</p>
<ul>
<li><code>InnoDB</code>支持事务(<code>transaction</code>)；<code>MyISAM</code>不支持事务</li>
<li><code>Innodb</code> 默认采用行锁， <code>MyISAM</code> 是默认采用表锁。加锁可以保证事务的一致性，可谓是有人(锁)的地方，就有江湖(事务)</li>
<li><code>MyISAM</code>不适合高并发（MyISAM 在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行更新操作 (UPDATE、DELETE、INSERT 等)前，会自动给涉及的表加写锁）<blockquote>
<p>MyISAM存储引擎有一个系统变量concurrent_insert,专门用以控制其并发插入的行为,其值分别可以为0、1或2。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当concurrent_insert设置为0时,不允许并发插入。</span><br><span class="line">当concurrent_insert设置为1时,如果MyISAM表中没有空洞(即表的中间没有被删除的 行),MyISAM允许在一个进程读表的同时,另一个进程从表尾插入记录。这也是MySQL 的默认设置。</span><br><span class="line">当concurrent_insert设置为2时,无论MyISAM表中有没有空洞,都允许在表尾并发插入记录</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>我们采用<strong>乐观锁</strong> 来处理这次的定时任务多节点执行时分布式锁方案</p>
<ul>
<li><p>表结构设计</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE &#96;job_lock&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  &#96;name&#96; varchar(255) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;job名称&#39;,</span><br><span class="line">  &#96;timeout&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;任务执行超时间隔,毫秒&#39;,</span><br><span class="line">  &#96;status&#96; tinyint(4) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;job状态：0-空闲，1-运行&#39;,</span><br><span class="line">  &#96;description&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;job描述&#39;,</span><br><span class="line">  &#96;gmt_create&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_update&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;,</span><br><span class="line">  &#96;version&#96; bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;版本&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin;</span><br></pre></td></tr></table></figure>
</li>
<li><p>加锁方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;update id&#x3D;&quot;requireLock&quot; parameterType&#x3D;&quot;java.util.Map&quot;&gt;</span><br><span class="line">&lt;![CDATA[</span><br><span class="line">    update job_lock</span><br><span class="line">    set status &#x3D; 1, version&#x3D;version + 1</span><br><span class="line">    where id &#x3D; #&#123;id&#125; and version &#x3D;#&#123;version&#125; and status &#x3D; 0</span><br><span class="line">]]&gt;</span><br><span class="line">&lt;&#x2F;update&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>解锁方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;update id&#x3D;&quot;releaseLock&quot; parameterType&#x3D;&quot;java.util.Map&quot;&gt;</span><br><span class="line">&lt;![CDATA[</span><br><span class="line">    update job_lock</span><br><span class="line">    set status &#x3D; 0</span><br><span class="line">    where id &#x3D; #&#123;id&#125; and status &#x3D; 1</span><br><span class="line">]]&gt;</span><br><span class="line">&lt;&#x2F;update&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>尝试加锁</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public JobLockDO tryLock(String name) &#123;</span><br><span class="line">  if (ValidateUtils.isNull(name))&#123;</span><br><span class="line">    return null;</span><br><span class="line">  &#125;</span><br><span class="line">  JobLockDO jobLocksDO &#x3D; getJob(name);</span><br><span class="line">  if (ValidateUtils.isNull(jobLocksDO)) &#123;</span><br><span class="line">    return null;</span><br><span class="line">  &#125;</span><br><span class="line">  &#x2F;&#x2F; 任务一直在运行中，可能是服务重启等异常情况，造成锁状态一直未更新</span><br><span class="line">  if (jobLocksDO.getStatus().equals(Constant.JOB_LOCK_RUNNING)) &#123;</span><br><span class="line">    &#x2F;&#x2F; 先判断运行是否超时，未超时，则不处理</span><br><span class="line">    if (System.currentTimeMillis() - jobLocksDO.getGmtUpdate().getTime() &lt;&#x3D; jobLocksDO.getTimeout()) &#123;</span><br><span class="line">      return null;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      &#x2F;&#x2F; 已超时，更新任务锁状态(释放锁)</span><br><span class="line">      releaseLock(jobLocksDO.getId());</span><br><span class="line">      &#x2F;&#x2F; 重新加锁</span><br><span class="line">      requireLock(jobLocksDO.getId(), jobLocksDO.getVersion());</span><br><span class="line">      &#x2F;&#x2F; 返回任务锁</span><br><span class="line">      return jobLocksDO;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  try &#123;</span><br><span class="line">    &#x2F;&#x2F; 加锁</span><br><span class="line">    if (!requireLock(jobLocksDO.getId(), jobLocksDO.getVersion())) &#123;</span><br><span class="line">      return null;</span><br><span class="line">    &#125;</span><br><span class="line">    return jobLocksDO;</span><br><span class="line">  &#125; catch (Exception e) &#123;</span><br><span class="line">    LOGGER.error(&quot;require lock by name:&#123;&#125; fail.&quot;, name, e);</span><br><span class="line">  &#125;</span><br><span class="line">  return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次线上fgc排查过程</title>
    <url>/2022/01/19/java_full_gc/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>用户反馈api请求时快时慢，慢的时候网页打开很久都没有结果，直到超时给出500错误</p>
<h3 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h3><h4 id="初步怀疑"><a href="#初步怀疑" class="headerlink" title="初步怀疑"></a>初步怀疑</h4><p>当前程序分布式部署在多个节点上，通过<code>vip</code>进行负载均衡，所以对于直接将反馈慢的页面打开的请求通过<code>curl</code>方式登陆生产环境所有节点，进行轮训一遍，发现其中02节点需要等待很久，其他节点均正常，所以问题应该出在02节点，<br>注意：这个定位过程当然也可以使用监控图就一目了然了。推荐使用<code>grafana prometheus spring boot dashboard</code>在<code>google</code>搜寻下相关配置就可以了。<br><img src="/images/java/fgc/8.png" alt="cgi"></p>
<h4 id="查询该节点负载"><a href="#查询该节点负载" class="headerlink" title="查询该节点负载"></a>查询该节点负载</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 得到进程的pid</span><br><span class="line">jps -mlv </span><br><span class="line"># 通过top命令查询节点实际负载</span><br><span class="line">top -Hp pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/1.png" alt="cgi"></p>
<blockquote>
<p>通过top命令发现该节点memory使用了接近<code>90%</code>，怀疑出现内存泄露</p>
</blockquote>
<h4 id="查询该节点内存使用情况"><a href="#查询该节点内存使用情况" class="headerlink" title="查询该节点内存使用情况"></a>查询该节点内存使用情况</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jstat -gcutil pid 1000</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/2.png" alt="cgi"></p>
<blockquote>
<p>如我所料，几乎不到<code>1s</code>就开始做一次<code>fgc</code>，所以服务才越来越慢响应</p>
</blockquote>
<h3 id="内存分析"><a href="#内存分析" class="headerlink" title="内存分析"></a>内存分析</h3><h4 id="使用jmap分析内存概要"><a href="#使用jmap分析内存概要" class="headerlink" title="使用jmap分析内存概要"></a>使用jmap分析内存概要</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -heap pid ｜ head -n20</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/10.png" alt="cgi"></p>
<h4 id="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"><a href="#使用jmap打印堆内存的对象，带上live，则只统计活着的对象" class="headerlink" title="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"></a>使用jmap打印堆内存的对象，带上live，则只统计活着的对象</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -histo pid ｜ head -n20</span><br><span class="line">jmap -histo:live pid ｜ head -n20</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/11.png" alt="cgi"></p>
<h4 id="打印进程的内存使用情况"><a href="#打印进程的内存使用情况" class="headerlink" title="打印进程的内存使用情况"></a>打印进程的内存使用情况</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jmap -dump:format&#x3D;b,file&#x3D;dumpFileName pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/3.png" alt="cgi"></p>
<blockquote>
<p>dump出来了<code>12G</code>的文件，通过scp工具转存到本地</p>
</blockquote>
<h4 id="jprofiler分析堆内存"><a href="#jprofiler分析堆内存" class="headerlink" title="jprofiler分析堆内存"></a>jprofiler分析堆内存</h4><ul>
<li>1、把dumpFileName文件转存为.hprof格式后直接双击打开，按照instance count逆序排列<br><img src="/images/java/fgc/5.png" alt="cgi"></li>
<li>2、会发现有hashmap类型占了最大头，但是这个类型，双击它，选择<code>merged incoming reference</code>，查看合并后的来源引用统计<br><img src="/images/java/fgc/6.png" alt="cgi"></li>
<li>3、还是选最大头的文件数一直拆到最里层，找出来源引用是<code>org.apache.ibatis.executor.result.DefaultResultHandler</code>这个类，基本能定位到问题根源了，是我们连接<code>clickhouse</code>客户端去查询结果时，未对结果集做限制，导致了一个很大的结果集返回到内存中。<br><img src="/images/java/fgc/7.png" alt="cgi"></li>
</ul>
<h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>当然是对结果集做限制，检测用户输入的sql，是否包含limit条数限制，若未限制，则对sql进行改写，增加<code>500</code>条数限制<br><img src="/images/java/fgc/9.png" alt="cgi"></p>
<h3 id="GC的运行原理"><a href="#GC的运行原理" class="headerlink" title="GC的运行原理"></a>GC的运行原理</h3><p><code>GC</code>（<code>garbage collection</code>）：垃圾回收，主要是指<code>YGC</code>和<code>FGC</code><br><code>YGC</code>（minor garbage collection）：新生代垃圾回收<br><code>FGC</code>（major garbage collection）：老年代垃圾回收</p>
<h4 id="堆内存结构"><a href="#堆内存结构" class="headerlink" title="堆内存结构"></a>堆内存结构</h4><p><img src="/images/java/fgc/12.png" alt="cgi"><br>堆内存采用了分代结构，包括新生代和老年代，新生代分为：<code>eden</code>区、<code>from survivor</code>区（简称<code>s0</code>）、<code>to survivor</code>区（简称<code>s1</code>），三者默认比例上8:1:1，另外新生代和老年代的比例则是1:2。<br>堆内存之所以采用分代结构，是因为绝大多数对象都是短生命周期的，这样设计可以把不同的生命周期的对象放在不同的区域中，然后针对新生代和老年代采用不同的垃圾回收算法，从而使得<code>GC</code>效率最高。</p>
<h4 id="YGC是什么时候触发的？"><a href="#YGC是什么时候触发的？" class="headerlink" title="YGC是什么时候触发的？"></a>YGC是什么时候触发的？</h4><p>大多数情况下，对象直接在年轻代中的<code>Eden</code>区进行分配，如果<code>Eden</code>区域没有足够的空间，那么就会触发<code>YGC</code>（<code>Minor GC</code>），<code>YGC</code>处理的区域只有新生代。因为大部分对象在短时间内都是可收回掉的，因此YGC后只有极少数的对象能存活下来，而被移动到S0区（采用的是复制算法）。<br>当触发下一次YGC时，会将Eden区和S0区的存活对象移动到S1区，同时清空Eden区和S0区。当再次触发YGC时，这时候处理的区域就变成了Eden区和S1区（即S0和S1进行角色交换）。每经过一次YGC，存活对象的年龄就会加1。</p>
<h4 id="FGC是什么时候触发的？"><a href="#FGC是什么时候触发的？" class="headerlink" title="FGC是什么时候触发的？"></a>FGC是什么时候触发的？</h4><ul>
<li><p>1、<code>YGC</code>时，<code>To Survivor</code>区不足以存放存活的对象，对象会直接进入到老年代。经过多次<code>YGC</code>后，如果存活对象的年龄达到了设定阈值，则会晋升到老年代中。动态年龄判定规则，<code>To Survivor</code>区中相同年龄的对象，如果其大小之和占到了 <code>To Survivor</code> 区一半以上的空间，那么大于此年龄的对象会直接进入老年代，而不需要达到默认的分代年龄。大对象：由<code>-XX:PretenureSizeThreshold</code>启动参数控制，若对象大小大于此值，就会绕过新生代, 直接在老年代中分配。当晋升到老年代的对象大于了老年代的剩余空间时，就会触发<code>FGC</code>（<code>Major GC</code>），<code>FGC</code>处理的区域同时包括新生代和老年代。老年代的内存使用率达到了一定阈值（可通过参数调整），直接触发<code>FGC</code>。</p>
</li>
<li><p>2、空间分配担保：在<code>YGC</code>之前，会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，说明<code>YGC</code>是不安全的，则会查看参数 <code>HandlePromotionFailure</code> 是否被设置成了允许担保失败，如果不允许则直接触发<code>Full GC</code>；如果允许，那么会进一步检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于也会触发 <code>Full GC</code>。</p>
</li>
<li><p>3、<code>Metaspace</code>（元空间）在空间不足时会进行扩容，当扩容到了<code>-XX:MetaspaceSize</code> 参数的指定值时，也会触发<code>FGC</code>。</p>
</li>
<li><p>4、<code>System.gc</code>() 或者<code>Runtime.gc</code>() 被显式调用时，触发<code>FGC</code>。</p>
</li>
</ul>
<h4 id="GC对程序会产生什么影响"><a href="#GC对程序会产生什么影响" class="headerlink" title="GC对程序会产生什么影响"></a>GC对程序会产生什么影响</h4><p>不管是YGC还是FGC，都会造成一定程度上的程序卡顿（stop the world问题：GC线程开始工作，其他工作线程被挂起），即使采用ParNew、CMS、G1这些更先进的垃圾回收算法，也只是减少卡顿的时间，并不能完全消除卡顿</p>
<ul>
<li>FGC过于频繁：<br>FGC通常是比较慢的，少则几百号秒，多则几秒，正常情况下FGC每隔几个小时或者几天才会执行一次，对系统的影响是可接受的，所以一旦出现FGC频繁（比如几分钟/几十分钟出现一次）会导致工作线程频繁被停掉，让系统看起来就一直卡顿，使得程序的整体性能变差。</li>
<li>YGC耗时过长：<br>一般来说YGC的总耗时指需要几十毫秒或上百毫秒，对于系统来说几乎无感知，所以如果YGC耗时达到1秒甚至几秒（快赶上FGC的耗时），那么卡顿就会加剧，加上YGC本身会比较频繁发生，就可能导致服务响应时间超时。</li>
<li>FGC耗时过长：<br>FGC耗时增加，卡顿时间也会随之增加，尤其对于高并发服务，可能导致FGC期间比较多的超时问题，可用性降低，这种也需要关注</li>
<li>YGC过于频繁：<br>即使YGC不会引起服务超时，但是YGC过于频繁也会降低服务的整体性能，对于高并发服务也是需要关注的。</li>
</ul>
<blockquote>
<p>其中，「FGC过于频繁」和「YGC耗时过长」，这两种情况属于比较典型的GC问题，大概率会对程序的服务质量产生影响。剩余两种情况的严重程度低一些，但是对于高并发或者高可用的程序也需要关注。</p>
</blockquote>
<h4 id="导致FGC的原因总结"><a href="#导致FGC的原因总结" class="headerlink" title="导致FGC的原因总结"></a>导致FGC的原因总结</h4><ul>
<li>大对象：系统一次性加载了过多数据到内存中（比如SQL查询未做分页），导致大对象进入了老年代。（即本文中的案例）</li>
<li>内存泄漏：频繁创建了大量对象，但是无法被回收（比如IO对象使用完后未调用close方法释放资源），先引发FGC，最后导致OOM.</li>
<li>程序频繁生成一些长生命周期的对象，当这些对象的存活年龄超过分代年龄时便会进入老年代，最后引发FGC. </li>
<li>程序BUG导致动态生成了很多新类，使得 Metaspace 不断被占用，先引发FGC，最后导致OOM.</li>
<li>代码中显式调用了gc方法，包括自己的代码甚至框架中的代码。</li>
<li>JVM参数设置问题：包括总内存大小、新生代和老年代的大小、Eden区和S区的大小、元空间大小、垃圾回收算法等等。</li>
</ul>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql在使用order by limit时出现数据重复的问题</title>
    <url>/2019/12/04/mysql-priority-que/</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>用户反馈说分页数据重复，查看日志，发现说这样的sql：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select column1,column2 </span><br><span class="line">from table</span><br><span class="line">where columnx &#x3D; &#39;xxx&#39;</span><br><span class="line">order by columny</span><br><span class="line">limit current,size</span><br></pre></td></tr></table></figure></p>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul>
<li>mysql版本<br>mysql5.7.20<br>查看mysql的<a href="https://dev.mysql.com/doc/relnotes/mysql/5.6/en/news-5-6-16.html" target="_blank" rel="noopener">changes list</a>  <blockquote>
<p>MySQL 5.6 has only one way one can check whether filesort used priority queue. You need to enable optimizer_trace (set optimizer_trace=1), and then run the query (not EXPLAIN, but the query itself). Then, you can look into the optimizer trace </p>
</blockquote>
</li>
<li>order by<br>MySQL 执行查询语句， 对于order by谓词，可能会使用filesort或者temporary。比如explain一条语句的时候，会看到Extra字段中可能会出现，using filesort和using temporary。下面我们就来探讨下两个的区别和适用场景。</li>
<li>filesort<br>filesort主要用于查询数据结果集的排序操作，首先MySQL会使用<strong>sort_buffer_size</strong>大小的内存进行排序，如果结果集超过了<strong>sort_buffer_size</strong>大小，会把这一个排序后的<strong>chunk</strong>转移到<strong>file</strong>上，最后使用<strong>多路归并排序</strong>完成所有数据的排序操作。<br>filesort有两种使用模式:<br>模式1: sort的item保存了所需要的所有字段，排序完成后，没有必要再回表扫描。<br>模式2: sort的item仅包括，待排序完成后，根据rowid查询所需要的columns。<blockquote>
<p>很明显，模式1能够极大的减少回表的随机IO。</p>
</blockquote>
</li>
<li>priority query</li>
</ul>
<ol>
<li>打开optimizer_trace<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; set session optimizer_trace&#x3D;’enabled&#x3D;on&#39;;</span><br></pre></td></tr></table></figure></li>
<li>查询information_schema.optimizer_trace表<br>主要分为三个部分<br>join_preparation：SQL的准备阶段，sql被格式化<br>对应函数 JOIN::prepare<br>join_optimization：SQL优化阶段<br>对应函数JOIN::optimize<br>join_execution：SQL执行阶段<br>对应函数：JOIN::exec</li>
<li>查看sql执行阶段<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;join_execution&quot;: &#123;</span><br><span class="line">&quot;select#&quot;: 1,</span><br><span class="line">&quot;steps&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">    &quot;filesort_information&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">        &quot;direction&quot;: &quot;asc&quot;,</span><br><span class="line">        &quot;table&quot;: &quot;&#96;film&#96;&quot;,</span><br><span class="line">        &quot;field&quot;: &quot;actor_age&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;filesort_priority_queue_optimization&quot;: &#123;</span><br><span class="line">        &quot;usable&quot;: false,</span><br><span class="line">        &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;filesort_execution&quot;: [</span><br><span class="line">    ],</span><br><span class="line">    &quot;filesort_summary&quot;: &#123;</span><br><span class="line">        &quot;rows&quot;: 1,</span><br><span class="line">        &quot;examined_rows&quot;: 5,</span><br><span class="line">        &quot;number_of_tmp_files&quot;: 0,</span><br><span class="line">        &quot;sort_buffer_size&quot;: 261872,</span><br><span class="line">        &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
当使用order by limit时，filesort_priority_queue_optimization给出的useable为true，在mysql5.6之后（包括5.6）做了一个优化，即<strong>priority queue</strong>，使用<strong>priority queue</strong>的目的是为了加快查询，如果sql中未使用到索引有序性时，<strong>order by limit</strong>会在满足<strong>buffer size</strong>设置后返回只保证返回<strong>limit size</strong>，但不保证排序出来的结果和读出来的数据顺序一致，这就是堆排序对效果，先select出符合条件的rows，再order by column，如果这个column没有明确的唯一性，则再limit后，只是会随机出limit的size条数，这个随机性不保证数据是否重复<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3></li>
</ol>
<ul>
<li>使用有序索引排序<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select from table where xx order by column desc,id desc limit size</span><br></pre></td></tr></table></figure></li>
<li>给order by 的column加上索引<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table add index (column)</span><br></pre></td></tr></table></figure></li>
<li>强制使用索引<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select from table force index(column) order by column limit size</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql5.7忘记root密码</title>
    <url>/2020/07/16/mysql5.7-forget-password/</url>
    <content><![CDATA[<ul>
<li>关闭mysqld<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep mysqld | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9</span><br></pre></td></tr></table></figure></li>
<li>修改my.conf<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.conf</span><br><span class="line"># 找到[mysqld]这个section,添加skip-grant-tables,意思是忽略所有表的授权</span><br><span class="line">skip-grant-tables</span><br></pre></td></tr></table></figure></li>
<li>开启mysqld服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqld &amp;</span><br></pre></td></tr></table></figure></li>
<li>进入mysql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -u root</span><br><span class="line">mysql&gt; use mysql;</span><br><span class="line">mysql&gt; update mysql.user set authentication_string&#x3D;password(&#39;new password&#39;) where user&#x3D;&#39;root&#39;;</span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure></li>
<li>撤回skip-grant-tables<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.conf</span><br><span class="line"># 找到[mysqld]这个section,注释掉skip-grant-tables</span><br></pre></td></tr></table></figure></li>
<li>重启mysqld<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep mysqld | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9</span><br><span class="line">mysqld &amp;</span><br></pre></td></tr></table></figure></li>
<li>密码登录mysql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">#输入刚配置的新密码</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql8忘记root密码</title>
    <url>/2020/09/03/mysql8-forget-password%20copy/</url>
    <content><![CDATA[<ul>
<li>关闭mysqld<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep mysqld | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9</span><br></pre></td></tr></table></figure></li>
<li>修改my.conf<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.conf</span><br><span class="line"># 找到[mysqld]这个section,添加skip-grant-tables,意思是忽略所有表的授权</span><br><span class="line">skip-grant-tables</span><br></pre></td></tr></table></figure></li>
<li>开启mysqld服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqld &amp;</span><br></pre></td></tr></table></figure></li>
<li>进入mysql，设置密码为空<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -u root</span><br><span class="line">mysql&gt; use mysql;</span><br><span class="line">mysql&gt; update user set authentication_string&#x3D;&#39;&#39; where user&#x3D;&#39;root&#39;;</span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure></li>
<li>撤回skip-grant-tables<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;my.conf</span><br><span class="line"># 找到[mysqld]这个section,注释掉skip-grant-tables</span><br></pre></td></tr></table></figure></li>
<li>重启mysqld<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep mysqld | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9</span><br><span class="line">mysqld &amp;</span><br></pre></td></tr></table></figure></li>
<li>无密码登录mysql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line"></span><br><span class="line">mysql&gt; use mysql;</span><br><span class="line">mysql&gt; ALTER user &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;Qian123#&#39;;</span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>next模板页面空白解决方法</title>
    <url>/2019/11/27/next-package-blank/</url>
    <content><![CDATA[<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>+出现markdown语法出错</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>在markdown语法里，不用使用”&lt;&gt;/“这些尖括号斜杆，不然会被markdown反解析后就有语法错误了!<br>全文搜索有出现有出现就替换掉！</p>
<h2 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h2><p>从github仓库clone后，没有next目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls themes&#x2F;next</span><br></pre></td></tr></table></figure><br>是否为空？</p>
<h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><p>如果确实是空的<br>则重新clone next仓库到指定目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -fr themes&#x2F;next</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-theme-next.git next</span><br><span class="line">&#x2F;&#x2F; 修改主题</span><br><span class="line">cd themes&#x2F;next&#x2F;</span><br><span class="line">vim _config.yml</span><br><span class="line">&#x2F;&#x2F; scheme: Pisces</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次线上core dump</title>
    <url>/2022/01/19/linux_min_free_kbytes/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>官方解释<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">min_free_kbytes:</span><br><span class="line">This is used to force the Linux VM to keep a minimum number</span><br><span class="line">of kilobytes free.  The VM uses this number to compute a</span><br><span class="line">watermark[WMARK_MIN] value for each lowmem zone in the system.</span><br><span class="line">Each lowmem zone gets a number of reserved free pages based</span><br><span class="line">proportionally on its size.</span><br><span class="line">Some minimal amount of memory is needed to satisfy PF_MEMALLOC</span><br><span class="line">allocations; if you set this to lower than 1024KB, your system will</span><br><span class="line">become subtly broken, and prone to deadlock under high loads.</span><br><span class="line">Setting this too high will OOM your machine instantly.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo 3145728 &gt;&gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;min_free_kbytes</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sysctl -a | grep min_free</span><br></pre></td></tr></table></figure>
<p><img src="/images/min_free_kbytes/2.png" alt="docker-bridge"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -a | grep oom</span><br></pre></td></tr></table></figure>
<p><img src="/images/min_free_kbytes/1.png" alt="docker-bridge"></p>
<p>min_free_kbytes大小的影响<br>min_free_kbytes设的越大，watermark的线越高，同时三个线之间的buffer量也相应会增加。这意味着会较早的启动kswapd进行回收，且会回收上来较多的内存（直至watermark[high]才会停止），这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量。极端情况下设置min_free_kbytes接近内存大小时，留给应用程序的内存就会太少而可能会频繁地导致OOM的发生。</p>
<p>min_free_kbytes设的过小，则会导致系统预留内存过小。kswapd回收的过程中也会有少量的内存分配行为（会设上PF_MEMALLOC）标志，这个标志会允许kswapd使用预留内存；另外一种情况是被OOM选中杀死的进程在退出过程中，如果需要申请内存也可以使用预留部分。这两种情况下让他们使用预留内存可以避免系统进入deadlock状态。</p>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的linux排查命令</title>
    <url>/2023/01/04/linux%E5%B8%B8%E7%94%A8%E6%8E%92%E6%9F%A5%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="如何看查占用cpu最多的进程？"><a href="#如何看查占用cpu最多的进程？" class="headerlink" title="如何看查占用cpu最多的进程？"></a>如何看查占用cpu最多的进程？</h2><ul>
<li><p>方法一<br>核心指令：ps<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps H -eo pid,pcpu | sort -nk2 | tail</span><br></pre></td></tr></table></figure>
<p>执行效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[work@test01 ~]$ ps H -eo pid,pcpu | sort -nk2 | tail</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">30904  1.0</span><br><span class="line">30914  1.0</span><br></pre></td></tr></table></figure>
<p>结果：<br>瞧见了吧，最耗cpu的pid=30914。<br>画外音：实际上是31396。</p>
</li>
<li><p>方法二<br>核心指令：top<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top</span><br><span class="line">Shift + t</span><br></pre></td></tr></table></figure>
<h2 id="找到了最耗CPU的进程ID，对应的服务名是什么呢？"><a href="#找到了最耗CPU的进程ID，对应的服务名是什么呢？" class="headerlink" title="找到了最耗CPU的进程ID，对应的服务名是什么呢？"></a>找到了最耗CPU的进程ID，对应的服务名是什么呢？</h2></li>
<li><p>方法一<br>核心指令：ps<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | fgrep pid</span><br></pre></td></tr></table></figure>
<p>执行效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[work@test01 ~]$ ps aux | fgrep 30914</span><br><span class="line">work 30914  1.0  0.8 309568 71668 ?  Sl   Feb02 124:44 .&#x2F;router2 –conf&#x3D;rs.conf</span><br></pre></td></tr></table></figure>
<p>结果：<br>瞧见了吧，进程是./router2</p>
</li>
<li><p>方法二<br>直接查proc即可。<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ll &#x2F;proc&#x2F;pid</span><br></pre></td></tr></table></figure>
<p>执行效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[work@test01 ~]$ ll &#x2F;proc&#x2F;30914</span><br><span class="line">lrwxrwxrwx  1 work work 0 Feb 10 13:27 cwd -&gt; &#x2F;home&#x2F;work&#x2F;im-env&#x2F;router2</span><br><span class="line">lrwxrwxrwx  1 work work 0 Feb 10 13:27 exe -&gt; &#x2F;home&#x2F;work&#x2F;im-env&#x2F;router2&#x2F;router2</span><br></pre></td></tr></table></figure>
<p>画外音：这个好，全路径都出来了。</p>
</li>
</ul>
<h2 id="如何查看某个端口的连接情况？"><a href="#如何查看某个端口的连接情况？" class="headerlink" title="如何查看某个端口的连接情况？"></a>如何查看某个端口的连接情况？</h2><ul>
<li><p>方法一<br>核心指令：netstat<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -lap | fgrep port</span><br></pre></td></tr></table></figure>
<p>执行效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[work@test01 ~]$ netstat -lap | fgrep 22022</span><br><span class="line">tcp        0      0 1.2.3.4:22022          *:*                         LISTEN      31396&#x2F;imui</span><br><span class="line">tcp        0      0 1.2.3.4:22022          1.2.3.4:46642          ESTABLISHED 31396&#x2F;imui</span><br><span class="line">tcp        0      0 1.2.3.4:22022          1.2.3.4:46640          ESTABLISHED 31396&#x2F;imui</span><br></pre></td></tr></table></figure>
</li>
<li><p>方法二<br>核心指令：lsof<br>实际命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof -i :port</span><br></pre></td></tr></table></figure>
<p>执行效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[work@test01 ~]$ &#x2F;usr&#x2F;sbin&#x2F;lsof -i :22022</span><br><span class="line">COMMAND   PID USER   FD   TYPE   DEVICE SIZE NODE NAME</span><br><span class="line">router  30904 work   50u  IPv4 69065770       TCP 1.2.3.4:46638-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br><span class="line">router  30904 work   51u  IPv4 69065772       TCP 1.2.3.4:46639-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br><span class="line">router  30904 work   52u  IPv4 69065774       TCP 1.2.3.4:46640-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br></pre></td></tr></table></figure>
<p>学废了吗？</p>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>sre</tag>
      </tags>
  </entry>
  <entry>
    <title>使用nginx搭建加密的文件服务器</title>
    <url>/2020/05/07/nginx-file-server/</url>
    <content><![CDATA[<ul>
<li>安装epel<br>EPEL 仓库中有 Nginx 的安装包。如果你还没有安装过 EPEL，可以通过运行下面的命令来完成安装：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install epel-release</span><br></pre></td></tr></table></figure></li>
<li>安装nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install nginx</span><br></pre></td></tr></table></figure></li>
<li>配置文件<ul>
<li>日志文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log</span><br><span class="line"> &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log</span><br></pre></td></tr></table></figure></li>
<li>conf文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;</span><br></pre></td></tr></table></figure></li>
<li>项目文件<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;var&#x2F;www&#x2F;html&#x2F;&lt;site_name&gt;</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;&lt;site_name&gt;</span><br></pre></td></tr></table></figure></li>
<li>nginx命令<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;nginx</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>启动nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;nginx</span><br></pre></td></tr></table></figure></li>
<li>生成密钥<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用openssl生成密钥</span><br><span class="line">printf &quot;admin:$(openssl passwd -crypt 123456)\n&quot; &gt;&gt; &#x2F;etc&#x2F;nginx&#x2F;conf&#x2F;htpasswd</span><br><span class="line">cat &#x2F;etc&#x2F;nginx&#x2F;conf&#x2F;htpasswd</span><br><span class="line">admin:xyJkVhXGAZ8tM</span><br><span class="line"># 使用htpasswd生成密钥</span><br><span class="line">yum install httpd-tools -y</span><br><span class="line">htpasswd -c -d &#x2F;etc&#x2F;nginx&#x2F;conf&#x2F;htpasswd admin</span><br></pre></td></tr></table></figure></li>
<li>添加server配置<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">  listen       80;</span><br><span class="line">  server_name  localhost;</span><br><span class="line"></span><br><span class="line">  auth_basic   &quot;登录认证&quot;;</span><br><span class="line">  auth_basic_user_file &#x2F;etc&#x2F;nginx&#x2F;conf&#x2F;htpasswd;</span><br><span class="line"></span><br><span class="line">  autoindex on;</span><br><span class="line">  autoindex_exact_size on; #显示文件大小</span><br><span class="line">  autoindex_localtime on; #显示文件时间</span><br><span class="line"></span><br><span class="line">  root   &#x2F;var&#x2F;www&#x2F;html;</span><br><span class="line">  index  index.html index.php</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>重启nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;nginx -s reload</span><br></pre></td></tr></table></figure>
<img src="/images/nginx-file-server.png" alt="nginx-file-server"></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7源码安装nginx</title>
    <url>/2020/08/11/nginx-install/</url>
    <content><![CDATA[<h3 id="yum安装过程"><a href="#yum安装过程" class="headerlink" title="yum安装过程"></a>yum安装过程</h3><ul>
<li>安装nginx最新源<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum localinstall http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;centos&#x2F;7&#x2F;noarch&#x2F;RPMS&#x2F;nginx-release-centos-7-0.el7.ngx.noarch.rpm</span><br></pre></td></tr></table></figure></li>
<li>安装nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install nginx</span><br></pre></td></tr></table></figure></li>
<li>启动nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install nginx</span><br></pre></td></tr></table></figure></li>
<li>设置nginx开机启动<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable nginx.service</span><br><span class="line"># 检查是否成功</span><br><span class="line">systemctl list-dependencies | grep nginx</span><br></pre></td></tr></table></figure></li>
<li><p>通过 egrep 查询 nginx 服务器的用户和用户组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">egrep &#39;^(user|group)&#39; &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br></pre></td></tr></table></figure>
<ul>
<li>结果示例：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user nginx;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>路径整理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nginx 配置文件</span><br><span class="line">&#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line"></span><br><span class="line"># nginx 默认项目路径</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>web server</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>macbook多版本使用nodejs</title>
    <url>/2020/07/16/nvm/</url>
    <content><![CDATA[<blockquote>
<p>nvm:node version manager</p>
<ul>
<li>安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brew install nvm</span><br></pre></td></tr></table></figure></li>
<li>把nvm加入系统环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;source $(brew --prefix nvm)&#x2F;nvm.sh&quot; &gt;&gt; ~&#x2F;.bash_profile</span><br><span class="line">source ~&#x2F;.bash_profile</span><br></pre></td></tr></table></figure></li>
<li>查看远程版本<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm ls-remote</span><br></pre></td></tr></table></figure></li>
<li>安装指定的版本<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm install &lt;version&gt;</span><br></pre></td></tr></table></figure></li>
<li>安装稳定版本<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm install stable</span><br></pre></td></tr></table></figure></li>
<li>查看本地安装的版本列表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm ls</span><br></pre></td></tr></table></figure></li>
<li>使用某版本<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm use &lt;version&gt;</span><br></pre></td></tr></table></figure></li>
<li>删除某版本<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvm uninstall &lt;version&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7源码安装php7.2</title>
    <url>/2020/08/11/php7.2-install/</url>
    <content><![CDATA[<h3 id="yum安装过程"><a href="#yum安装过程" class="headerlink" title="yum安装过程"></a>yum安装过程</h3><ul>
<li>安装 EPEL 软件包<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br></pre></td></tr></table></figure></li>
<li>安装 remi 源<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install http:&#x2F;&#x2F;rpms.remirepo.net&#x2F;enterprise&#x2F;remi-release-7.rpm</span><br></pre></td></tr></table></figure></li>
<li>安装 yum 扩展包<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install yum-utils</span><br></pre></td></tr></table></figure></li>
<li>启用 remi 仓库<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum-config-manager --enable remi-php72</span><br><span class="line">yum update</span><br></pre></td></tr></table></figure></li>
<li>安装php7.2<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y php72-php-fpm php72-php-gd php72-php-json php72-php-mbstring php72-php-mysqlnd php72-php-xml php72-php-xmlrpc php72-php-opcache</span><br></pre></td></tr></table></figure></li>
<li>设置开机自启<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable php72-php-fpm.service</span><br></pre></td></tr></table></figure>
<h3 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h3></li>
<li>安装系统依赖<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br><span class="line">yum install autoconf libtool re2c bison libxml2-devel bzip2-devel libcurl-devel libpng-devel libicu-devel gcc-c++ libmcrypt-devel libwebp-devel libjpeg-devel openssl-devel -y</span><br></pre></td></tr></table></figure></li>
<li>下载源码<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -O -L https:&#x2F;&#x2F;github.com&#x2F;php&#x2F;php-src&#x2F;archive&#x2F;php-7.2.3.tar.gz</span><br><span class="line">tar -zxvf php-7.2.3.tar.gz</span><br><span class="line">cd php-src-php-7.2.3</span><br></pre></td></tr></table></figure></li>
<li>编译安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;buildconf --force</span><br><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php --enable-fpm --disable-short-tags --with-openssl --with-pcre-regex --with-pcre-jit --with-zlib --enable-bcmath --with-bz2 --enable-calendar --with-curl --enable-exif --with-gd --enable-intl --enable-mbstring --with-mysqli --enable-pcntl --with-pdo-mysql --enable-soap --enable-sockets --with-xmlrpc --enable-zip --with-webp-dir --with-jpeg-dir --with-png-dir</span><br><span class="line">make clean</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li>
<li>php-fpm setup<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.conf.default &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.conf</span><br><span class="line">cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.d&#x2F;www.conf.default &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.d&#x2F;www.conf</span><br><span class="line">cp php.ini-development &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.ini</span><br></pre></td></tr></table></figure></li>
<li>修改配置<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.ini</span><br><span class="line">expose_php &#x3D; Off</span><br><span class="line">short_open_tag &#x3D; ON</span><br><span class="line">max_execution_time &#x3D; 300</span><br><span class="line">max_input_time &#x3D; 300</span><br><span class="line">memory_limit &#x3D; 128M</span><br><span class="line">post_max_size &#x3D; 32M</span><br><span class="line">date.timezone &#x3D; Asia&#x2F;Shanghai</span><br><span class="line">mbstring.func_overload&#x3D;2</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.d&#x2F;www.conf</span><br><span class="line">listen &#x3D; &#x2F;var&#x2F;run&#x2F;www&#x2F;php-cgi.sock</span><br><span class="line">listen.owner &#x3D; www</span><br><span class="line">listen.group &#x3D; www</span><br><span class="line">listen.mode &#x3D; 0660</span><br><span class="line">listen.allowed_clients &#x3D; 127.0.0.1</span><br><span class="line">pm &#x3D; dynamic</span><br><span class="line">listen.backlog &#x3D; -1</span><br><span class="line">pm.max_children &#x3D; 180</span><br><span class="line">pm.start_servers &#x3D; 50</span><br><span class="line">pm.min_spare_servers &#x3D; 50</span><br><span class="line">pm.max_spare_servers &#x3D; 180</span><br><span class="line">request_terminate_timeout &#x3D; 120</span><br><span class="line">request_slowlog_timeout &#x3D; 50</span><br><span class="line">slowlog &#x3D; var&#x2F;log&#x2F;slow.log</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php-fpm.conf</span><br><span class="line">pid &#x3D; &#x2F;usr&#x2F;local&#x2F;php&#x2F;var&#x2F;run&#x2F;php-fpm.pid</span><br></pre></td></tr></table></figure>
<ul>
<li>php加入系统环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;bashrc</span><br><span class="line">export PHP_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;php</span><br><span class="line">export PATH&#x3D;$PHP_PATH&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li>
<li><p>启动php-fpm</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;local&#x2F;php&#x2F;sbin&#x2F;php-fpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改执行 php-fpm 的权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;opt&#x2F;remi&#x2F;php72&#x2F;php-fpm.d&#x2F;www.conf</span><br><span class="line"># 设置用户和用户组为 nginx</span><br><span class="line">user &#x3D; nginx</span><br><span class="line">group &#x3D; nginx</span><br></pre></td></tr></table></figure></li>
<li>路径整理<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;opt&#x2F;remi&#x2F;php72</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>php 5.3.3 以后的php-fpm 不再支持 php-fpm 以前具有的 /usr/local/php/sbin/php-fpm (start|stop|reload)等命令，所以不要再看这种老掉牙的命令了</p>
</blockquote>
<ul>
<li><p>使用信号控制</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INT, TERM 立刻终止</span><br><span class="line">QUIT 平滑终止</span><br><span class="line">USR1 重新打开日志文件</span><br><span class="line">USR2 平滑重载所有worker进程并重新载入配置和二进制模块</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看php-fpm的master进程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep php-fpm | grep -v grep</span><br></pre></td></tr></table></figure>
<p><img src="/images/php-fpm-process.png" alt="php-fpm-process"></p>
<ul>
<li>重启php-fpm<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 最后的一串数字就是master进程的id</span><br><span class="line">kill -USR2 44551</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>web server</category>
      </categories>
      <tags>
        <tag>php7.2</tag>
      </tags>
  </entry>
  <entry>
    <title>python的orm框架peewee使用介绍</title>
    <url>/2020/05/19/python-peewee/</url>
    <content><![CDATA[<blockquote>
<p>ORM(object relational mapping)对象关系映射，用来把对象模型表示的对象映射到基于SQL的关系型数据库结构中去，好处是我们在具体的操作实体对象时，不需要再去和复杂的sql语句打交道，只需要简单的操作实体对象的属性和方法。  </p>
</blockquote>
<ul>
<li>peewee介绍<ul>
<li>优点：<ul>
<li>Django式的API，使其易用 </li>
<li>轻量实现，很容易和任意web框架集成 </li>
</ul>
</li>
<li>缺点：<ul>
<li>不支持自动化 schema 迁移 </li>
<li>多对多查询写起来不直观  </li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>具体使用请访问peewee的<a href="http://docs.peewee-orm.com/en/latest/peewee/installation.html" target="_blank" rel="noopener">官方文档</a>  </p>
</blockquote>
<ul>
<li>安装peewee<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install pymysql</span><br><span class="line">pip install peewee</span><br></pre></td></tr></table></figure></li>
<li>自动创建model(库和表已经在mysql创建)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd project</span><br><span class="line">&#x2F;&#x2F; username是数据库用户名，host是数据库连接地址，database是数据库名</span><br><span class="line">python -m pwiz -e mysql -u username -H host --password database &gt; model.py</span><br><span class="line">&#x2F;&#x2F; 创建成功后会在model.py里看到对应的类名即表名驼峰</span><br></pre></td></tr></table></figure></li>
<li>新增<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from model import Person</span><br><span class="line">p &#x3D; Person(name&#x3D;&quot;xx&quot;,age&#x3D;18)</span><br><span class="line">p.save()</span><br></pre></td></tr></table></figure></li>
<li>删除<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">p &#x3D; Person.get(Person.id &#x3D;&#x3D; 1)</span><br><span class="line">p.delete_instance() # 返回删除的行数</span><br><span class="line">&#x2F;&#x2F; 或者</span><br><span class="line">query &#x3D; Person.delete().where(Person.id &#x3D;&#x3D; 1)</span><br><span class="line">query.execute() # 返回删除的行数</span><br></pre></td></tr></table></figure></li>
<li>修改<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">query &#x3D; Person.update(name&#x3D;&quot;yy&quot;).where(Person.id &#x3D;&#x3D; 1)</span><br><span class="line">query.execute() # 返回修改的行数</span><br></pre></td></tr></table></figure></li>
<li>查询<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 单条查询</span><br><span class="line">query &#x3D; Person.get(Person.id &#x3D;&#x3D; 1)</span><br><span class="line">print(query.name)</span><br><span class="line">&#x2F;&#x2F; 多条查询</span><br><span class="line">for query in Person.select().where(Person.id &#x3D;&#x3D; 1):</span><br><span class="line">  print(query.name)</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>virtualenv使用介绍</title>
    <url>/2020/05/19/python-virtualenv/</url>
    <content><![CDATA[<blockquote>
<p>为了让不同的应用有不同的python环境，相互之间隔绝，互相不影响，我们引入virtualenv。  </p>
</blockquote>
<ul>
<li>安装virtualenv<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure></li>
<li>创建虚拟环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd project</span><br><span class="line">virtualenv -p $(which python) venv</span><br></pre></td></tr></table></figure></li>
<li>打开虚拟环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source venv&#x2F;bin&#x2F;activate</span><br></pre></td></tr></table></figure>
<blockquote>
<p>(venv)  ~/Documents/code/python/project</p>
</blockquote>
</li>
<li>在虚拟环境安装模块<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install xx</span><br></pre></td></tr></table></figure></li>
<li>关闭虚拟环境<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure>
<blockquote>
<p>~/Documents/code/python/project</p>
</blockquote>
</li>
<li>在pycharm配置virtualenv<br><img src="/images/pycharm-virtualenv.png" alt="pycharm-virtualenv"><br><img src="/images/pycharm-virtualenv-1.png" alt="pycharm-virtualenv-1"><br><img src="/images/pycharm-virtualenv-2.png" alt="pycharm-virtualenv-2"></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>在centos7下安装python3</title>
    <url>/2020/05/19/python3-install/</url>
    <content><![CDATA[<blockquote>
<p>在<a href="https://www.python.org/ftp/python/中选择自己需要的python源码包，我下载的是python3.7.0" target="_blank" rel="noopener">https://www.python.org/ftp/python/中选择自己需要的python源码包，我下载的是python3.7.0</a>  </p>
</blockquote>
<ul>
<li>下载<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;www.python.org&#x2F;ftp&#x2F;python&#x2F;3.7.0&#x2F;Python-3.7.0.tgz</span><br></pre></td></tr></table></figure></li>
<li>解压<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxvf Python-3.7.0.tgz</span><br></pre></td></tr></table></figure></li>
<li><p>安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd Python-3.7.0</span><br><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python3</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<blockquote>
<p>安装完成没有提示错误便安装成功了  </p>
</blockquote>
</li>
<li><p>建立软连接</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;python3&#x2F;bin&#x2F;python3.7 &#x2F;usr&#x2F;bin&#x2F;python3</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;python3&#x2F;bin&#x2F;pip3.7 &#x2F;usr&#x2F;bin&#x2F;pip3</span><br></pre></td></tr></table></figure></li>
<li><p>测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python3 --version</span><br></pre></td></tr></table></figure>
</li>
<li><p>卸载python</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm -fr &#x2F;usr&#x2F;local&#x2F;python3</span><br><span class="line">sudo rm -fr &#x2F;usr&#x2F;bin&#x2F;python3</span><br><span class="line">sudo rm -fr &#x2F;usr&#x2F;bin&#x2F;pip3</span><br></pre></td></tr></table></figure>
</li>
<li><p>ssl错误</p>
<blockquote>
<p>Could not fetch URL <a href="https://pypi.org/simple/pip/" target="_blank" rel="noopener">https://pypi.org/simple/pip/</a>: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host=’pypi.org’, port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(“Can’t connect to HTTPS URL because the SSL module is not available.”)) - skipping</p>
</blockquote>
</li>
</ul>
<ol>
<li>安装openssl<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install openssl</span><br></pre></td></tr></table></figure></li>
<li><p>卸载python和pip</p>
</li>
<li><p>重新安装python</p>
</li>
</ol>
<ul>
<li>升级pip<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;get-pip.py | python</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>线程知识点</title>
    <url>/2021/10/20/thread-basic/</url>
    <content><![CDATA[<h3 id="进程是什么"><a href="#进程是什么" class="headerlink" title="进程是什么"></a>进程是什么</h3><blockquote>
<p>进程是一个具有独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统调度和进行资源分配和调度的一个独立单位，进程一般由程序、数据集合、进程控制块三部分组成</p>
<ul>
<li>程序：用于描述进程要完成的功能，是控制进程执行的指令集</li>
<li>数据集合：程序在执行时所需要的数据和工作区</li>
<li>进程控制块：Program Control Block，简称PCB，包含进程的描述信息和控制信息，是进程存在的唯一标示<br>进程由内存空间（代码、数据、进程空间、打开的文件）和一个或者多个线程组成<h3 id="线程是什么"><a href="#线程是什么" class="headerlink" title="线程是什么"></a>线程是什么</h3>线程是程序执行流的最小单元，是处理器调度和分派的基本单位，一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间（也就是所在进程的内存空间），一个标准的线程由线程ID、当前指令指针（PC）、寄存器和堆栈组成</li>
<li>什么是时间片<br>大部分操作系统（windows、linux）的任务调度都是采用时间片轮转的方式进行抢占式调度，在一个进程中，当 一个线程任务执行几毫秒后，会有操作系统的内核进行调度，通过硬件的计数器中断处理器让该线程强制暂停并将该线程的寄存器暂存到内存中，通过查看线程列表来决定下一个线程的执行，并从内存中恢复该线程的寄存器，在这个过程中，任务执行的那一小段时间就叫时间片，任务正在执行的状态就叫运行状态（RUNNABLE），被暂停的线程任务状态就叫就绪状态（WAITING），意为等待下一个时间片的到来。<br><img src="/images/java_thread_basic/1.png" alt="avatar"><h3 id="进程和线程的关系"><a href="#进程和线程的关系" class="headerlink" title="进程和线程的关系"></a>进程和线程的关系</h3></li>
<li>线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；</li>
<li>一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；</li>
<li>进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；</li>
<li>调度和切换：线程上下文切换比进程上下文切换要快得多<br><img src="/images/java_thread_basic/2.png" alt="avatar"><h3 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h3>多核处理器是指一个处理器上集成多个运算核心，从而提高计算能力，每一个处理核心对应一个内核线程<br>内核线程（Kernel Thread，KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程映射到各个处理器上，一般一个处理核心对应一个内核线程<h3 id="轻量级进程"><a href="#轻量级进程" class="headerlink" title="轻量级进程"></a>轻量级进程</h3>轻量级进程（Lightweight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，也被叫做用户线程。由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。用户线程与内核线程的对应关系有三种模型：一对一模型、多对一模型、多对多模型，在这以4个内核线程、3个用户线程为例对三种模型进行说明。</li>
</ul>
</blockquote>
<h3 id="线程状态介绍"><a href="#线程状态介绍" class="headerlink" title="线程状态介绍"></a>线程状态介绍</h3><blockquote>
<p>java.lang.Thread 类定义了枚举类型State，包含Thread的所有状态<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public enum State &#123;</span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a thread which has not yet started.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        NEW,</span><br><span class="line"></span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a runnable thread.  A thread in the runnable</span><br><span class="line">         * state is executing in the Java virtual machine but it may</span><br><span class="line">         * be waiting for other resources from the operating system</span><br><span class="line">         * such as processor.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        RUNNABLE,</span><br><span class="line"></span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a thread blocked waiting for a monitor lock.</span><br><span class="line">         * A thread in the blocked state is waiting for a monitor lock</span><br><span class="line">         * to enter a synchronized block&#x2F;method or</span><br><span class="line">         * reenter a synchronized block&#x2F;method after calling</span><br><span class="line">         * &#123;@link Object#wait() Object.wait&#125;.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        BLOCKED,</span><br><span class="line"></span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a waiting thread.</span><br><span class="line">         * A thread is in the waiting state due to calling one of the</span><br><span class="line">         * following methods:</span><br><span class="line">         * &lt;ul&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link Object#wait() Object.wait&#125; with no timeout&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link #join() Thread.join&#125; with no timeout&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link LockSupport#park() LockSupport.park&#125;&lt;&#x2F;li&gt;</span><br><span class="line">         * &lt;&#x2F;ul&gt;</span><br><span class="line">         *</span><br><span class="line">         * &lt;p&gt;A thread in the waiting state is waiting for another thread to</span><br><span class="line">         * perform a particular action.</span><br><span class="line">         *</span><br><span class="line">         * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;&#x2F;tt&gt;</span><br><span class="line">         * on an object is waiting for another thread to call</span><br><span class="line">         * &lt;tt&gt;Object.notify()&lt;&#x2F;tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;&#x2F;tt&gt; on</span><br><span class="line">         * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;&#x2F;tt&gt;</span><br><span class="line">         * is waiting for a specified thread to terminate.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        WAITING,</span><br><span class="line"></span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a waiting thread with a specified waiting time.</span><br><span class="line">         * A thread is in the timed waiting state due to calling one of</span><br><span class="line">         * the following methods with a specified positive waiting time:</span><br><span class="line">         * &lt;ul&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;&#x2F;li&gt;</span><br><span class="line">         *   &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;&#x2F;li&gt;</span><br><span class="line">         * &lt;&#x2F;ul&gt;</span><br><span class="line">         *&#x2F;</span><br><span class="line">        TIMED_WAITING,</span><br><span class="line"></span><br><span class="line">        &#x2F;**</span><br><span class="line">         * Thread state for a terminated thread.</span><br><span class="line">         * The thread has completed execution.</span><br><span class="line">         *&#x2F;</span><br><span class="line">        TERMINATED;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br><img src="/images/java_thread_basic/2.png" alt="avatar"></p>
<ul>
<li><ol>
<li>初始状态(NEW)<br>实现Runnable接口和继承Thread可以得到一个线程类，new一个实例出来，线程就进入了初始状态。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 通过Thread类</span><br><span class="line">Thread thread &#x3D; new Thread();</span><br><span class="line">&#x2F;&#x2F; 通过Runnable接口</span><br><span class="line">Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>就绪状态(RUNNABLE)</li>
</ol>
<ul>
<li><ol>
<li>READY<br>就绪状态只是说你有资格运行，调度程序没有挑选到你，你就永远是就绪状态。<br>调用线程的start()方法，此线程进入就绪状态。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Thread thread &#x3D; new Thread(()-&gt;&#123;</span><br><span class="line">    System.out.println(&quot;hello&quot;);</span><br><span class="line">&#125;);</span><br><span class="line">thread.start();</span><br></pre></td></tr></table></figure>
当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。<br>当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。<br>锁池里的线程拿到对象锁后，进入就绪状态。</li>
</ol>
</li>
<li><ol>
<li>RUNNING<br>线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一的一种方式。</li>
</ol>
</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li><ol>
<li>阻塞状态(BLOCKED)<br>阻塞状态是线程阻塞在进入synchronized关键字修饰的方法或代码块(获取锁)时的状态。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ConcurrencyTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Object lock &#x3D; new Object();</span><br><span class="line">        ThreadPoolExecutor executor &#x3D; new ThreadPoolExecutor(10,10,0, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;());</span><br><span class="line">        for (int i &#x3D; 0; i&lt; 11; i++) &#123;</span><br><span class="line">            Thread thread &#x3D; new Thread(() -&gt; &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    synchronized (lock) &#123;</span><br><span class="line">                        System.out.println(&quot;try to refresh config&quot;);</span><br><span class="line">                        Thread.sleep(3*60*1000);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            executor.submit(thread);</span><br><span class="line">        &#125;</span><br><span class="line">        executor.shutdown();;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><ol>
<li>等待(WAITING)<br>处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">  Thread t &#x3D; new Thread(()-&gt;&#123;</span><br><span class="line">    System.out.println(&quot;hello&quot;);</span><br><span class="line">  &#125;);</span><br><span class="line">  System.out.println(&quot;start&quot;);</span><br><span class="line">  &#x2F;&#x2F; 调用start方法，t线程从NEW状态-》runnable状态</span><br><span class="line">  t.start();</span><br><span class="line">  &#x2F;&#x2F; 调用join方法，让main线程处于waiting状态，先执行t线程的start-》hello，t线程执行结束后处于terminated，main线程从waiting状态恢复到runnable状态，执行自己的的end</span><br><span class="line">  t.join();</span><br><span class="line">  System.out.println(&quot;end&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/images/java_thread_basic/7.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>超时等待(TIMED_WAITING)<br>处于这种状态的线程不会被分配CPU执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一定时间后它们会自动唤醒。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">  &#x2F;&#x2F; 当前main线程处于RUNNABLE状态</span><br><span class="line">  try &#123;</span><br><span class="line">    &#x2F;&#x2F; 调用sleep后，main线程进入TIMED_WAITING状态</span><br><span class="line">      Thread.sleep(10000);</span><br><span class="line">  &#125; catch (InterruptedException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">  &#125;</span><br><span class="line">  &#x2F;&#x2F; 休眠结束后，恢复RUNNABLE状态</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/images/java_thread_basic/6.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>终止状态(TERMINATED)<br>当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。<br>在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。</li>
</ol>
</li>
</ul>
<h3 id="线程的应用实践"><a href="#线程的应用实践" class="headerlink" title="线程的应用实践"></a>线程的应用实践</h3><ul>
<li>Thread类<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ThreadStatusTest &#123;</span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        Thread t &#x3D; new Thread(() -&gt; &#123;</span><br><span class="line">            System.out.println(&quot;hello&quot;);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(100000);</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(&quot;start&quot;);</span><br><span class="line">        System.out.println(&quot;&#x3D;&#x3D;1&#x3D;&#x3D;&quot;+t.getState());</span><br><span class="line">        t.start();</span><br><span class="line">        System.out.println(&quot;&#x3D;&#x3D;2&#x3D;&#x3D;&quot;+t.getState());</span><br><span class="line">        t.join();</span><br><span class="line">        System.out.println(&quot;&#x3D;&#x3D;3&#x3D;&#x3D;&quot;+t.getState());</span><br><span class="line">        System.out.println(&quot;end&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
如上图<br><img src="/images/java_thread_basic/4.png" alt="avatar"><br><img src="/images/java_thread_basic/5.png" alt="avatar"></li>
</ul>
]]></content>
      <categories>
        <category>interview</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse离线导入大揭秘</title>
    <url>/2022/09/26/replace-trigger/</url>
    <content><![CDATA[<h3 id="如何按照hive表的表结构创建clickhouse表"><a href="#如何按照hive表的表结构创建clickhouse表" class="headerlink" title="如何按照hive表的表结构创建clickhouse表"></a>如何按照hive表的表结构创建clickhouse表</h3><p>点击<a href="http://studio.data.didichuxing.com/stream/create-table?tableType=clickHouse" target="_blank" rel="noopener">链接</a>通过数梦的实时平台可以快捷创建对应hive表结构的ck表，如下图所示：<br><img src="/images/clickhouse/hive2clickhouse/1.png" alt="clickhouse"></p>
<h3 id="hive表的数据如何导入clickhouse表"><a href="#hive表的数据如何导入clickhouse表" class="headerlink" title="hive表的数据如何导入clickhouse表"></a>hive表的数据如何导入clickhouse表</h3><h4 id="创建同步任务"><a href="#创建同步任务" class="headerlink" title="创建同步任务"></a>创建同步任务</h4><p>点击<a href="http://sync.data-pre.didichuxing.com/job/offline/edit/818177?step=1" target="_blank" rel="noopener">链接</a>通过数梦的同步中心可以快捷创建hive表映射到ck表的同步任务，如下图所示<br><img src="/images/clickhouse/hive2clickhouse/2.png" alt="clickhouse"></p>
<h4 id="同步任务流程"><a href="#同步任务流程" class="headerlink" title="同步任务流程"></a>同步任务流程</h4><p>如下图所示，我们按照这个流程处理hive数据导入到clickhouse<br><img src="/images/clickhouse/hive2clickhouse/3.png" alt="clickhouse"></p>
<ul>
<li><ol>
<li>创建临时表<br>按照ck表的表结构，我们会在集群的所有写节点创建同样表结构的单机表（MergeTree）引擎</li>
</ol>
</li>
<li><ol>
<li>起spark任务，利用clickhouse-local工具将hive表导入到临时表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat data.orc | clickhouse-local \</span><br><span class="line">--format&#x3D;Native \</span><br><span class="line">--query&#x3D;&#39;CREATE TABLE input (col1 String, col2 String, col3 String) ENGINE &#x3D; File(ORC, stdin);CREATE TABLE target_table (col1 String, col2 String, col3 String) ENGINE &#x3D; MergeTree() partition by tuple() order by col1;insert into target_table select *,&quot;$year&quot; as year,&quot;$month&quot; as month, &quot;$day&quot; as day from input;optimize table target_table final&#39; \</span><br><span class="line">--config-file&#x3D;config.xmls</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>starrocks在滴滴的落地</title>
    <url>/2022/10/17/starrocks%E5%9C%A8%E6%BB%B4%E6%BB%B4%E7%9A%84%E8%90%BD%E5%9C%B0/</url>
    <content><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><h4 id="ClickHouse介绍"><a href="#ClickHouse介绍" class="headerlink" title="ClickHouse介绍"></a>ClickHouse介绍</h4><blockquote>
<p><code>ClickHouse</code>是由俄罗斯的第一大搜索引擎<code>Yandex</code>公司开源的列存数据库。令人惊喜的是，<code>ClickHouse</code>相较于很多商业<code>MPP</code>数据库，比如<code>Vertica</code>，<code>InfiniDB</code>有着极大的性能提升。除了<code>Yandex</code>以外，越来越多的公司开始尝试使用<code>ClickHouse</code>等列存数据库。对于一般的分析业务，结构性较强且数据变更不频繁，可以考虑将需要进行关联的表打平成宽表，放入<code>ClickHouse</code>中。</p>
<ul>
<li>配置丰富，只依赖与<code>Zookeeper</code></li>
<li>线性可扩展性，可以通过添加服务器扩展集群</li>
<li>容错性高，不同分片间采用异步多主复制</li>
<li>单表性能极佳，采用向量计算，支持采样和近似计算等优化手段</li>
<li>功能强大支持多种表引擎</li>
</ul>
</blockquote>
<h4 id="StarRocks介绍"><a href="#StarRocks介绍" class="headerlink" title="StarRocks介绍"></a>StarRocks介绍</h4><blockquote>
<p><code>StarRocks</code>是一款极速全场景MPP企业级数据库产品，具备水平在线扩缩容，金融级高可用，兼容<code>MySQL</code>协议和<code>MySQL</code>生态，提供全面向量化引擎与多种数据源联邦查询等重要特性。<code>StarRocks</code>致力于在全场景<code>OLAP</code>业务上为用户提供统一的解决方案，适用于对性能，实时性，并发能力和灵活性有较高要求的各类应用场景。</p>
<ul>
<li>不依赖于大数据生态，同时外表的联邦查询可以兼容大数据生态</li>
<li>提供多种不同的模型，支持不同维度的数据建模</li>
<li>支持在线弹性扩缩容，可以自动负载均衡</li>
<li>支持高并发分析查询</li>
<li>实时性好，支持数据秒级写入</li>
<li>兼容MySQL 5.7协议和MySQL生态</li>
</ul>
</blockquote>
<h4 id="二者的对比"><a href="#二者的对比" class="headerlink" title="二者的对比"></a>二者的对比</h4><p><strong>相似之处</strong></p>
<ul>
<li>都可以提供极致的性能</li>
<li>都不依赖于<code>Hadoop</code>生态</li>
<li>底层存储分片都提供了主主的复制高可用机制。</li>
<li>都是<code>MPP</code>架构</li>
<li>都是列式存储</li>
<li>都支持表述SQL语法</li>
<li>都提供了MOLAP库的预聚合能力</li>
</ul>
<p><strong>差异性</strong></p>
<ul>
<li><code>ClickHouse</code>在更适用于大宽表的场景，<code>TP</code>的数据通过<code>CDC</code>工具的，可以考虑在<code>Flink</code>中将需要关联的表打平，以大宽表的形式写入<code>ClickHouse</code></li>
<li><code>StarRocks</code>对于<code>join</code>的能力更强，<code>ClickHouse虽</code>然提供了<code>join</code>的语义，但使用上对大表关联的能力支撑较弱，复杂的关联查询经常会引起<code>OOM</code></li>
<li><code>ClickHouse</code>对高并发的业务并不友好，即使一个查询，也会用服务器一半的<code>CPU</code>去查询</li>
<li><code>StarRocks</code>可以支撑数千用户同时进行分析查询，在部分场景下，高并发能力能够达到万级。<code>StarRocks</code>在数据存储层，采用先分区再分桶的策略，增加了数据的指向性，利用前缀索引可以快读对数据进行过滤和查找，减少磁盘的<code>I/O</code>操作，提升查询性能</li>
<li>对于用户的原有的查询基表的 <code>SQL</code> 语句保持不变，<code>StarRocks</code> 会自动选择一个最优的物化视图，从物化视图中读取数据并计算。用户可以通过 <code>EXPLAIN</code> 命令来检查当前查询是否使用了物化视图。而<code>ClickHouse</code>则需要用户自行指定<code>SQL</code>中所需要使用的物化视图。</li>
</ul>
<h4 id="为什么推荐StarRocks"><a href="#为什么推荐StarRocks" class="headerlink" title="为什么推荐StarRocks"></a>为什么推荐StarRocks</h4><ol>
<li>滴滴大数据<code>OLAP</code>团队目前在维护的引擎有<code>StarRocks</code>、<code>ClickHouse</code>、<code>Druid</code>，3个引擎各有各的特点，现有的OLAP引擎(Kylin、Druid、ClickHouse)多表Join时的性能都比较差，甚至不支持多表Join，现有的引擎<code>Druid</code>虽然有<code>lookup</code>表的能力，但经过实际测试后性能不佳。<code>Apache Kylin</code>实际上也不支持<code>Join</code>，多表的<code>Join</code>需要通过在<code>cube</code>构建的时候底层打成宽表来实现。<code>ClickHouse</code>只支持本地<code>Hash join</code>的模式，不支持分布式<code>Shuffle join</code>，多数情况下灵活性受限，性能表现不佳。</li>
<li><code>OLAP</code>引擎需要同时具备明细数据查询和数据聚合的能力。由于<code>Apache Kylin</code>、<code>Druid</code>不能较好支持明细数据查询，我们引入了<code>ClickHouse</code>，通过在明细表基础上创建相应聚合物化视图来处理，但是不够灵活，对于上层应用来说，查明细和查聚合需要切到不同的表去处理。</li>
<li>目前我们团队在有限人员情况下需要维护这3个引擎的稳定性，导致我们对每一个引擎的理解深度都不够，特别像<code>ClickHouse</code>，运维成本非常高，ClickHouse集群的分片、副本信息，都是通过静态的配置文件的方式进行配置。当整个集群需要扩缩容的时候，就必须通过修改配置文件的方式进行刷新，数据的均衡都需要运维人员介入。此外ClickHouse通过zookeeper来做副本管理，当集群规模变大时，副本数过多会导致zookeeper的压力变大，集群的稳定性也就会相应变差。<br>为解决以上问题，滴滴大数据<code>OLAP</code>团队在2022年初开始调研<code>StarRocks</code>，在全面测试过从上面对<code>StarRocks</code>和<code>ClickHouse</code>的对比，我们也可以明显感受到<code>StarRocks</code>在多数场景下都是优于<code>ClickHouse</code>的，我们希望通过<code>StarRocks</code>来实现<code>OLAP</code>平台的多业务场景的查询引擎统一化。<br><img src="/images/starrocks/helloworld/20.png" alt="1"><br>注：这是我们针对<code>Druid</code>、<code>ClickHouse</code>、<code>StarRocks</code>进行的测试对比，<a href="http://wiki.intra.xiaojukeji.com/pages/viewpage.action?pageId=799050659" target="_blank" rel="noopener">链接</a>。</li>
</ol>
<h3 id="StarRocks特性"><a href="#StarRocks特性" class="headerlink" title="StarRocks特性"></a>StarRocks特性</h3><blockquote>
<p><code>StarRocks</code>的架构设计融合了<code>MPP</code>数据库，以及分布式系统的设计思想，其特性如下所示。</p>
<h4 id="架构精简"><a href="#架构精简" class="headerlink" title="架构精简"></a>架构精简</h4><ul>
<li><code>StarRocks</code>内部通过<code>MPP</code>计算框架完成<code>SQL</code>的具体执行工作。<code>MPP</code>框架能够充分的利用多节点的计算能力，整个查询可以并行执行，从而实现良好的交互式分析体验。</li>
<li><code>StarRocks</code>集群不需要依赖任何其他组件，易部署、易维护和极简的架构设计，降低了<code>StarRocks</code>系统的复杂度和维护成本，同时也提升了系统的可靠性和扩展性。管理员只需要专注于<code>StarRocks</code>系统，无需学习和管理任何其他外部系统。</li>
</ul>
</blockquote>
<h4 id="全面向量化引擎"><a href="#全面向量化引擎" class="headerlink" title="全面向量化引擎"></a>全面向量化引擎</h4><p><code>StarRocks</code>的计算层全面采用了向量化技术，将所有算子、函数、扫描过滤和导入导出模块进行了系统性优化。通过列式的内存布局、适配<code>CPU</code>的<code>SIMD</code>指令集等手段，充分发挥了现代<code>CPU</code>的并行计算能力，从而实现亚秒级别的多维分析能力。</p>
<h4 id="智能查询优化"><a href="#智能查询优化" class="headerlink" title="智能查询优化"></a>智能查询优化</h4><p><code>StarRocks</code>通过<code>CBO</code>优化器 <strong>（Cost Based Optimizer）</strong> 可以对复杂查询自动优化。无需人工干预，就可以通过统计信息合理估算执行成本，生成更优的执行计划，大大提高了<code>AdHoc</code>和<code>ETL</code>场景的数据分析效率。</p>
<h4 id="联邦查询"><a href="#联邦查询" class="headerlink" title="联邦查询"></a>联邦查询</h4><p><code>StarRocks</code>支持使用外表的方式进行联邦查询，当前可以支持<code>Hive</code>、<code>MySQL</code>、<code>Elasticsearch</code>、<code>Iceberg</code>和<code>Hudi</code>类型的外表，您无需通过数据导入，可以直接进行数据查询加速。</p>
<h4 id="高效更新"><a href="#高效更新" class="headerlink" title="高效更新"></a>高效更新</h4><p><code>StarRocks</code>支持明细模型(DUPLICATE KEY)、聚合模型(AGGREGATE KEY)、主键模型(PRIMARY KEY)和更新模型(UNIQUE KEY)，其中主键模型可以按照主键进行<code>Upsert</code>或<code>Delete</code>操作，通过存储和索引的优化可以在并发更新的同时实现高效的查询优化，更好的服务实时数仓的场景。</p>
<h4 id="智能物化视图"><a href="#智能物化视图" class="headerlink" title="智能物化视图"></a>智能物化视图</h4><ul>
<li><code>StarRocks</code>支持智能的物化视图。您可以通过创建物化视图，预先计算生成预聚合表用于加速聚合类查询请求。</li>
<li><code>StarRocks</code>的物化视图能够在数据导入时自动完成汇聚，与原始表数据保持一致。</li>
<li>查询的时候，您无需指定物化视图，<code>StarRocks</code>能够自动选择最优的物化视图来满足查询请求。</li>
</ul>
<h4 id="标准SQL"><a href="#标准SQL" class="headerlink" title="标准SQL"></a>标准SQL</h4><ul>
<li><code>StarRocks</code>支持标准的<code>SQL</code>语法，包括聚合、<code>JOIN</code>、排序、窗口函数和自定义函数等功能。</li>
<li><code>StarRocks</code>可以完整支持<code>TPC-H</code>的22个<code>SQL</code>和<code>TPC-DS</code>的99个<code>SQL</code>。</li>
<li><code>StarRocks</code>兼容<code>MySQL</code>协议语法，可以使用现有的各种客户端工具、<code>BI</code>软件访问<code>StarRocks</code>，对<code>StarRocks</code>中的数据进行拖拽式分析。</li>
</ul>
<h4 id="流批一体"><a href="#流批一体" class="headerlink" title="流批一体"></a>流批一体</h4><ul>
<li><code>StarRocks</code>支持实时和批量两种数据导入方式。</li>
<li><code>StarRocks</code>支持的数据源有<code>Kafka</code>、<code>HDFS</code>和本地文件。</li>
<li><code>StarRocks</code>支持的数据格式有<code>ORC</code>、<code>Parquet</code>和<code>CSV</code>等。</li>
<li><code>StarRocks</code>可以实时消费<code>Kafka</code>数据来完成数据导入，保证数据不丢不重 <strong>（exactly once）</strong>。</li>
<li><code>StarRocks</code>也可以从本地或者远程（HDFS）批量导入数据。</li>
</ul>
<h4 id="高可用易扩展"><a href="#高可用易扩展" class="headerlink" title="高可用易扩展"></a>高可用易扩展</h4><ul>
<li><code>StarRocks</code>的元数据和数据都是多副本存储，并且集群中服务有热备，多实例部署，避免了单点故障。</li>
<li>集群具有自愈能力，可弹性恢复，节点的宕机、下线和异常都不会影响<code>StarRocks</code>集群服务的整体稳定性。</li>
<li><code>StarRocks</code>采用分布式架构，存储容量和计算能力可近乎线性水平扩展。<code>StarRocks</code>单集群的节点规模可扩展到数百节点，数据规模可达到10 PB级别。</li>
<li>扩缩容期间无需停服，可以正常提供查询服务。</li>
<li><code>StarRocks</code>中表模式热变更，可通过一条简单<code>SQL</code>命令动态地修改表的定义，例如增加列、减少列和新建物化视图等。同时，处于模式变更中的表也可以正常导入和查询数据。</li>
</ul>
<h3 id="StarRocks应用场景"><a href="#StarRocks应用场景" class="headerlink" title="StarRocks应用场景"></a>StarRocks应用场景</h3><blockquote>
<p>StarRocks可以满足企业级用户的多种分析需求，具体的业务场景如下所示：</p>
<h4 id="OLAP多维分析"><a href="#OLAP多维分析" class="headerlink" title="OLAP多维分析"></a>OLAP多维分析</h4><ul>
<li>用户行为分析</li>
<li>用户画像、标签分析、圈人</li>
<li>高维业务指标报表</li>
<li>自助式报表平台</li>
<li>业务问题探查分析</li>
<li>跨主题业务分析</li>
<li>财务报表</li>
<li>系统监控分析</li>
</ul>
</blockquote>
<h4 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h4><ul>
<li>电商大促数据分析</li>
<li>教育行业的直播质量分析</li>
<li>物流行业的运单分析</li>
<li>金融行业绩效分析、指标计算</li>
<li>广告投放分析</li>
<li>管理驾驶舱</li>
<li>探针分析APM（Application Performance Management）</li>
</ul>
<h4 id="高并发查询"><a href="#高并发查询" class="headerlink" title="高并发查询"></a>高并发查询</h4><ul>
<li>广告主报表分析</li>
<li>零售行业渠道人员分析</li>
<li>saas行业面向用户分析报表</li>
<li>dashboard多页面分析</li>
</ul>
<h4 id="统一分析"><a href="#统一分析" class="headerlink" title="统一分析"></a>统一分析</h4><p>通过使用一套系统解决多维分析、高并发查询、实时分析和Ad-Hoc查询等场景，降低系统复杂度和多技术栈开发与维护成本。</p>
<h3 id="如何使用StarRocks"><a href="#如何使用StarRocks" class="headerlink" title="如何使用StarRocks"></a>如何使用StarRocks</h3><blockquote>
<p>我们olap团队已经将<code>StarRocks</code>接入到滴滴各个平台，下面会介绍如何使用滴滴内部的平台和工具方便快捷的使用<code>StarRocks</code>引擎。<br><img src="/images/starrocks/helloworld/19.png" alt="1"></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>starrocks离线构建</title>
    <url>/2022/11/19/starrocks-load/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul>
<li><p>入口文件-&gt;StarRocksFE.java</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.....</span><br><span class="line">feServer.start();</span><br><span class="line">httpServer.start();</span><br><span class="line">qeService.start();</span><br></pre></td></tr></table></figure>
<p>主要是初始化配置和启动服务，分别是mysql server端口、thrift server端口、http端口</p>
</li>
<li><p>mysq服务启动-&gt;QeService.java</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void start() throws IOException &#123;</span><br><span class="line">        if (!mysqlServer.start()) &#123;</span><br><span class="line">            LOG.error(&quot;mysql server start failed&quot;);</span><br><span class="line">            System.exit(-1);</span><br><span class="line">        &#125;</span><br><span class="line">        LOG.info(&quot;QE service start.&quot;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>MysqlServer.java</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; start MySQL protocol service</span><br><span class="line">&#x2F;&#x2F; return true if success, otherwise false</span><br><span class="line">public boolean start() &#123;</span><br><span class="line">    if (scheduler &#x3D;&#x3D; null) &#123;</span><br><span class="line">        LOG.warn(&quot;scheduler is NULL.&quot;);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; open server socket</span><br><span class="line">    try &#123;</span><br><span class="line">        serverChannel &#x3D; ServerSocketChannel.open();</span><br><span class="line">        serverChannel.socket().bind(new InetSocketAddress(&quot;0.0.0.0&quot;, port), 2048);</span><br><span class="line">        serverChannel.configureBlocking(true);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        LOG.warn(&quot;Open MySQL network service failed.&quot;, e);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; start accept thread</span><br><span class="line">    listener &#x3D; ThreadPoolManager.newDaemonCacheThreadPool(1, &quot;MySQL-Protocol-Listener&quot;, true);</span><br><span class="line">    running &#x3D; true;</span><br><span class="line">    listenerFuture &#x3D; listener.submit(new Listener());</span><br><span class="line"></span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Listener 监听线程，实现Runnable接口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    while (running &amp;&amp; serverChannel.isOpen()) &#123;</span><br><span class="line">        SocketChannel clientChannel;</span><br><span class="line">        try &#123;</span><br><span class="line">            clientChannel &#x3D; serverChannel.accept();</span><br><span class="line">            if (clientChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F; submit this context to scheduler</span><br><span class="line">            ConnectContext context &#x3D; new ConnectContext(clientChannel);</span><br><span class="line">            &#x2F;&#x2F; Set catalog here.</span><br><span class="line">            context.setCatalog(Catalog.getCurrentCatalog());</span><br><span class="line">            if (!scheduler.submit(context)) &#123;</span><br><span class="line">                LOG.warn(&quot;Submit one connect request failed. Client&#x3D;&quot; + clientChannel.toString());</span><br><span class="line">                &#x2F;&#x2F; clear up context</span><br><span class="line">                context.cleanup();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            &#x2F;&#x2F; ClosedChannelException</span><br><span class="line">            &#x2F;&#x2F; AsynchronousCloseException</span><br><span class="line">            &#x2F;&#x2F; ClosedByInterruptException</span><br><span class="line">            &#x2F;&#x2F; Other IOException, for example &quot;to many open files&quot; ...</span><br><span class="line">            LOG.warn(&quot;Query server encounter exception.&quot;, e);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(100);</span><br><span class="line">            &#125; catch (InterruptedException e1) &#123;</span><br><span class="line">                &#x2F;&#x2F; Do nothing</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            &#x2F;&#x2F; NotYetBoundException</span><br><span class="line">            &#x2F;&#x2F; SecurityException</span><br><span class="line">            LOG.warn(&quot;Query server failed when calling accept.&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line">+ submit提交连接的上下文给线程池</span><br></pre></td></tr></table></figure>
<p>// submit one MysqlContext to this scheduler.<br>// return true, if this connection has been successfully submitted, otherwise return false.<br>// Caller should close ConnectContext if return false.<br>public boolean submit(ConnectContext context) {<br>  if (context == null) {</p>
<pre><code>  return false;
</code></pre><p>  }</p>
<p>  context.setConnectionId(nextConnectionId.getAndAdd(1));<br>  // no necessary for nio.<br>  if (context instanceof NConnectContext) {</p>
<pre><code>  return true;
</code></pre><p>  }<br>  if (executor.submit(new LoopHandler(context)) == null) {</p>
<pre><code>  LOG.warn(&quot;Submit one thread failed.&quot;);
  return false;
</code></pre><p>  }<br>  return true;<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ LoopHandler.java (实现Runnable接口)</span><br></pre></td></tr></table></figure>
<p>public void run() {<br>  try {</p>
<pre><code>  // Set thread local info
  context.setThreadLocalInfo();
  context.setConnectScheduler(ConnectScheduler.this);
  // authenticate check failed.
  if (!MysqlProto.negotiate(context)) {
      return;
  }

  if (registerConnection(context)) {
      MysqlProto.sendResponsePacket(context);
  } else {
      context.getState().setError(&quot;Reach limit of connections&quot;);
      MysqlProto.sendResponsePacket(context);
      return;
  }

  context.setStartTime();
  ConnectProcessor processor = new ConnectProcessor(context);
  processor.loop();
</code></pre><p>  } catch (Exception e) {</p>
<pre><code>  // for unauthrorized access such lvs probe request, may cause exception, just log it in debug level
  if (context.getCurrentUserIdentity() != null) {
      LOG.warn(&quot;connect processor exception because &quot;, e);
  } else {
      LOG.debug(&quot;connect processor exception because &quot;, e);
  }
</code></pre><p>  } finally {</p>
<pre><code>  unregisterConnection(context);
  context.cleanup();
</code></pre><p>  }<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; loop</span><br></pre></td></tr></table></figure>
<p>public void loop() {<br>  while (!ctx.isKilled()) {</p>
<pre><code>  try {
      processOnce();
  } catch (Exception e) {
      // TODO(zhaochun): something wrong
      LOG.warn(&quot;Exception happened in one seesion(&quot; + ctx + &quot;).&quot;, e);
      ctx.setKilled();
      break;
  }
</code></pre><p>  }<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; processOnce</span><br></pre></td></tr></table></figure>
<p>// handle one process<br>public void processOnce() throws IOException {<br>  // set status of query to OK.<br>  ctx.getState().reset();<br>  executor = null;</p>
<p>  // reset sequence id of MySQL protocol<br>  final MysqlChannel channel = ctx.getMysqlChannel();<br>  channel.setSequenceId(0);<br>  // read packet from channel<br>  try {</p>
<pre><code>  packetBuf = channel.fetchOnePacket();
  if (packetBuf == null) {
      throw new IOException(&quot;Error happened when receiving packet.&quot;);
  }
</code></pre><p>  } catch (AsynchronousCloseException e) {</p>
<pre><code>  // when this happened, timeout checker close this channel
  // killed flag in ctx has been already set, just return
  return;
</code></pre><p>  }</p>
<p>  // dispatch<br>  dispatch();<br>  // finalize<br>  finalizeCommand();</p>
<p>  ctx.setCommand(MysqlCommand.COM_SLEEP);<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; dispatch</span><br></pre></td></tr></table></figure>
<p>int code = packetBuf.get();<br>MysqlCommand command = MysqlCommand.fromCode(code);<br>….<br>ctx.setCommand(command);<br>….</p>
</li>
</ul>
<p>switch (command) {<br>    case COM_INIT_DB:<br>        handleInitDb();<br>        break;<br>    case COM_QUIT:<br>        handleQuit();<br>        break;<br>    case COM_QUERY:<br>        handleQuery();<br>        ctx.setStartTime();<br>        break;<br>    case COM_FIELD_LIST:<br>        handleFieldList();<br>        break;<br>    case COM_CHANGE_USER:<br>        handleChangeUser();<br>        break;<br>    case COM_RESET_CONNECTION:<br>        handleResetConnnection();<br>        break;<br>    case COM_PING:<br>        handlePing();<br>        break;<br>    default:<br>        ctx.getState().setError(“Unsupported command(“ + command + “)”);<br>        LOG.warn(“Unsupported command(“ + command + “)”);<br>        break;<br>}<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; handleQuery</span><br></pre></td></tr></table></figure><br>….<br>List<StatementBase> stmts = analyze(originStmt);<br>for (int i = 0; i &lt; stmts.size(); ++i) {<br>    ctx.getState().reset();<br>    if (i &gt; 0) {<br>        ctx.resetRetureRows();<br>        ctx.setQueryId(UUIDUtil.genUUID());<br>    }<br>    parsedStmt = stmts.get(i);<br>    parsedStmt.setOrigStmt(new OriginStatement(originStmt, i));</p>
<pre><code>executor = new StmtExecutor(ctx, parsedStmt);
ctx.setExecutor(executor);

ctx.setIsLastStmt(i == stmts.size() - 1);

executor.execute();

// do not execute following stmt when current stmt failed, this is consistent with mysql server
if (ctx.getState().getStateType() == QueryState.MysqlStateType.ERR) {
    break;
}

if (i != stmts.size() - 1) {
    // NOTE: set serverStatus after executor.execute(),
    //      because when execute() throws exception, the following stmt will not execute
    //      and the serverStatus with MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS will
    //      cause client error: Packet sequence number wrong
    ctx.getState().serverStatus |= MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS;
    finalizeCommand();
}
</code></pre><p>}<br>….</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; analyze</span><br></pre></td></tr></table></figure>
<p>// analyze the origin stmt and return multi-statements<br>private List<StatementBase> analyze(String originStmt) throws AnalysisException {<br>    LOG.debug(“the originStmts are: {}”, originStmt);<br>    // Parse statement with parser generated by CUP&amp;FLEX<br>    SqlScanner input = new SqlScanner(new StringReader(originStmt), ctx.getSessionVariable().getSqlMode());<br>    SqlParser parser = new SqlParser(input);<br>    try {<br>        return SqlParserUtils.getMultiStmts(parser);<br>    } catch (Error e) {<br>        throw new AnalysisException(“Please check your sql, we meet an error when parsing.”, e);<br>    } catch (AnalysisException e) {<br>        LOG.warn(“origin_stmt: “ + originStmt + “; Analyze error message: “ + parser.getErrorMsg(originStmt), e);<br>        String errorMessage = parser.getErrorMsg(originStmt);<br>        if (errorMessage == null) {<br>            throw e;<br>        } else {<br>            throw new AnalysisException(errorMessage, e);<br>        }<br>    } catch (Exception e) {<br>        // TODO(lingbin): we catch ‘Exception’ to prevent unexpected error,<br>        // should be removed this try-catch clause future.<br>        LOG.warn(“origin_stmt: “ + originStmt + “; exception: “, e);<br>        String errorMessage = e.getMessage();<br>        if (errorMessage == null) {<br>            throw new AnalysisException(“Internal Error”);<br>        } else {<br>            throw new AnalysisException(“Internal Error: “ + errorMessage);<br>        }<br>    }<br>}<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>} else if (parsedStmt instanceof DdlStmt) {<br>    handleDdlStmt();<br>}<br>……<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; handleDdlStmt</span><br></pre></td></tr></table></figure><br>private void handleDdlStmt() {<br>  try {<br>      DdlExecutor.execute(context.getCatalog(), (DdlStmt) parsedStmt);<br>      context.getState().setOk();<br>  } catch (QueryStateException e) {<br>      if (e.getQueryState().getStateType() != MysqlStateType.OK) {<br>          LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      }<br>      context.setState(e.getQueryState());<br>  } catch (UserException e) {<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      // Return message to info client what happened.<br>      context.getState().setError(e.getMessage());<br>  } catch (Exception e) {<br>      // Maybe our bug<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      context.getState().setError(“Unexpected exception: “ + e.getMessage());<br>  }<br>}<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ DdlExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>else if (ddlStmt instanceof LoadStmt) {<br>    LoadStmt loadStmt = (LoadStmt) ddlStmt;<br>    EtlJobType jobType = loadStmt.getEtlJobType();<br>    if (jobType == EtlJobType.UNKNOWN) {<br>        throw new DdlException(“Unknown load job type”);<br>    }<br>    if (jobType == EtlJobType.HADOOP &amp;&amp; Config.disable_hadoop_load) {<br>        throw new DdlException(“Load job by hadoop cluster is disabled.”</p>
<pre><code>            + &quot; Try using broker load. See &#39;help broker load;&#39;&quot;);
}

catalog.getLoadManager().createLoadJobFromStmt(loadStmt);
</code></pre><p>}<br>……..<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadManager.java -&gt; createLoadJobFromStmt</span><br></pre></td></tr></table></figure><br>public void createLoadJobFromStmt(LoadStmt stmt) throws DdlException {<br>  Database database = checkDb(stmt.getLabel().getDbName());<br>  long dbId = database.getId();<br>  LoadJob loadJob = null;<br>  writeLock();<br>  try {<br>      checkLabelUsed(dbId, stmt.getLabel().getLabelName());<br>      if (stmt.getBrokerDesc() == null &amp;&amp; stmt.getResourceDesc() == null) {<br>          throw new DdlException(“LoadManager only support the broker and spark load.”);<br>      }<br>      if (loadJobScheduler.isQueueFull()) {<br>          throw new DdlException(<br>                  “There are more than “ + Config.desired_max_waiting_jobs + “ load jobs in waiting queue, “</p>
<pre><code>                      + &quot;please retry later.&quot;);
  }
  loadJob = BulkLoadJob.fromLoadStmt(stmt);
  createLoadJob(loadJob);
</code></pre><p>  } finally {<br>      writeUnlock();<br>  }<br>  Catalog.getCurrentCatalog().getEditLog().logCreateLoadJob(loadJob);</p>
<p>  // The job must be submitted after edit log.<br>  // It guarantee that load job has not been changed before edit log.<br>  loadJobScheduler.submitJob(loadJob);<br>}<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">通过 &#96;createLoadJobFromStmt&#96; 创建load任务</span><br><span class="line">+ LoadJobScheduler.java -&gt; process</span><br><span class="line">注意：LoadJobScheduler 继承自 MasterDaemon，MasterDaemon 继承自 Daemon，</span><br><span class="line">Daemon继承自Thread，重载了run方法，里面有一个loop，主要执行runOneCycle</span><br><span class="line">MasterDaemon 又重写了 runOneCycle，执行 runAfterCatalogReady 函数</span><br><span class="line">LoadJobScheduler 又重写了 runAfterCatalogReady 主要就是干process处理，里面是一个死循环，不断从LinkedBlockingQueue类型的needScheduleJobs里出栈取要珍惜的job</span><br></pre></td></tr></table></figure><br>while (true) {<br>  // take one load job from queue<br>  LoadJob loadJob = needScheduleJobs.poll();<br>  if (loadJob == null) {<br>      return;<br>  }</p>
<p>  // schedule job<br>  try {<br>      loadJob.execute();<br>  }<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadJob.java -&gt; execute</span><br></pre></td></tr></table></figure><br>/**</p>
<ul>
<li>create pending task for load job and add pending task into pool</li>
<li>if job has been cancelled, this step will be ignored<br>*</li>
<li>@throws LabelAlreadyUsedException  the job is duplicated</li>
<li>@throws BeginTransactionException  the limit of load job is exceeded</li>
<li>@throws AnalysisException          there are error params in job</li>
<li><p>@throws DuplicatedRequestException<br>*/<br>public void execute() throws LabelAlreadyUsedException, BeginTransactionException, AnalysisException,</p>
<pre><code>DuplicatedRequestException, LoadException {
</code></pre><p>writeLock();<br>try {</p>
<pre><code>unprotectedExecute();
</code></pre><p>} finally {</p>
<pre><code>writeUnlock();
</code></pre><p>}<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; unprotectedExecuteJob</span><br></pre></td></tr></table></figure>
<p>protected void unprotectedExecuteJob() throws LoadException {<br>// create pending task<br>LoadTask task = new SparkLoadPendingTask(this, fileGroupAggInfo.getAggKeyToFileGroups(),</p>
<pre><code>    sparkResource, brokerDesc);
</code></pre><p>task.init();<br>idToTasks.put(task.getSignature(), task);<br>submitTask(Catalog.getCurrentCatalog().getPendingLoadTaskScheduler(), task);<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; init</span><br></pre></td></tr></table></figure>
<p>public void init() throws LoadException {<br>createEtlJobConf();<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadTask -&gt; exec</span><br></pre></td></tr></table></figure>
<p>@Override<br>protected void exec() {<br>boolean isFinished = false;<br>try {</p>
<pre><code>// execute pending task
executeTask();
// callback on pending task finished
callback.onTaskFinished(attachment);
isFinished = true;
</code></pre><p>} catch (UserException e) {</p>
<pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());
LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())
        .add(&quot;error_msg&quot;, &quot;Failed to execute load task&quot;).build(), e);
</code></pre><p>} catch (Exception e) {</p>
<pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());
LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())
        .add(&quot;error_msg&quot;, &quot;Unexpected failed to execute load task&quot;).build(), e);
</code></pre><p>} finally {</p>
<pre><code>if (!isFinished) {
    // callback on pending task failed
    callback.onTaskFailed(signature, failMsg);
}
</code></pre><p>}<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; executeTask</span><br></pre></td></tr></table></figure>
<p>void executeTask() throws LoadException {<br>LOG.info(“begin to execute spark pending task. load job id: {}”, loadJobId);<br>submitEtlJob();<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure>
<p>private void submitEtlJob() throws LoadException {<br>SparkPendingTaskAttachment sparkAttachment = (SparkPendingTaskAttachment) attachment;<br>// retry different output path<br>etlJobConfig.outputPath = EtlJobConfig.getOutputPath(resource.getWorkingDir(), dbId, loadLabel, signature);<br>sparkAttachment.setOutputPath(etlJobConfig.outputPath);</p>
<p>// handler submit etl job<br>SparkEtlJobHandler handler = new SparkEtlJobHandler();<br>handler.submitEtlJob(loadJobId, loadLabel, etlJobConfig, resource, brokerDesc, sparkLoadAppHandle,</p>
<pre><code>    sparkAttachment);
</code></pre><p>LOG.info(“submit spark etl job success. load job id: {}, attachment: {}”, loadJobId, sparkAttachment);<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkEtlJobHandler.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure>
<p>public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobConfig, SparkResource resource,</p>
<pre><code>                     BrokerDesc brokerDesc, SparkLoadAppHandle handle, SparkPendingTaskAttachment attachment)
</code></pre><p>  throws LoadException {<br>// delete outputPath<br>// init local dir<br>// prepare dpp archive<br>SparkLauncher launcher = new SparkLauncher(envs);<br>// master      |  deployMode<br>// ——————|——————-<br>// yarn        |  cluster<br>// spark://xx  |  client<br>launcher.setMaster(resource.getMaster())</p>
<pre><code>  .setDeployMode(resource.getDeployMode().name().toLowerCase())
  .setAppResource(appResourceHdfsPath)
  .setMainClass(SparkEtlJob.class.getCanonicalName())
  .setAppName(String.format(ETL_JOB_NAME, loadLabel))
  .setSparkHome(sparkHome)
  .addAppArgs(jobConfigHdfsPath)
  .redirectError();
</code></pre><p>// spark configs</p>
<p>// start app<br>State state = null;<br>String appId = null;<br>String logPath = null;<br>String errMsg = “start spark app failed. error: “;<br>try {<br>  Process process = launcher.launch();<br>  handle.setProcess(process);<br>  if (!FeConstants.runningUnitTest) {</p>
<pre><code>  SparkLauncherMonitor.LogMonitor logMonitor = SparkLauncherMonitor.createLogMonitor(handle);
  logMonitor.setSubmitTimeoutMs(GET_APPID_TIMEOUT_MS);
  logMonitor.setRedirectLogPath(logFilePath);
  logMonitor.start();
  try {
      logMonitor.join();
  } catch (InterruptedException e) {
      logMonitor.interrupt();
      throw new LoadException(errMsg + e.getMessage());
  }
</code></pre><p>  }<br>  appId = handle.getAppId();<br>  state = handle.getState();<br>  logPath = handle.getLogPath();<br>} catch (IOException e) {<br>  LOG.warn(errMsg, e);<br>  throw new LoadException(errMsg + e.getMessage());<br>}<br>……….<br>// success<br>attachment.setAppId(appId);<br>attachment.setHandle(handle);<br>}</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; onTaskFinished</span><br></pre></td></tr></table></figure>
<p>public void onTaskFinished(TaskAttachment attachment) {<br>if (attachment instanceof SparkPendingTaskAttachment) {</p>
<pre><code>onPendingTaskFinished((SparkPendingTaskAttachment) attachment);
</code></pre><p>}<br>}</p>
</li>
</ul>
<p>private void onPendingTaskFinished(SparkPendingTaskAttachment attachment) {<br>    writeLock();<br>    try {<br>        // check if job has been cancelled<br>        if (isTxnDone()) {<br>            LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)<br>                    .add(“state”, state)<br>                    .add(“error_msg”, “this task will be ignored when job is: “ + state)<br>                    .build());<br>            return;<br>        }</p>
<pre><code>    if (finishedTaskIds.contains(attachment.getTaskId())) {
        LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)
                .add(&quot;task_id&quot;, attachment.getTaskId())
                .add(&quot;error_msg&quot;, &quot;this is a duplicated callback of pending task &quot;
                        + &quot;when broker already has loading task&quot;)
                .build());
        return;
    }

    // add task id into finishedTaskIds
    finishedTaskIds.add(attachment.getTaskId());

    sparkLoadAppHandle = attachment.getHandle();
    appId = attachment.getAppId();
    etlOutputPath = attachment.getOutputPath();

    executeEtl();
    // log etl state
    unprotectedLogUpdateStateInfo();
} finally {
    writeUnlock();
}
</code></pre><p>}</p>
<p>```</p>
]]></content>
      <categories>
        <category>sre</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>线程池相关</title>
    <url>/2021/10/17/thread-pool/</url>
    <content><![CDATA[<h3 id="如何判断程序类型"><a href="#如何判断程序类型" class="headerlink" title="如何判断程序类型"></a>如何判断程序类型</h3><ul>
<li><p>CPU密集型</p>
<blockquote>
<p> <code>CPU</code> 密集型简单理解就是利用 <code>CPU</code> 计算能力的任务,比如你在内存中对大量数据进行排序</p>
</blockquote>
</li>
<li><p>I/O密集型</p>
<blockquote>
<p>但凡涉及到网络读取，文件读取这类都是 <code>IO</code> 密集型，这类任务的特点是 <code>CPU</code> 计算耗费时间相比于等待 <code>IO</code> 操作完成的时间来说很少，大部分时间都花在了等待 <code>IO</code> 操作完成上。</p>
</blockquote>
</li>
</ul>
<h3 id="线程池设置"><a href="#线程池设置" class="headerlink" title="线程池设置"></a>线程池设置</h3><ul>
<li><p>CPU 密集型任务(CPU核数 + 1)： </p>
<blockquote>
<p>这种任务消耗的主要是 <code>CPU</code> 资源，可以将线程数设置为 <code>N</code>（<code>CPU</code> 核心数）+1，比 <code>CPU</code> 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，<code>CPU</code> 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。</p>
</blockquote>
</li>
<li><p>I/O 密集型任务(CPU核数 * 2)： </p>
<blockquote>
<p>这种任务应用起来，系统会用大部分的时间来处理 <code>I/O</code> 交互，而线程在处理 <code>I/O</code> 的时间段内不会占用 <code>CPU</code> 来处理，这时就可以将 <code>CPU</code> 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 <code>2N</code>。</p>
</blockquote>
</li>
<li><p>参数介绍</p>
<ul>
<li>corePoolSize：核心线程数，定义了最小可以同时运行的线程数量</li>
<li>maximumPoolSize：当队列中存放的任务达到队列容量时，当前可以同时运行的线程数量变为最大线程数</li>
<li>workQueue：当新任务来的时候，先判断当前运行的线程数量是否达到核心线程数（corePoolSize），如果达到，则新任务会被存放到队列中</li>
<li>keepAliveTime：当线程池中的线程数量大于核心线程池（corePoolSize）时，如果没有新任务提交，核心线程外的线程（maximumPoolSize - corePoolSize）不会被立即销毁，而是等到keepAliveTime时间后，才会被回收销毁</li>
<li>unit：keepAliveTime的时间单位（TimeUnit类中的成员变量）</li>
<li>threadFactory：executor创建线程的工厂类</li>
<li>handler：饱和策略<blockquote>
<p>如果当前同时运行的线程数量达到最大线程数（maximumPoolSize），并且队列（workQueue）已经满了，ThreadPoolExecutory就会执行一些策略</p>
<ul>
<li>AbortPolicy：抛出 RejectExecutionExeception 来拒绝新任务加入 （默认）</li>
<li>CallerRunsPolicy：调用执行自己的线程运行拒绝任务</li>
<li>DiscardPolicy：不处理新任务，直接丢弃</li>
<li>DiscardOldestPolicy：丢弃最早的未处理的任务</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
<p><img src="/images/java_thread_pool/1.png" alt="avatar"></p>
<h3 id="线程池原理分析"><a href="#线程池原理分析" class="headerlink" title="线程池原理分析"></a>线程池原理分析</h3><ul>
<li><p>ThreadPoolExecutor</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ThreadPoolExecutor extends AbstractExecutorService &#123;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ThreadPoolExecutor类 继承了 AbstractExecutorService类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public abstract class AbstractExecutorService implements ExecutorService &#123;</span><br></pre></td></tr></table></figure>
<p>AbstractExecutorService类 实现了 ExecutorService接口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public interface ExecutorService extends Executor &#123;</span><br></pre></td></tr></table></figure>
<p>ExecutorService接口 继承了 Executor类</p>
</blockquote>
</li>
<li><p>线程池demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package blank.lin.thread;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.ArrayBlockingQueue;</span><br><span class="line">import java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line">public class ThreadPoolTest &#123;</span><br><span class="line">    private static ThreadPoolExecutor threadPoolExecutor &#x3D; new ThreadPoolExecutor(</span><br><span class="line">            1,</span><br><span class="line">            2,</span><br><span class="line">            0L,</span><br><span class="line">            TimeUnit.MILLISECONDS,</span><br><span class="line">            new ArrayBlockingQueue&lt;Runnable&gt;(1)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(500);</span><br><span class="line">                    System.out.println(&quot;第1个任务执行完成&quot;);</span><br><span class="line">                &#125; catch (Exception exception) &#123;</span><br><span class="line">                    exception.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;加入第1个任务，线程池刚刚初始化，没有可以执行任务的核心线程，创建一个核心线程来执行任务&quot;);</span><br><span class="line"></span><br><span class="line">        threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(500);</span><br><span class="line">                    System.out.println(&quot;第2个任务执行完成&quot;);</span><br><span class="line">                &#125; catch (Exception exception) &#123;</span><br><span class="line">                    exception.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;加入第2个任务，没有可以执行任务的核心线程，且任务数大于corePoolSize，新加入任务被放在了阻塞队列中&quot;);</span><br><span class="line"></span><br><span class="line">        threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(500);</span><br><span class="line">                    System.out.println(&quot;第3个任务执行完成&quot;);</span><br><span class="line">                &#125; catch (Exception exception) &#123;</span><br><span class="line">                    exception.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;加入第3个任务，此时，阻塞队列已满，新建非核心线程执行新加入任务&quot;);</span><br><span class="line"></span><br><span class="line">        threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(500);</span><br><span class="line">                    System.out.println(&quot;第4个任务执行完成&quot;);</span><br><span class="line">                &#125; catch (Exception exception) &#123;</span><br><span class="line">                    exception.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;加入第4个任务，此时，阻塞队列已满，新建非核心线程执行新加入任务&quot;);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(600);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;第1个任务执行完毕，核心线程空闲，阻塞队列的任务被取出来，使用核心线程来执行&quot;);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(600);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;第2个任务执行完毕，核心线程空闲，非核心线程在执行第3个任务&quot;);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(600);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        printCount();</span><br><span class="line">        System.out.println(&quot;第3个任务执行完毕，非核心线程被销毁，核心线程保留&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void printCount() &#123;</span><br><span class="line">        System.out.println(&quot;------------------------------------&quot;);</span><br><span class="line">        System.out.println(&quot;当前活跃线程数:&quot;+threadPoolExecutor.getActiveCount());</span><br><span class="line">        System.out.println(&quot;当前核心线程数:&quot;+threadPoolExecutor.getCorePoolSize());</span><br><span class="line">        System.out.println(&quot;阻塞队列中的任务数:&quot;+threadPoolExecutor.getQueue().size());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>threadPoolExecutor.execute源码分析</p>
<blockquote>
<p>处理过程一共3步  </p>
</blockquote>
<ul>
<li>首先判断核心线程池是否满了，未满则开启新线程执行任务，addWorker调用会原子性检查线程运行状态和线程数，并且<blockquote>
<ol>
<li>If fewer than corePoolSize threads are running, try to start a new thread with the given command as its first task.  The call to addWorker atomically checks runState and workerCount, and so prevents false alarms that would add threads when it shouldn’t, by returning false.</li>
</ol>
</blockquote>
</li>
<li>如果一个任务被成功加入到队列里，也会重复检查是否应该新添加一个线程去执行，因为自上次检查后现存线程可以已死，或者线程池在进入这个方法后就关闭了，所以我们会重复检查状态，并且判断是否需要回滚队列，或者开启新线程<blockquote>
<ol>
<li>If a task can be successfully queued, then we still need to double-check whether we should have added a thread (because existing ones died since last checking) or that the pool shut down since entry into this method. So we recheck state and if necessary roll back the enqueuing if stopped, or start a new thread if there are none.</li>
</ol>
</blockquote>
</li>
<li>如果无法加入队列任务，我们会尝试新添加一个线程，如果新线程添加失败，我们知道线程被关闭了或者已经满了，所以任务会被拒绝<blockquote>
<ol>
<li>If we cannot queue task, then we try to add a new thread.  If it fails, we know we are shut down or saturated and so reject the task.  </li>
</ol>
</blockquote>
</li>
</ul>
</li>
<li>源码   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void execute(Runnable command) &#123;</span><br><span class="line">        &#x2F;&#x2F; 任务为空，抛异常</span><br><span class="line">        if (command &#x3D;&#x3D; null)</span><br><span class="line">            throw new NullPointerException();</span><br><span class="line">         &#x2F;&#x2F; ctl中保存的线程池当前的一些任务状态</span><br><span class="line">        int c &#x3D; ctl.get();</span><br><span class="line">        &#x2F;&#x2F; 上面介绍的3步从这里开始</span><br><span class="line">        &#x2F;&#x2F; 第一步，判断当前线程池中的任务数量是否小于核心线程数</span><br><span class="line">        &#x2F;&#x2F; 如果小于的话通过addWorker新建一个线程，并将任务添加到线程去执行</span><br><span class="line">        if (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class="line">            if (addWorker(command, true))</span><br><span class="line">                return;</span><br><span class="line">            c &#x3D; ctl.get();</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; 第二步，如果当前线程数已经大于等于核心线程数了</span><br><span class="line">        &#x2F;&#x2F; 通过isRunning来判断线程池状态，线程池处于RUNNING状态，才会将任务加入到workQueue队列中</span><br><span class="line">        if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class="line">            int recheck &#x3D; ctl.get();</span><br><span class="line">            &#x2F;&#x2F; 再次获取线程池状态，如果线程池不是RUNNING状态了，就需要从workQueue中移除任务</span><br><span class="line">            if (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class="line">                &#x2F;&#x2F; 执行拒绝策略</span><br><span class="line">                reject(command);</span><br><span class="line">            &#x2F;&#x2F; 当前线程池为空，则重新创建线程去执行任务</span><br><span class="line">            else if (workerCountOf(recheck) &#x3D;&#x3D; 0)</span><br><span class="line">                addWorker(null, false);</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; 第三步</span><br><span class="line">        &#x2F;&#x2F; 创建线程执行任务失败，执行相应的拒绝任务</span><br><span class="line">        else if (!addWorker(command, false))</span><br><span class="line">            reject(command);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<img src="/images/java_thread_pool/2.png" alt="avatar"></li>
</ul>
<h3 id="查看机器cpu信息"><a href="#查看机器cpu信息" class="headerlink" title="查看机器cpu信息"></a>查看机器cpu信息</h3><ul>
<li><p>查看物理cpu个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_thread_pool/4.png" alt="avatar"></p>
</li>
<li><p>查看每个物理cpu中core的个数（即核数）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;cpuinfo| grep &quot;cpu cores&quot;| uniq</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_thread_pool/5.png" alt="avatar"></p>
</li>
<li><p>查看逻辑cpu的个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;cpuinfo| grep &quot;processor&quot;| wc -l</span><br><span class="line">&#x2F;&#x2F; 在java里也可以这样查询</span><br><span class="line">Runtime.getRuntime().avaliableProcessor();</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_thread_pool/3.png" alt="avatar"></p>
</li>
<li><p>查看cpu型号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x2F;proc&#x2F;cpuinfo | grep name | uniq | cut -f2 -d:</span><br></pre></td></tr></table></figure>
<p><img src="/images/java_thread_pool/6.png" alt="avatar"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>interview</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>关于时间的思考和总结</title>
    <url>/2021/10/22/time-review/</url>
    <content><![CDATA[<h2 id="关于时间的解释"><a href="#关于时间的解释" class="headerlink" title="关于时间的解释"></a>关于时间的解释</h2><h3 id="GMT时间"><a href="#GMT时间" class="headerlink" title="GMT时间"></a>GMT时间</h3><p>格林尼治平时(Greenwich Mean Time，GMT)，又称为格林尼治标准时间。<br>格林尼治平时的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。自1924年2月5日开始，格林尼治天文台负责每隔一小时向全世界发放调时信息。由于地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。</p>
<h3 id="UT时间"><a href="#UT时间" class="headerlink" title="UT时间"></a>UT时间</h3><p>世界时(Universal Time，UT)，是一种以格林尼治子夜起算的平太阳时。<br>由于1925年以前人们在天文观测中，常常把每天的起始（0时）定为正午，而不是通常民用的午夜，给格林尼治平时的意义造成含糊，人们使用世界时一词来明确表示每天从午夜开始的格林尼治平时。</p>
<h3 id="时区"><a href="#时区" class="headerlink" title="时区"></a>时区</h3><p>时区是指地球上的某一个区域使用同一个时间定义。GMT时间或者UT时间，都是表示地球自转速率的一种形式。从太阳升起到太阳落下，时刻从0到24变化。这样，不同经度的地方时间自然会不相同。为了解决这个问题，人们把地球按经度划分为不同的区域，每个区域内使用同一个时间定义，相邻的区域时间差为1个小时。时区又分为理论时区和法定时区。</p>
<h3 id="UTC时间"><a href="#UTC时间" class="headerlink" title="UTC时间"></a>UTC时间</h3><p>协调世界时(Coordinated Universal Time)。是主要的世界时间标准，以原子钟所定义的秒长为基础，在时刻上尽量接近GMT时间。UTC时间认为一个太阳日总是86400秒。在大多数情况下，UTC时间能与GMT时间互换。</p>
<h4 id="UTC与时区"><a href="#UTC与时区" class="headerlink" title="UTC与时区"></a>UTC与时区</h4><p>本初子午线所在的时区的时间后面加上字符Z，表示UTC时间。Z即为0时区的标志，读做Zulu。例如09:30 UTC就写作0930Z，14:45:15 UTC则为14:45:15Z或144515Z</p>
<h4 id="UTC偏移量"><a href="#UTC偏移量" class="headerlink" title="UTC偏移量"></a>UTC偏移量</h4><p>UTC偏移量用以下形式表示: ±[hh]:[mm]、±[hh][mm]、或者±[hh]。例如UTC时间为09:30z，此时北京时间就是1730 +0800，纽约时间是0430 -0500。<br>UTC时间表示的格式一般为Sat, 20 May 2018 12:45:57 +0800表示东八区(北京时间)2018年5月20号 12:45:57星期六。</p>
<h4 id="时差"><a href="#时差" class="headerlink" title="时差"></a>时差</h4><p>某个地方的时刻与0时区的时刻差称为时差，时差东正西负。以本初子午线为中心，每向东一跨过一个时区，时刻增加一个小时，每向西跨过一个时区，时刻减少一个小时。</p>
<ul>
<li>如何理解向东时区增加<blockquote>
<p>由于地球是自西向东转，在地球的某一个地方观察，东边的时间比西边的时间早(东边的人们先看到太阳升起)。<br>想象一下某一个时刻，太阳在你的正上空，此时你所在的地点的时间为正午12点。这时住在你东边的人们，他们看到太阳已经在西边了，他们的时刻是下午，所以往东，时刻增加。</p>
</blockquote>
</li>
</ul>
<h4 id="UTC时间与本地时间的转换"><a href="#UTC时间与本地时间的转换" class="headerlink" title="UTC时间与本地时间的转换"></a>UTC时间与本地时间的转换</h4><p>UTC时间 + 时差 = 本地时间</p>
<h3 id="CST时间"><a href="#CST时间" class="headerlink" title="CST时间"></a>CST时间</h3><p>CST (China Standard Time，中国标准时间) 是UTC+8时区的知名名称之一，比UTC（协调世界时)提前8个小时与UTC的时间偏差可写为+08:00.</p>
<h2 id="http协议里respond的header日期"><a href="#http协议里respond的header日期" class="headerlink" title="http协议里respond的header日期"></a>http协议里respond的header日期</h2><p><img src="/images/time_knowledge/4.png" alt="avatar"></p>
<blockquote>
<p>All HTTP date/time stamps MUST be represented in Greenwich Mean Time (GMT), without exception.<br>格林尼治标准时间。 在HTTP协议中，时间都是用格林尼治标准时间来表示的，而不是本地时间。<br><a href="https://datatracker.ietf.org/doc/html/rfc7231#section-7.1.1.2" target="_blank" rel="noopener">RFC 7231, section 7.1.1.2: Date</a></p>
</blockquote>
<h2 id="在java里用到的时间"><a href="#在java里用到的时间" class="headerlink" title="在java里用到的时间"></a>在java里用到的时间</h2><p><img src="/images/time_knowledge/2.png" alt="avatar"></p>
<h3 id="SimpleDateFormat工具"><a href="#SimpleDateFormat工具" class="headerlink" title="SimpleDateFormat工具"></a>SimpleDateFormat工具</h3><ul>
<li>例子如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line">import java.util.Date;</span><br><span class="line"></span><br><span class="line">public class UTCTimeFormatTest &#123;</span><br><span class="line">    public static void main(String[] args) throws ParseException &#123;</span><br><span class="line">        &#x2F;&#x2F;Z代表UTC统一时间:2017-11-27T03:16:03.944Z</span><br><span class="line">        SimpleDateFormat format &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS&#39;Z&#39;&quot;);</span><br><span class="line">        Date date &#x3D; new Date();</span><br><span class="line">        System.out.println(date);</span><br><span class="line">        String str &#x3D; format.format(date);</span><br><span class="line">        System.out.println(str);</span><br><span class="line">        SimpleDateFormat dayformat &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);</span><br><span class="line">        String source &#x3D;&quot;2018-09-18&quot;;        &#x2F;&#x2F;先将年月日的字符串日期格式化为date类型</span><br><span class="line">        Date day &#x3D; dayformat.parse(source);　　　　 &#x2F;&#x2F;然后将date类型的日期转化为UTC格式的时间</span><br><span class="line">        String str2&#x3D; format.format(day);</span><br><span class="line">        System.out.println(str2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
打印结果<br><img src="/images/time_knowledge/1.png" alt="avatar"><h3 id="SimpleDateFormat线程不安全"><a href="#SimpleDateFormat线程不安全" class="headerlink" title="SimpleDateFormat线程不安全"></a>SimpleDateFormat线程不安全</h3><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line">import java.util.Date;</span><br><span class="line">import java.util.concurrent.ExecutorService;</span><br><span class="line">import java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line">public class SimpleDateFormatTest extends Thread &#123;</span><br><span class="line">    private static SimpleDateFormat simpleDateFormat &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);</span><br><span class="line">    private String name;</span><br><span class="line">    private String dateStr;</span><br><span class="line"></span><br><span class="line">    public SimpleDateFormatTest(String name, String dateStr) &#123;</span><br><span class="line">        this.dateStr &#x3D; dateStr;</span><br><span class="line">        this.name &#x3D; name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            Date date &#x3D; simpleDateFormat.parse(dateStr);</span><br><span class="line">            System.out.println(name + &quot;: date : &quot; + date);</span><br><span class="line">        &#125; catch (ParseException exception) &#123;</span><br><span class="line">            exception.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        ExecutorService executorService &#x3D; Executors.newFixedThreadPool(3);</span><br><span class="line">        executorService.execute(new SimpleDateFormatTest(&quot;A&quot;, &quot;2017-01-01&quot;));</span><br><span class="line">        executorService.execute(new SimpleDateFormatTest(&quot;B&quot;, &quot;2020-12-12&quot;));</span><br><span class="line">        executorService.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
运行结果<br><img src="/images/time_knowledge/3.png" alt="avatar"><h4 id="原理解释"><a href="#原理解释" class="headerlink" title="原理解释"></a>原理解释</h4></li>
<li>SimpleDateFormat构造函数<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public SimpleDateFormat(String pattern, Locale locale)</span><br><span class="line">&#123;</span><br><span class="line">    if (pattern &#x3D;&#x3D; null || locale &#x3D;&#x3D; null) &#123;</span><br><span class="line">        throw new NullPointerException();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    initializeCalendar(locale);</span><br><span class="line">    this.pattern &#x3D; pattern;</span><br><span class="line">    this.formatData &#x3D; DateFormatSymbols.getInstanceRef(locale);</span><br><span class="line">    this.locale &#x3D; locale;</span><br><span class="line">    initialize(locale);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>initializeCalendar初始化calendar方法<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void initializeCalendar(Locale loc) &#123;</span><br><span class="line">    if (calendar &#x3D;&#x3D; null) &#123;</span><br><span class="line">        assert loc !&#x3D; null;</span><br><span class="line">        &#x2F;&#x2F; The format object must be constructed using the symbols for this zone.</span><br><span class="line">        &#x2F;&#x2F; However, the calendar should use the current default TimeZone.</span><br><span class="line">        &#x2F;&#x2F; If this is not contained in the locale zone strings, then the zone</span><br><span class="line">        &#x2F;&#x2F; will be formatted using generic GMT+&#x2F;-H:MM nomenclature.</span><br><span class="line">        calendar &#x3D; Calendar.getInstance(TimeZone.getDefault(), loc);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>calendar变量的构造过程<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static Calendar getInstance(TimeZone zone, Locale aLocale)</span><br><span class="line">&#123;</span><br><span class="line">    return createCalendar(zone, aLocale);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private static Calendar createCalendar(TimeZone zone, Locale aLocale)</span><br><span class="line">&#123;</span><br><span class="line">    CalendarProvider provider &#x3D;</span><br><span class="line">        LocaleProviderAdapter.getAdapter(CalendarProvider.class, aLocale)</span><br><span class="line">                                .getCalendarProvider();</span><br><span class="line">    if (provider !&#x3D; null) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            return provider.getInstance(zone, aLocale);</span><br><span class="line">        &#125; catch (IllegalArgumentException iae) &#123;</span><br><span class="line">            &#x2F;&#x2F; fall back to the default instantiation</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Calendar cal &#x3D; null;</span><br><span class="line"></span><br><span class="line">    if (aLocale.hasExtensions()) &#123;</span><br><span class="line">        String caltype &#x3D; aLocale.getUnicodeLocaleType(&quot;ca&quot;);</span><br><span class="line">        if (caltype !&#x3D; null) &#123;</span><br><span class="line">            switch (caltype) &#123;</span><br><span class="line">            case &quot;buddhist&quot;:</span><br><span class="line">            cal &#x3D; new BuddhistCalendar(zone, aLocale);</span><br><span class="line">                break;</span><br><span class="line">            case &quot;japanese&quot;:</span><br><span class="line">                cal &#x3D; new JapaneseImperialCalendar(zone, aLocale);</span><br><span class="line">                break;</span><br><span class="line">            case &quot;gregory&quot;:</span><br><span class="line">                cal &#x3D; new GregorianCalendar(zone, aLocale);</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (cal &#x3D;&#x3D; null) &#123;</span><br><span class="line">        &#x2F;&#x2F; If no known calendar type is explicitly specified,</span><br><span class="line">        &#x2F;&#x2F; perform the traditional way to create a Calendar:</span><br><span class="line">        &#x2F;&#x2F; create a BuddhistCalendar for th_TH locale,</span><br><span class="line">        &#x2F;&#x2F; a JapaneseImperialCalendar for ja_JP_JP locale, or</span><br><span class="line">        &#x2F;&#x2F; a GregorianCalendar for any other locales.</span><br><span class="line">        &#x2F;&#x2F; NOTE: The language, country and variant strings are interned.</span><br><span class="line">        if (aLocale.getLanguage() &#x3D;&#x3D; &quot;th&quot; &amp;&amp; aLocale.getCountry() &#x3D;&#x3D; &quot;TH&quot;) &#123;</span><br><span class="line">            cal &#x3D; new BuddhistCalendar(zone, aLocale);</span><br><span class="line">        &#125; else if (aLocale.getVariant() &#x3D;&#x3D; &quot;JP&quot; &amp;&amp; aLocale.getLanguage() &#x3D;&#x3D; &quot;ja&quot;</span><br><span class="line">                    &amp;&amp; aLocale.getCountry() &#x3D;&#x3D; &quot;JP&quot;) &#123;</span><br><span class="line">            cal &#x3D; new JapaneseImperialCalendar(zone, aLocale);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            cal &#x3D; new GregorianCalendar(zone, aLocale);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return cal;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过查看源码发现，原来SimpleDateFormat类内部有一个Calendar对象引用,它用来储存和这个SimpleDateFormat相关的日期信息,例如sdf.parse(dateStr),sdf.format(date) 诸如此类的方法参数传入的日期相关String,Date等等, 都是交由Calendar引用来储存的.这样就会导致一个问题,如果你的SimpleDateFormat是个static的, 那么多个thread 之间就会共享这个SimpleDateFormat, 同时也是共享这个Calendar引用。</p>
</blockquote>
</li>
</ul>
<h4 id="正确姿势"><a href="#正确姿势" class="headerlink" title="正确姿势"></a>正确姿势</h4><ul>
<li>将SimpleDateFormat定义成局部变量<blockquote>
<p>缺点是每次调用方法后都会实例化一个SimpleDateFormat对象，方法结束后会被垃圾回收</p>
</blockquote>
</li>
<li>如果要定义成静态变量，一定要加锁，保证同一个时刻就只有一个线程可以访问到SimpleDateFormat对象<blockquote>
<p>缺点是性能变差，每次都得等待锁释放后其他线程才能访问SimpleDateFormat对象</p>
</blockquote>
</li>
<li><p>使用ThreadLocal来保存SimpleDateFormat对象，每个线程拥有自己的SimpleDateFormat对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line">import java.util.Date;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">public class DateUtils &#123;</span><br><span class="line">    &#x2F;&#x2F; 单例</span><br><span class="line">    private static Map&lt;String, ThreadLocal&lt;SimpleDateFormat&gt;&gt; localMap &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">    private static final Object lockObject &#x3D; new Object();</span><br><span class="line"></span><br><span class="line">    public static SimpleDateFormat getSimpleDateFormat(String pattern) &#123;</span><br><span class="line">        ThreadLocal&lt;SimpleDateFormat&gt; threadLocal &#x3D; localMap.get(pattern);</span><br><span class="line">        if (threadLocal &#x3D;&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F; 加锁，不重复初始化已经存在的pattern</span><br><span class="line">            synchronized (lockObject) &#123;</span><br><span class="line">                &#x2F;&#x2F; 再取一次是为了防止localMap被重复多次put已存在的pattern</span><br><span class="line">                threadLocal &#x3D; localMap.get(pattern);</span><br><span class="line">                if (threadLocal &#x3D;&#x3D; null) &#123;</span><br><span class="line">                    System.out.println(&quot;put new sdf of pattern &quot; + pattern + &quot; to map&quot;);</span><br><span class="line">                    threadLocal &#x3D; new ThreadLocal&lt;SimpleDateFormat&gt;() &#123;</span><br><span class="line">                        @Override</span><br><span class="line">                        protected SimpleDateFormat initialValue() &#123;</span><br><span class="line">                            System.out.println(&quot;thread: &quot; + Thread.currentThread() + &quot; init pattern: &quot; + pattern);</span><br><span class="line">                            return new SimpleDateFormat(pattern);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;;</span><br><span class="line">                    localMap.put(pattern, threadLocal);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return threadLocal.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String format(Date date, String pattern) &#123;</span><br><span class="line">        return getSimpleDateFormat(pattern).format(date);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static Date parse(String dateString, String pattern) throws ParseException &#123;</span><br><span class="line">        return getSimpleDateFormat(pattern).parse(dateString);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="ThreadLocal解析"><a href="#ThreadLocal解析" class="headerlink" title="ThreadLocal解析"></a>ThreadLocal解析</h4><p><img src="/images/time_knowledge/5.png" alt="avatar"></p>
<blockquote>
<p>ThreadLocal是用哈希表实现的，每个线程里都有一个ThreadLocalMap，就是以Map的形式存储多个ThreadLocal对象，当线程调用ThreadLocal操作方法时，都会通过当前线程Thread对象拿到ThreadLocalMap，再通过ThreadLocal对象从ThreadLocalMap中锁定数据实体（ThreadLocal.Entry）</p>
</blockquote>
</li>
<li><p>ThreadLocal.set方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void set(T value) &#123;</span><br><span class="line">    &#x2F;&#x2F; 取出当前线程</span><br><span class="line">    Thread t &#x3D; Thread.currentThread();</span><br><span class="line">    &#x2F;&#x2F; 取出Thread.ThreadLocal.ThreadLocalMap threadLocals &#x3D; null;</span><br><span class="line">    ThreadLocalMap map &#x3D; getMap(t);</span><br><span class="line">    &#x2F;&#x2F; 已存在，则更新</span><br><span class="line">    if (map !&#x3D; null)</span><br><span class="line">        map.set(this, value);</span><br><span class="line">    else</span><br><span class="line">    &#x2F;&#x2F; 否则创建map</span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>ThreadLocalMap.set方法<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">* Set the value associated with key.</span><br><span class="line">*</span><br><span class="line">* @param key the thread local object</span><br><span class="line">* @param value the value to be set</span><br><span class="line">*&#x2F;</span><br><span class="line">private void set(ThreadLocal&lt;?&gt; key, Object value) &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; We don&#39;t use a fast path as with get() because it is at</span><br><span class="line">    &#x2F;&#x2F; least as common to use set() to create new entries as</span><br><span class="line">    &#x2F;&#x2F; it is to replace existing ones, in which case, a fast</span><br><span class="line">    &#x2F;&#x2F; path would fail more often than not.</span><br><span class="line"></span><br><span class="line">    Entry[] tab &#x3D; table;</span><br><span class="line">    int len &#x3D; tab.length;</span><br><span class="line">    int i &#x3D; key.threadLocalHashCode &amp; (len-1);</span><br><span class="line"></span><br><span class="line">    for (Entry e &#x3D; tab[i];</span><br><span class="line">            e !&#x3D; null;</span><br><span class="line">            e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123;</span><br><span class="line">        ThreadLocal&lt;?&gt; k &#x3D; e.get();</span><br><span class="line"></span><br><span class="line">        if (k &#x3D;&#x3D; key) &#123;</span><br><span class="line">            e.value &#x3D; value;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (k &#x3D;&#x3D; null) &#123;</span><br><span class="line">            replaceStaleEntry(key, value, i);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tab[i] &#x3D; new Entry(key, value);</span><br><span class="line">    int sz &#x3D; ++size;</span><br><span class="line">    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;&#x3D; threshold)</span><br><span class="line">        rehash();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>ThreadLocal.createMap方法<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">* Create the map associated with a ThreadLocal. Overridden in</span><br><span class="line">* InheritableThreadLocal.</span><br><span class="line">*</span><br><span class="line">* @param t the current thread</span><br><span class="line">* @param firstValue value for the initial entry of the map</span><br><span class="line">*&#x2F;</span><br><span class="line">void createMap(Thread t, T firstValue) &#123;</span><br><span class="line">    &#x2F;&#x2F; 实例化一个新ThreadLocalMap对象</span><br><span class="line">    &#x2F;&#x2F; this就是操作的ThreadLocal对象，firstValue就是要保存的值</span><br><span class="line">    t.threadLocals &#x3D; new ThreadLocalMap(this, firstValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="SimpleDateFormat挖坑自跳"><a href="#SimpleDateFormat挖坑自跳" class="headerlink" title="SimpleDateFormat挖坑自跳"></a>SimpleDateFormat挖坑自跳</h3><h4 id="坑王举例"><a href="#坑王举例" class="headerlink" title="坑王举例"></a>坑王举例</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line">public class SimpleDateFormatErrorTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            String date1 &#x3D; &quot;2021-05-01&quot;;</span><br><span class="line">            SimpleDateFormat simpleDateFormat &#x3D; new SimpleDateFormat(&quot;yyyyMMdd&quot;);</span><br><span class="line">            System.out.println(simpleDateFormat.parse(date1));</span><br><span class="line">        &#125; catch (ParseException exception) &#123;</span><br><span class="line">            exception.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打印结果如下<br><img src="/images/time_knowledge/6.png" alt="avatar"><br>这个代码预期是会走到catch的exception里，但是却正常打印输出了</p>
<h4 id="SimpleDateFormat-parse源码解析"><a href="#SimpleDateFormat-parse源码解析" class="headerlink" title="SimpleDateFormat.parse源码解析"></a>SimpleDateFormat.parse源码解析</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Date parse(String text, ParsePosition pos)</span><br><span class="line">&#123;</span><br><span class="line">    checkNegativeNumberExpression();</span><br><span class="line"></span><br><span class="line">    int start &#x3D; pos.index;</span><br><span class="line">    int oldStart &#x3D; start;</span><br><span class="line">    int textLength &#x3D; text.length();</span><br><span class="line"></span><br><span class="line">    boolean[] ambiguousYear &#x3D; &#123;false&#125;;</span><br><span class="line"></span><br><span class="line">    CalendarBuilder calb &#x3D; new CalendarBuilder();</span><br><span class="line"></span><br><span class="line">    for (int i &#x3D; 0; i &lt; compiledPattern.length; ) &#123;</span><br><span class="line">        int tag &#x3D; compiledPattern[i] &gt;&gt;&gt; 8;</span><br><span class="line">        int count &#x3D; compiledPattern[i++] &amp; 0xff;</span><br><span class="line">        if (count &#x3D;&#x3D; 255) &#123;</span><br><span class="line">            count &#x3D; compiledPattern[i++] &lt;&lt; 16;</span><br><span class="line">            count |&#x3D; compiledPattern[i++];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        switch (tag) &#123;</span><br><span class="line">        case TAG_QUOTE_ASCII_CHAR:</span><br><span class="line">            if (start &gt;&#x3D; textLength || text.charAt(start) !&#x3D; (char)count) &#123;</span><br><span class="line">                pos.index &#x3D; oldStart;</span><br><span class="line">                pos.errorIndex &#x3D; start;</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">            start++;</span><br><span class="line">            break;</span><br><span class="line"></span><br><span class="line">        case TAG_QUOTE_CHARS:</span><br><span class="line">            while (count-- &gt; 0) &#123;</span><br><span class="line">                if (start &gt;&#x3D; textLength || text.charAt(start) !&#x3D; compiledPattern[i++]) &#123;</span><br><span class="line">                    pos.index &#x3D; oldStart;</span><br><span class="line">                    pos.errorIndex &#x3D; start;</span><br><span class="line">                    return null;</span><br><span class="line">                &#125;</span><br><span class="line">                start++;</span><br><span class="line">            &#125;</span><br><span class="line">            break;</span><br><span class="line">        &#x2F;&#x2F; 进入默认配置</span><br><span class="line">        default:</span><br><span class="line">            &#x2F;&#x2F; Peek the next pattern to determine if we need to</span><br><span class="line">            &#x2F;&#x2F; obey the number of pattern letters for</span><br><span class="line">            &#x2F;&#x2F; parsing. It&#39;s required when parsing contiguous</span><br><span class="line">            &#x2F;&#x2F; digit text (e.g., &quot;20010704&quot;) with a pattern which</span><br><span class="line">            &#x2F;&#x2F; has no delimiters between fields, like &quot;yyyyMMdd&quot;.</span><br><span class="line">            boolean obeyCount &#x3D; false;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 在阿拉伯语中，负数的减号可以放在数字的后面（1111-）</span><br><span class="line">            &#x2F;&#x2F; In Arabic, a minus sign for a negative number is put after</span><br><span class="line">            &#x2F;&#x2F; the number. Even in another locale, a minus sign can be</span><br><span class="line">            &#x2F;&#x2F; put after a number using DateFormat.setNumberFormat().</span><br><span class="line">            &#x2F;&#x2F; If both the minus sign and the field-delimiter are &#39;-&#39;,</span><br><span class="line">            &#x2F;&#x2F; subParse() needs to determine whether a &#39;-&#39; after a number</span><br><span class="line">            &#x2F;&#x2F; in the given text is a delimiter or is a minus sign for the</span><br><span class="line">            &#x2F;&#x2F; preceding number. We give subParse() a clue based on the</span><br><span class="line">            &#x2F;&#x2F; information in compiledPattern.</span><br><span class="line">            boolean useFollowingMinusSignAsDelimiter &#x3D; false;</span><br><span class="line"></span><br><span class="line">            if (i &lt; compiledPattern.length) &#123;</span><br><span class="line">                int nextTag &#x3D; compiledPattern[i] &gt;&gt;&gt; 8;</span><br><span class="line">                if (!(nextTag &#x3D;&#x3D; TAG_QUOTE_ASCII_CHAR ||</span><br><span class="line">                        nextTag &#x3D;&#x3D; TAG_QUOTE_CHARS)) &#123;</span><br><span class="line">                    obeyCount &#x3D; true;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                if (hasFollowingMinusSign &amp;&amp;</span><br><span class="line">                    (nextTag &#x3D;&#x3D; TAG_QUOTE_ASCII_CHAR ||</span><br><span class="line">                        nextTag &#x3D;&#x3D; TAG_QUOTE_CHARS)) &#123;</span><br><span class="line">                    int c;</span><br><span class="line">                    if (nextTag &#x3D;&#x3D; TAG_QUOTE_ASCII_CHAR) &#123;</span><br><span class="line">                        c &#x3D; compiledPattern[i] &amp; 0xff;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        c &#x3D; compiledPattern[i+1];</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    if (c &#x3D;&#x3D; minusSign) &#123;</span><br><span class="line">                        useFollowingMinusSignAsDelimiter &#x3D; true;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            start &#x3D; subParse(text, start, tag, count, obeyCount,</span><br><span class="line">                                ambiguousYear, pos,</span><br><span class="line">                                useFollowingMinusSignAsDelimiter, calb);</span><br><span class="line">            if (start &lt; 0) &#123;</span><br><span class="line">                pos.index &#x3D; oldStart;</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; At this point the fields of Calendar have been set.  Calendar</span><br><span class="line">    &#x2F;&#x2F; will fill in default values for missing fields when the time</span><br><span class="line">    &#x2F;&#x2F; is computed.</span><br><span class="line"></span><br><span class="line">    pos.index &#x3D; start;</span><br><span class="line"></span><br><span class="line">    Date parsedDate;</span><br><span class="line">    try &#123;</span><br><span class="line">        parsedDate &#x3D; calb.establish(calendar).getTime();</span><br><span class="line">        &#x2F;&#x2F; If the year value is ambiguous,</span><br><span class="line">        &#x2F;&#x2F; then the two-digit year &#x3D;&#x3D; the default start year</span><br><span class="line">        if (ambiguousYear[0]) &#123;</span><br><span class="line">            if (parsedDate.before(defaultCenturyStart)) &#123;</span><br><span class="line">                parsedDate &#x3D; calb.addYear(100).establish(calendar).getTime();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; An IllegalArgumentException will be thrown by Calendar.getTime()</span><br><span class="line">    &#x2F;&#x2F; if any fields are out of range, e.g., MONTH &#x3D;&#x3D; 17.</span><br><span class="line">    catch (IllegalArgumentException e) &#123;</span><br><span class="line">        pos.errorIndex &#x3D; start;</span><br><span class="line">        pos.index &#x3D; oldStart;</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return parsedDate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>正确姿势<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line">public class SimpleDateFormatErrorTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String date1 &#x3D; &quot;2021-05-01&quot;;</span><br><span class="line">        try &#123;</span><br><span class="line">            SimpleDateFormat simpleDateFormat &#x3D; new SimpleDateFormat(&quot;yyyyMMdd&quot;);</span><br><span class="line">            &#x2F;&#x2F; 设置为严格模式,Calendar类默认把lenient设置为true，意思是宽松模式解析</span><br><span class="line">            simpleDateFormat.setLenient(false);</span><br><span class="line">            System.out.println(simpleDateFormat.parse(date1));</span><br><span class="line">        &#125; catch (ParseException exception) &#123;</span><br><span class="line">            exception.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
运行结果，看到已经抛出异常了<br><img src="/images/time_knowledge/7.png" alt="avatar"><h4 id="坑爹举例"><a href="#坑爹举例" class="headerlink" title="坑爹举例"></a>坑爹举例</h4></li>
<li>代码如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.text.ParseException;</span><br><span class="line">import java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line">public class SimpleDateFormatErrorTest &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        String date1 &#x3D; &quot;2021-05-01&quot;;</span><br><span class="line">        try &#123;</span><br><span class="line">            SimpleDateFormat simpleDateFormat &#x3D; new SimpleDateFormat(&quot;YYYY-MM-dd&quot;);</span><br><span class="line">            &#x2F;&#x2F; 设置为严格模式</span><br><span class="line">            simpleDateFormat.setLenient(false);</span><br><span class="line">            System.out.println(simpleDateFormat.parse(date1));</span><br><span class="line">        &#125; catch (ParseException exception) &#123;</span><br><span class="line">            exception.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
打印结果，输出是2020-12-27<br><img src="/images/time_knowledge/8.png" alt="avatar"></li>
<li>详解<br><a href="https://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html" target="_blank" rel="noopener">官方文档</a>  </li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">字母</th>
<th style="text-align:right">日期含义</th>
<th style="text-align:center">举例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">y</td>
<td style="text-align:right">year</td>
<td style="text-align:center">正常年份</td>
</tr>
<tr>
<td style="text-align:left">Y</td>
<td style="text-align:right">week year</td>
<td style="text-align:center">按周算的年份，比如2018年12月31日，正好是2019 Week-year的第一周第一天</td>
</tr>
<tr>
<td style="text-align:left">D</td>
<td style="text-align:right">Day in year</td>
<td style="text-align:center">一年中的第几天</td>
</tr>
<tr>
<td style="text-align:left">d</td>
<td style="text-align:right">Day in month</td>
<td style="text-align:center">正常日期的日</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>interview</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>wireshark3.4.8保姆级入门教程</title>
    <url>/2021/10/02/wireshard3.4.8/</url>
    <content><![CDATA[<h2 id="wireshark3-4-8，主界面"><a href="#wireshark3-4-8，主界面" class="headerlink" title="wireshark3.4.8，主界面"></a>wireshark3.4.8，主界面</h2><p><img src="/images/wireshark/1.png" alt="avatar"></p>
<h2 id="通过ping简单入门"><a href="#通过ping简单入门" class="headerlink" title="通过ping简单入门"></a>通过ping简单入门</h2><ul>
<li>启动wireshark后，wireshark处于抓包状态中<br><img src="/images/wireshark/2.png" alt="avatar"></li>
<li>在终端输入ping命令后<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping www.baidu.com</span><br></pre></td></tr></table></figure>
<img src="/images/wireshark/3.png" alt="avatar"></li>
<li>通过过滤栏设置过滤条件进行数据包列表过滤<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip.addr &#x3D;&#x3D; 180.101.49.12 and icmp</span><br></pre></td></tr></table></figure>
<img src="/images/wireshark/4.png" alt="avatar"></li>
</ul>
<blockquote>
<p>ICMP（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议簇的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。 ICMP协议是一种面向无连接的协议。</p>
</blockquote>
<h2 id="wireshark抓包界面介绍"><a href="#wireshark抓包界面介绍" class="headerlink" title="wireshark抓包界面介绍"></a>wireshark抓包界面介绍</h2><p><img src="/images/wireshark/5.png" alt="avatar"></p>
<ul>
<li>Display Filter(显示过滤器)，  用于设置过滤条件进行数据包列表过滤。菜单路径：Analyze —&gt; Display Filters。</li>
<li>Packet List Pane(数据包列表)， 显示捕获到的数据包，每个数据包包含编号，时间戳，源地址，目标地址，协议，长度，以及数据包信息。 不同协议的数据包使用了不同的颜色区分显示</li>
<li>Packet Details Pane(数据包详细信息), 在数据包列表中选择指定数据包，在数据包详细信息中会显示数据包的所有详细信息内容。数据包详细信息面板是最重要的，用来查看协议中的每一个字段。各行信息分别为<br>（1）Frame:   物理层的数据帧概况<br>（2）Ethernet II: 数据链路层以太网帧头部信息<br>（3）Internet Protocol Version 4: 互联网层IP包头部信息<br>（4）Transmission Control Protocol:  传输层T的数据段头部信息，此处是TCP<br>（5）Hypertext Transfer Protocol:  应用层的信息，此处是HTTP协议<br><img src="/images/wireshark/6.png" alt="avatar"></li>
</ul>
<h3 id="TCP包的具体内容"><a href="#TCP包的具体内容" class="headerlink" title="TCP包的具体内容"></a>TCP包的具体内容</h3><p><img src="/images/wireshark/7.png" alt="avatar"></p>
<h3 id="抓包过滤器语法"><a href="#抓包过滤器语法" class="headerlink" title="抓包过滤器语法"></a>抓包过滤器语法</h3><ul>
<li>抓包过滤器语法和实例<blockquote>
<p>抓包过滤器类型Type（host、net、port）、方向Dir（src、dst）、协议Proto（ether、ip、tcp、udp、http、icmp、ftp等）、逻辑运算符（&amp;&amp; 与、|| 或、！非）</p>
</blockquote>
</li>
</ul>
<p>（1）协议过滤</p>
<p>  比较简单，直接在抓包过滤框中直接输入协议名即可。</p>
<p>  TCP，只显示TCP协议的数据包列表</p>
<p>  HTTP，只查看HTTP协议的数据包列表</p>
<p>  ICMP，只显示ICMP协议的数据包列表</p>
<p>（2）IP过滤</p>
<p>  host 192.168.1.104</p>
<p>  src host 192.168.1.104</p>
<p>  dst host 192.168.1.104</p>
<p>（3）端口过滤</p>
<p>  port 80</p>
<p>  src port 80</p>
<p>  dst port 80</p>
<p>（4）逻辑运算符&amp;&amp; 与、|| 或、！非</p>
<p>  src host 192.168.1.104 &amp;&amp; dst port 80 抓取主机地址为192.168.1.80、目的端口为80的数据包</p>
<p>  host 192.168.1.104 || host 192.168.1.102 抓取主机为192.168.1.104或者192.168.1.102的数据包</p>
<p>  ！broadcast 不抓取广播数据包</p>
<p>2、显示过滤器语法和实例</p>
<p>（1）比较操作符</p>
<p>  比较操作符有== 等于、！= 不等于、&gt; 大于、&lt; 小于、&gt;= 大于等于、&lt;=小于等于。</p>
<p>（2）协议过滤</p>
<p>  比较简单，直接在Filter框中直接输入协议名即可。注意：协议名称需要输入小写。</p>
<p>  tcp，只显示TCP协议的数据包列表</p>
<p>  http，只查看HTTP协议的数据包列表</p>
<p>  icmp，只显示ICMP协议的数据包列表  </p>
<p>（3） ip过滤</p>
<p>   ip.src ==192.168.1.104 显示源地址为192.168.1.104的数据包列表</p>
<p>   ip.dst==192.168.1.104, 显示目标地址为192.168.1.104的数据包列表</p>
<p>   ip.addr == 192.168.1.104 显示源IP地址或目标IP地址为192.168.1.104的数据包列表</p>
<p>（4）端口过滤</p>
<p>  tcp.port ==80,  显示源主机或者目的主机端口为80的数据包列表。</p>
<p>  tcp.srcport == 80,  只显示TCP协议的源主机端口为80的数据包列表。</p>
<p>  tcp.dstport == 80，只显示TCP协议的目的主机端口为80的数据包列表。  </p>
<p>（5） Http模式过滤</p>
<p>  http.request.method==”GET”,   只显示HTTP GET方法的。</p>
<p>（6）逻辑运算符为 and/or/not</p>
<p>  过滤多个条件组合时，使用and/or。比如获取IP地址为192.168.1.104的ICMP数据包表达式为ip.addr == 192.168.1.104 and icmp</p>
<h3 id="wireshark抓包分析tcp3次握手"><a href="#wireshark抓包分析tcp3次握手" class="headerlink" title="wireshark抓包分析tcp3次握手"></a>wireshark抓包分析tcp3次握手</h3><blockquote>
<p>以某天气预报api举例,<a href="http://jisutianqi.market.alicloudapi.com/weather/query" target="_blank" rel="noopener">http://jisutianqi.market.alicloudapi.com/weather/query</a></p>
<ul>
<li>启动wireshark</li>
<li>用浏览器访问<a href="http://jisutianqi.market.alicloudapi.com/weather/query" target="_blank" rel="noopener">地址</a></li>
<li>在终端输入，得到实际ip地址<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping jisutianqi.market.alicloudapi.com</span><br></pre></td></tr></table></figure>
<img src="/images/wireshark/8.png" alt="avatar"></li>
<li>在wireshark上过滤<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip.addr &#x3D;&#x3D; 47.97.242.71</span><br></pre></td></tr></table></figure>
<img src="/images/wireshark/9.png" alt="avatar"><br>图中可以看到wireshark截获到了三次握手的三个数据包。第四个包才是HTTP的， 这说明HTTP的确是使用TCP建立连接的。</li>
<li>第一次握手抓包<br>客户端发送一个TCP，标志位为SYN，序列号为0， 代表客户端请求建立连接。 如下图。<br><img src="/images/wireshark/10.png" alt="avatar"><br>数据包的关键属性如下：<ul>
<li>SYN ：标志位，表示请求建立连接</li>
<li>Seq = 0 ：初始建立连接值为0，数据包的相对序列号从0开始，表示当前还没有发送数据</li>
<li>Ack =0：初始建立连接值为0，已经收到包的数量，表示当前没有接收到数据</li>
</ul>
</li>
<li>第二次握手抓包<br>服务器发回确认包, 标志位为 SYN,ACK. 将确认序号(Acknowledgement Number)设置为客户的I S N加1以.即0+1=1, 如下图<br><img src="/images/wireshark/11.png" alt="avatar"><br>数据包的关键属性如下：<ul>
<li>[SYN + ACK]: 标志位，同意建立连接，并回送SYN+ACK</li>
<li>Seq = 0 ：初始建立值为0，表示当前还没有发送数据</li>
<li>Ack = 1：表示当前端成功接收的数据位数，虽然客户端没有发送任何有效数据，确认号还是被加1，因为包含SYN或FIN标志位。（并不会对有效数据的计数产生影响，因为含有SYN或FIN标志位的包并不携带有效数据）</li>
</ul>
</li>
<li>第三次握手抓包<br>客户端再次发送确认包(ACK) SYN标志位为0,ACK标志位为1.并且把服务器发来ACK的序号字段+1,放在确定字段中发送给对方.并且在数据段放写ISN的+1, 如下图:<br><img src="/images/wireshark/12.png" alt="avatar"><br>数据包的关键属性如下：<ul>
<li>ACK ：标志位，表示已经收到记录</li>
<li>Seq = 1 ：表示当前已经发送1个数据</li>
<li>Ack = 1 : 表示当前端成功接收的数据位数，虽然服务端没有发送任何有效数据，确认号还是被加1，因为包含SYN或FIN标志位（并不会对有效数据的计数产生影响，因为含有SYN或FIN标志位的包并不携带有效数据)。</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>在TCP层，有个FLAGS字段，这个字段有以下几个标识：SYN, FIN, ACK, PSH, RST, URG。如下<br><img src="/images/wireshark/13.png" alt="avatar"><br>其中，对于我们日常的分析有用的就是前面的五个字段。它们的含义是：<ul>
<li>SYN表示建立连接，</li>
<li>FIN表示关闭连接，</li>
<li>ACK表示响应，</li>
<li>PSH表示有DATA数据传输，</li>
<li>RST表示连接重置</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>introduction</category>
      </categories>
      <tags>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title>教你新建一个vue项目</title>
    <url>/2019/11/27/vue-create-project/</url>
    <content><![CDATA[<ul>
<li>全局安装vue脚手架<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install vue-cli -g</span><br></pre></td></tr></table></figure></li>
<li>使用webpack初始化项目<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vue init webpack my-project</span><br></pre></td></tr></table></figure>
下面是安装过程系统给出的提示<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;项目名称</span><br><span class="line">? Project name devops</span><br><span class="line">&#x2F;&#x2F;项目描述</span><br><span class="line">? Project description bigdata devops platform</span><br><span class="line">&#x2F;&#x2F;项目作者</span><br><span class="line">? Author blank &lt;luck.linxiaoyu@gmail.com&gt;</span><br><span class="line">? Vue build standalone</span><br><span class="line">&#x2F;&#x2F;安装vue-router（vue的路由）</span><br><span class="line">? Install vue-router? Yes</span><br><span class="line">&#x2F;&#x2F; 使用eslint格式化你的代码</span><br><span class="line">? Use ESLint to lint your code? Yes</span><br><span class="line">&#x2F;&#x2F;选择Airbnb作为eslint的格式标准</span><br><span class="line">? Pick an ESLint preset Airbnb</span><br><span class="line">&#x2F;&#x2F;选一个单元测试工具</span><br><span class="line">? Set up unit tests Yes</span><br><span class="line">&#x2F;&#x2F; 我选的是jest</span><br><span class="line">? Pick a test runner jest</span><br><span class="line">&#x2F;&#x2F;使用nightwatch开始e2e单元测试</span><br><span class="line">? Setup e2e tests with Nightwatch? Yes</span><br><span class="line">&#x2F;&#x2F;项目创建使用使用npm install进行其他包安装</span><br><span class="line">? Should we run &#96;npm install&#96; for you after the project has been created? </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Project initialization finished!</span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">&#x2F;&#x2F; 安装完成给出提示如何启动项目</span><br><span class="line">To get started:</span><br><span class="line">  cd new</span><br><span class="line">  npm run dev</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>vuejs</tag>
        <tag>vue-cli</tag>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title>源码安装zabbix5.0</title>
    <url>/2020/08/14/zabbix-source-data-install/</url>
    <content><![CDATA[<ul>
<li><p>zabbix介绍</p>
<blockquote>
<p>通过<a href="https://www.zabbix.com/cn/whats_new_5_0" target="_blank" rel="noopener">官网</a>我们可以了解zabbix5.0和之前版本的差异及作出的改进</p>
</blockquote>
</li>
<li><p>下载zabbix5.0源码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install  epel-release wget tar</span><br><span class="line">wget https:&#x2F;&#x2F;cdn.zabbix.com&#x2F;zabbix&#x2F;sources&#x2F;stable&#x2F;5.0&#x2F;zabbix-5.0.2.tar.gz</span><br><span class="line">tar zxvf zabbix-5.0.2.tar.gz</span><br><span class="line">cd zabbix-5.0.2</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建zabbix用户</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groupadd zabbix</span><br><span class="line">useradd  -g  zabbix zabbix</span><br><span class="line">usermod  -s  &#x2F;sbin&#x2F;nologin  zabbix</span><br></pre></td></tr></table></figure>
</li>
<li><p>mysql相关操作</p>
<blockquote>
<p>安装mysql5.7请参考<a href="https://blanklin030.github.io/2020/05/13/rmp-install-mysql/" target="_blank" rel="noopener">地址</a></p>
<ul>
<li>创建zabbix数据库并且授权给zabbix@123456访问<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create database zabbix character set utf8 collate utf8_bin;</span><br><span class="line">grant all on zabbix.* to zabbix@localhost identified by &#39;123456&#39;;</span><br><span class="line">flush priviledges;</span><br></pre></td></tr></table></figure></li>
<li>导入zabbix数据到mysql<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -uzabbix -p123456 zabbix &lt; database&#x2F;mysql&#x2F;schema.sql</span><br><span class="line">mysql -uzabbix -p123456 zabbix &lt; database&#x2F;mysql&#x2F;images.sql</span><br><span class="line">mysql -uzabbix -p123456 zabbix &lt; database&#x2F;mysql&#x2F;data.sql</span><br></pre></td></tr></table></figure></li>
</ul>
</blockquote>
</li>
<li><p>php7.2安装</p>
<blockquote>
<p>安装php7.2请参考<a href="https://blanklin030.github.io/2020/08/11/php7.2-install/" target="_blank" rel="noopener">地址</a></p>
</blockquote>
</li>
<li><p>nginx安装</p>
<blockquote>
<p>安装nginx请参考<a href="https://blanklin030.github.io/2020/08/11/nginx-install/" target="_blank" rel="noopener">地址</a></p>
</blockquote>
</li>
<li><p>安装zabbix-server</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix  --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2</span><br><span class="line">make&amp;&amp;make install</span><br><span class="line">chown zabbix:zabbix &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F; -R</span><br></pre></td></tr></table></figure></li>
<li>创建软链接,把zabbix命令设置为系统命令<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;sbin&#x2F;zabbix_*  &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;</span><br></pre></td></tr></table></figure></li>
<li><p>配置zabbix启动脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在zabbix源码目录下</span><br><span class="line">cp  misc&#x2F;init.d&#x2F;tru64&#x2F;&#123;zabbix_agentd,zabbix_server&#125;  &#x2F;etc&#x2F;init.d&#x2F;;chmod o+x &#x2F;etc&#x2F;init.d&#x2F;zabbix_*</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置zabbix-web</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在zabbix源码目录下</span><br><span class="line">cp -a  ui&#x2F;* &#x2F;var&#x2F;www&#x2F;html&#x2F;zabbix&#x2F;</span><br><span class="line">chown -R nginx:nginx &#x2F;var&#x2F;www&#x2F;html&#x2F;zabbix</span><br></pre></td></tr></table></figure></li>
<li>配置nginx<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">    listen         	80;</span><br><span class="line">    server_name 	localhost;</span><br><span class="line">    set    $host_path 	&quot;&#x2F;var&#x2F;www&#x2F;html&#x2F;zabbix&quot;;</span><br><span class="line">    root &quot;$host_path&quot;;</span><br><span class="line">    index index.html index.htm index.php;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        fastcgi_pass      127.0.0.1:9000;</span><br><span class="line">        fastcgi_index     index.php;</span><br><span class="line">        fastcgi_param     SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class="line">        include           fastcgi_params;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>配置php</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post_max_size &#x3D; 16M</span><br><span class="line">max_execution_time &#x3D; 300</span><br><span class="line">max_input_time &#x3D; 300</span><br><span class="line">date.timezone &#x3D; Asia&#x2F;Shanghai</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改 zabbix server 配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc</span><br><span class="line">cp zabbix_server.conf zabbix_server.conf.bak</span><br><span class="line"># 修改以下配置</span><br><span class="line">LogFile&#x3D;&#x2F;tmp&#x2F;zabbix_server.log</span><br><span class="line">DBHost&#x3D;localhost</span><br><span class="line">DBName&#x3D;zabbix</span><br><span class="line">DBUser&#x3D;zabbix</span><br><span class="line">DBPassword&#x3D;123456</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启zabbix server和nginx和php-fpm</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;init.d&#x2F;zabbix_server  restart</span><br><span class="line">nginx -s reload</span><br><span class="line">systemctl restart php</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问zabbix web gui进行安装配置<br><img src="/images/zabbix-web-1.png" alt="zabbix-web-1"><br><img src="/images/zabbix-web-2.png" alt="zabbix-web-2"><br><img src="/images/zabbix-web-3.png" alt="zabbix-web-3"></p>
</li>
<li><p>源码部署zabbix agent</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install curl curl-devel net-snmp net-snmp-devel perl-DBI</span><br><span class="line">groupadd zabbix</span><br><span class="line">useradd -g zabbix zabbix</span><br><span class="line">usermod -s &#x2F;sbin&#x2F;nologin zabbix</span><br><span class="line">tar -xzf zabbix-5.0.2.tar.gz</span><br><span class="line">cd zabbix-5.0.2</span><br><span class="line">.&#x2F;configure  --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix  --enable-agent</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li>
<li>创建软链接<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;sbin&#x2F;zabbix_* &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;</span><br></pre></td></tr></table></figure></li>
<li><p>配置启动脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd zabbix-5.0.2</span><br><span class="line">cp  misc&#x2F;init.d&#x2F;tru64&#x2F;zabbix_agentd  &#x2F;etc&#x2F;init.d&#x2F;zabbix_agentd</span><br><span class="line">chmod o+x &#x2F;etc&#x2F;init.d&#x2F;zabbix_agentd</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf</span><br><span class="line">LogFile&#x3D;&#x2F;tmp&#x2F;zabbix_agentd.log</span><br><span class="line">Server&#x3D;192.168.2.214  #server端ip</span><br><span class="line">ServerActive&#x3D;192.168.2.214 #server端ip</span><br><span class="line">Hostname &#x3D; 192.168.2.215  #agent端ip或者是主机名都可以</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动agent</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;init.d&#x2F;zabbix_agentd</span><br></pre></td></tr></table></figure></li>
<li>自动发现agent<br><img src="/images/zabbix-web-5.png" alt="zabbix-web-5"></li>
</ul>
]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>macbook使用code .命令在vscode打开当前目录</title>
    <url>/2020/02/17/vscode-open-project/</url>
    <content><![CDATA[<h3 id="在vscode里使用快捷键如下"><a href="#在vscode里使用快捷键如下" class="headerlink" title="在vscode里使用快捷键如下"></a>在vscode里使用快捷键如下</h3><p>Open the Command Palette via (⇧⌘P)</p>
<h3 id="在弹出框中输入命令如下"><a href="#在弹出框中输入命令如下" class="headerlink" title="在弹出框中输入命令如下"></a>在弹出框中输入命令如下</h3><p>shell command<br><img src="/images/vscode-code-command.png" alt="vscode"></p>
<h3 id="重启vscode"><a href="#重启vscode" class="headerlink" title="重启vscode"></a>重启vscode</h3><blockquote>
<blockquote>
<p>After executing the command, restart the terminal for the new $PATH value to take effect. You’ll be able to simply type ‘code .’ in any folder to start editing files in that folder. The “.” Simply means “current directory”</p>
</blockquote>
</blockquote>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title>怎样使用hexo编写文章</title>
    <url>/2019/10/29/write-article/</url>
    <content><![CDATA[<h2 id="创建-MD-文章"><a href="#创建-MD-文章" class="headerlink" title="创建 MD 文章"></a>创建 MD 文章</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>创建的文章会出现在 source/_posts 文件夹下，是 MarkDown 格式。<br>在文章开头通过如下格式添加必要信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 标题 # 自动创建，如 hello-world</span><br><span class="line">date: 日期 # 自动创建，如 2019-09-22 01:47:21</span><br><span class="line">tags:</span><br><span class="line">- 标签1</span><br><span class="line">- 标签2</span><br><span class="line">- 标签3</span><br><span class="line">categories:</span><br><span class="line">- 分类1</span><br><span class="line">- 分类2</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>这样在下次编译的时候就会自动识别标题、时间、类别等等，另外还有其他的一些参数设置，可以<a href="https://hexo.io/zh-cn/docs/writing.html" target="_blank" rel="noopener">参考文档</a></p>
<h2 id="标签页"><a href="#标签页" class="headerlink" title="标签页"></a>标签页</h2><p>我们的博客只有首页、文章页，如果我们想要增加标签页，可以自行添加，这里 Hexo 也给我们提供了这个功能，在根目录执行命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>
<p>执行这个命令之后会自动帮我们生成一个 source/tags/index.md 文件，内容就只有这样子的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date: 2019-09-26 16:44:17</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>我们可以自行添加一个 type 字段来指定页面的类型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type: tags</span><br><span class="line">comments: false</span><br></pre></td></tr></table></figure>
<p>然后再在主题的 _config.yml 文件将这个页面的链接添加到主菜单里面，修改 menu 字段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: &#x2F; || home</span><br><span class="line">  #about: &#x2F;about&#x2F; || user</span><br><span class="line">  tags: &#x2F;tags&#x2F; || tags</span><br><span class="line">  #categories: &#x2F;categories&#x2F; || th</span><br><span class="line">  archives: &#x2F;archives&#x2F; || archive</span><br><span class="line">  #schedule: &#x2F;schedule&#x2F; || calendar</span><br><span class="line">  #sitemap: &#x2F;sitemap.xml || sitemap</span><br><span class="line">  #commonweal: &#x2F;404&#x2F; || heartbeat</span><br></pre></td></tr></table></figure>
<h2 id="分类页"><a href="#分类页" class="headerlink" title="分类页"></a>分类页</h2><p>分类功能和标签类似，一个文章可以对应某个分类，如果要增加分类页面可以使用如下命令创建：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>
<p>然后同样地，会生成一个 source/categories/index.md 文件。</p>
<p>我们可以自行添加一个 type 字段来指定页面的类型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type: categories</span><br><span class="line">comments: false</span><br></pre></td></tr></table></figure>
<p>然后再在主题的 _config.yml 文件将这个页面的链接添加到主菜单里面，修改 menu 字段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: &#x2F; || home</span><br><span class="line">  #about: &#x2F;about&#x2F; || user</span><br><span class="line">  tags: &#x2F;tags&#x2F; || tags</span><br><span class="line">  categories: &#x2F;categories&#x2F; || th</span><br><span class="line">  archives: &#x2F;archives&#x2F; || archive</span><br><span class="line">  #schedule: &#x2F;schedule&#x2F; || calendar</span><br><span class="line">  #sitemap: &#x2F;sitemap.xml || sitemap</span><br><span class="line">  #commonweal: &#x2F;404&#x2F; || heartbeat</span><br></pre></td></tr></table></figure>
<h2 id="搜索页"><a href="#搜索页" class="headerlink" title="搜索页"></a>搜索页</h2><p>很多情况下我们需要搜索全站的内容，所以一个搜索功能的支持也是很有必要的。</p>
<p>如果要添加搜索的支持，需要先安装一个插件，叫做 hexo-generator-searchdb，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p>然后在项目的 _config.yml 里面添加搜索设置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># Local search</span><br><span class="line"># Dependencies: https:&#x2F;&#x2F;github.com&#x2F;wzpan&#x2F;hexo-generator-search</span><br><span class="line">local_search:</span><br><span class="line">  enable: true</span><br><span class="line">  # If auto, trigger search by changing input.</span><br><span class="line">  # If manual, trigger search by pressing enter key or search button.</span><br><span class="line">  trigger: auto</span><br><span class="line">  # Show top n results per article, show all results by setting to -1</span><br><span class="line">  top_n_per_article: 5</span><br><span class="line">  # Unescape html strings to the readable one.</span><br><span class="line">  unescape: false</span><br><span class="line">  # Preload the search data when the page loads.</span><br><span class="line">  preload: false</span><br></pre></td></tr></table></figure>
<p>这里用的是 Local Search，如果想启用其他是 Search Service 的话可以参考官方文档：<a href="https://theme-next.org/docs/third-party-services/search-services。" target="_blank" rel="noopener">https://theme-next.org/docs/third-party-services/search-services。</a></p>
<h2 id="404-页面"><a href="#404-页面" class="headerlink" title="404 页面"></a>404 页面</h2><p>另外还需要添加一个 404 页面，直接在根目录 source 文件夹新建一个 404.md 文件即可，内容可以仿照如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">---</span><br><span class="line">title: 404 Not Found</span><br><span class="line">date: 2019-09-22 10:41:27</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">&lt;center&gt;</span><br><span class="line">对不起，您所访问的页面不存在或者已删除。</span><br><span class="line">您可以&lt;a href&#x3D;&quot;https:&#x2F;&#x2F;blog.nightteam.cn&gt;&quot;&gt;点击此处&lt;&#x2F;a&gt;返回首页。</span><br><span class="line">&lt;&#x2F;center&gt;</span><br><span class="line"></span><br><span class="line">&lt;blockquote class&#x3D;&quot;blockquote-center&quot;&gt;</span><br><span class="line">    NightTeam</span><br><span class="line">&lt;&#x2F;blockquote&gt;</span><br></pre></td></tr></table></figure>
<p>这里面的一些相关信息和链接可以替换成自己的。</p>
<p>增加了这个 404 页面之后就可以</p>
<p>完成了上面的配置基本就完成了大半了，其实 Hexo 还有很多很多功能，这里就介绍不过来了，大家可以直接参考官方文档：<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/</a> 查看更多的配置。</p>
<h2 id="部署脚本"><a href="#部署脚本" class="headerlink" title="部署脚本"></a>部署脚本</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>HowToWriteMarkDownArticle</tag>
      </tags>
  </entry>
</search>
