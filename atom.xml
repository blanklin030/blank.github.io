<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BlankLin</title>
  
  <subtitle>lazy and boring</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2023-01-04T15:05:15.857Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Blank Lin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常用的linux排查命令</title>
    <link href="http://yoursite.com/2023/01/04/linux%E5%B8%B8%E7%94%A8%E6%8E%92%E6%9F%A5%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2023/01/04/linux%E5%B8%B8%E7%94%A8%E6%8E%92%E6%9F%A5%E5%91%BD%E4%BB%A4/</id>
    <published>2023-01-04T15:04:11.000Z</published>
    <updated>2023-01-04T15:05:15.857Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何看查占用cpu最多的进程？"><a href="#如何看查占用cpu最多的进程？" class="headerlink" title="如何看查占用cpu最多的进程？"></a>如何看查占用cpu最多的进程？</h2><ul><li><p>方法一<br>核心指令：ps<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps H -eo pid,pcpu | sort -nk2 | tail</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[work@test01 ~]$ ps H -eo pid,pcpu | sort -nk2 | tail</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">31396  0.6</span><br><span class="line">30904  1.0</span><br><span class="line">30914  1.0</span><br></pre></td></tr></table></figure><p>结果：<br>瞧见了吧，最耗cpu的pid=30914。<br>画外音：实际上是31396。</p></li><li><p>方法二<br>核心指令：top<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">top</span><br><span class="line">Shift + t</span><br></pre></td></tr></table></figure><h2 id="找到了最耗CPU的进程ID，对应的服务名是什么呢？"><a href="#找到了最耗CPU的进程ID，对应的服务名是什么呢？" class="headerlink" title="找到了最耗CPU的进程ID，对应的服务名是什么呢？"></a>找到了最耗CPU的进程ID，对应的服务名是什么呢？</h2></li><li><p>方法一<br>核心指令：ps<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | fgrep pid</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[work@test01 ~]$ ps aux | fgrep 30914</span><br><span class="line">work 30914  1.0  0.8 309568 71668 ?  Sl   Feb02 124:44 .&#x2F;router2 –conf&#x3D;rs.conf</span><br></pre></td></tr></table></figure><p>结果：<br>瞧见了吧，进程是./router2</p></li><li><p>方法二<br>直接查proc即可。<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll &#x2F;proc&#x2F;pid</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[work@test01 ~]$ ll &#x2F;proc&#x2F;30914</span><br><span class="line">lrwxrwxrwx  1 work work 0 Feb 10 13:27 cwd -&gt; &#x2F;home&#x2F;work&#x2F;im-env&#x2F;router2</span><br><span class="line">lrwxrwxrwx  1 work work 0 Feb 10 13:27 exe -&gt; &#x2F;home&#x2F;work&#x2F;im-env&#x2F;router2&#x2F;router2</span><br></pre></td></tr></table></figure><p>画外音：这个好，全路径都出来了。</p></li></ul><h2 id="如何查看某个端口的连接情况？"><a href="#如何查看某个端口的连接情况？" class="headerlink" title="如何查看某个端口的连接情况？"></a>如何查看某个端口的连接情况？</h2><ul><li><p>方法一<br>核心指令：netstat<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -lap | fgrep port</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[work@test01 ~]$ netstat -lap | fgrep 22022</span><br><span class="line">tcp        0      0 1.2.3.4:22022          *:*                         LISTEN      31396&#x2F;imui</span><br><span class="line">tcp        0      0 1.2.3.4:22022          1.2.3.4:46642          ESTABLISHED 31396&#x2F;imui</span><br><span class="line">tcp        0      0 1.2.3.4:22022          1.2.3.4:46640          ESTABLISHED 31396&#x2F;imui</span><br></pre></td></tr></table></figure></li><li><p>方法二<br>核心指令：lsof<br>实际命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i :port</span><br></pre></td></tr></table></figure><p>执行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[work@test01 ~]$ &#x2F;usr&#x2F;sbin&#x2F;lsof -i :22022</span><br><span class="line">COMMAND   PID USER   FD   TYPE   DEVICE SIZE NODE NAME</span><br><span class="line">router  30904 work   50u  IPv4 69065770       TCP 1.2.3.4:46638-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br><span class="line">router  30904 work   51u  IPv4 69065772       TCP 1.2.3.4:46639-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br><span class="line">router  30904 work   52u  IPv4 69065774       TCP 1.2.3.4:46640-&gt;1.2.3.4:22022 (ESTABLISHED)</span><br></pre></td></tr></table></figure><p>学废了吗？</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何看查占用cpu最多的进程？&quot;&gt;&lt;a href=&quot;#如何看查占用cpu最多的进程？&quot; class=&quot;headerlink&quot; title=&quot;如何看查占用cpu最多的进程？&quot;&gt;&lt;/a&gt;如何看查占用cpu最多的进程？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;方法一&lt;br&gt;核心
      
    
    </summary>
    
    
      <category term="tool" scheme="http://yoursite.com/categories/tool/"/>
    
    
      <category term="sre" scheme="http://yoursite.com/tags/sre/"/>
    
  </entry>
  
  <entry>
    <title>2022年终总结</title>
    <link href="http://yoursite.com/2022/12/30/2022/"/>
    <id>http://yoursite.com/2022/12/30/2022/</id>
    <published>2022-12-30T08:04:11.000Z</published>
    <updated>2022-12-30T07:46:15.037Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>2022年仓皇而逃，在恍惚间我仍然有一丝怀疑，此时此刻是2019年的冬天，我们在准备着即将到来到2020年，订好了机票，订好了酒店，在跨年夜的云层之上，陌生人在沉睡，而我即将见到相隔数月思念日日夜夜的人儿。</p></li><li><p>这种怀疑在这3年间时不时的击碎我，重建我，沉溺我，到最后清醒我，时间过得太快了啊，快到迅雷烈风，快到掩耳而逝，我不是还在17/8岁的高中课堂上汗流浃背准备高考吗？怎么这一眨眼之间，我竟已是前额白发丝丝黑眼圈蜡黄脸的中年人了呢？</p></li><li><p>人世间的痛不知道何时能结束，人世间的离愁不知道何时能消散，虚度30余载光阴，到如今即将到来的第二个本命年，我有何成就吗？我有实现过理想吗？我活着的这些时刻，有给这个世界带来什么美好吗？我不自知只觉惭愧。</p></li><li><p>麻木的躯壳麻木的灵魂，肤浅的知识肤浅的见识，2022年在核酸、隔离、阳性中结束，这浅浅6个字结束了我的又一个365天，我是谁？我在2022年都做了什么事？有什么可以拿说来细说一二吗？有什么不足和遗憾吗？希望2023年可以改变吗？希望改变什么呢？</p></li><li><p>没有答案，我甚至连流水账都写不出来，哦，我这个可笑的中年人。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;2022年仓皇而逃，在恍惚间我仍然有一丝怀疑，此时此刻是2019年的冬天，我们在准备着即将到来到2020年，订好了机票，订好了酒店，在跨年夜的云层之上，陌生人在沉睡，而我即将见到相隔数月思念日日夜夜的人儿。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;这种怀疑在这3
      
    
    </summary>
    
    
      <category term="blank" scheme="http://yoursite.com/categories/blank/"/>
    
    
      <category term="流水记" scheme="http://yoursite.com/tags/%E6%B5%81%E6%B0%B4%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse集群cpu飙高问题排查</title>
    <link href="http://yoursite.com/2022/12/08/clickhouse%E9%9B%86%E7%BE%A4cpu%E9%A3%99%E9%AB%98%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2022/12/08/clickhouse%E9%9B%86%E7%BE%A4cpu%E9%A3%99%E9%AB%98%E9%97%AE%E9%A2%98/</id>
    <published>2022-12-08T11:35:11.000Z</published>
    <updated>2022-12-15T14:00:44.169Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>clickhouse是分布式系统，一条查询sql会经过pipeline处理后通过后台的查询线程池开启多线程查询，而经常会收到cpu飙高告警，则是因为这条sql开启了系统所有的cpu资源（多个线程）进行计算</p><h3 id="告警图"><a href="#告警图" class="headerlink" title="告警图"></a>告警图</h3><p>如下图所示，提示cpu飙高<br><img src="/images/clickhouse/cpu_high/1.png" alt="clickhouse"><br>如下图所示，ganglia上展示了当时的cpu顶着线在跑<br><img src="/images/clickhouse/cpu_high/2.png" alt="clickhouse"></p><h3 id="system-query-log"><a href="#system-query-log" class="headerlink" title="system.query_log"></a>system.query_log</h3><blockquote><p><a href="https://clickhouse.com/docs/en/operations/system-tables/query_log" target="_blank" rel="noopener">地址</a>，该表包含了所有进入到ck的sql语句。<br>该表包含字段如下：</p><ul><li>type (Enum8) — 执行查询时的事件类型. 值:<ul><li>‘QueryStart’ = 1 — 查询成功启动.</li><li>‘QueryFinish’ = 2 — 查询成功完成.</li></ul></li><li>‘ExceptionBeforeStart’ = 3 — 查询执行前有异常.</li><li>‘ExceptionWhileProcessing’ = 4 — 查询执行期间有异常.</li><li>event_date (Date) — 查询开始日期.</li><li>event_time (DateTime) — 查询开始时间.</li><li>event_time_microseconds (DateTime64) — 查询开始时间（毫秒精度）.</li><li>query_start_time (DateTime) — 查询执行的开始时间.</li><li>query_start_time_microseconds (DateTime64) — 查询执行的开始时间（毫秒精度）.</li><li>query_duration_ms (UInt64) — 查询消耗的时间（毫秒）.</li><li>read_rows (UInt64) — 从参与了查询的所有表和表函数读取的总行数. 包括：普通的子查询, IN 和 JOIN的子查询. 对于分布式查询 read_rows 包括在所有副本上读取的行总数。 每个副本发送它的 read_rows 值，并且查询的服务器-发起方汇总所有接收到的和本地的值。 缓存卷不会影响此值。</li><li>read_bytes (UInt64) — 从参与了查询的所有表和表函数读取的总字节数. 包括：普通的子查询, IN 和 JOIN的子查询. 对于分布式查询 read_bytes 包括在所有副本上读取的字节总数。 每个副本发送它的 read_bytes 值，并且查询的服务器-发起方汇总所有接收到的和本地的值。 缓存卷不会影响此值。</li><li>written_rows (UInt64) — 对于 INSERT 查询，为写入的行数。 对于其他查询，值为0。</li><li>written_bytes (UInt64) — 对于 INSERT 查询时，为写入的字节数。 对于其他查询，值为0。</li><li>result_rows (UInt64) — SELECT 查询结果的行数，或INSERT 的行数。</li><li>result_bytes (UInt64) — 存储查询结果的RAM量.</li><li>memory_usage (UInt64) — 查询使用的内存.</li><li>query (String) — 查询语句.</li><li>exception (String) — 异常信息.</li><li>exception_code (Int32) — 异常码.</li><li>stack_trace (String) — Stack Trace. 如果查询成功完成，则为空字符串。</li><li>is_initial_query (UInt8) — 查询类型. 可能的值:<ul><li>1 — 客户端发起的查询.</li><li>0 — 由另一个查询发起的，作为分布式查询的一部分.</li></ul></li><li>user (String) — 发起查询的用户.</li><li>query_id (String) — 查询ID.</li><li>address (IPv6) — 发起查询的客户端IP地址.</li><li>port (UInt16) — 发起查询的客户端端口.</li><li>initial_user (String) — 初始查询的用户名（用于分布式查询执行）.</li><li>initial_query_id (String) — 运行初始查询的ID（用于分布式查询执行）.</li><li>initial_address (IPv6) — 运行父查询的IP地址.</li><li>initial_port (UInt16) — 发起父查询的客户端端口.</li><li>interface (UInt8) — 发起查询的接口. 可能的值:<ul><li>1 — TCP.</li><li>2 — HTTP.</li></ul></li><li>os_user (String) — 运行 clickhouse-client的操作系统用户名.</li><li>client_hostname (String) — 运行clickhouse-client 或其他TCP客户端的机器的主机名。</li><li>client_name (String) — clickhouse-client 或其他TCP客户端的名称。</li><li>client_revision (UInt32) — clickhouse-client 或其他TCP客户端的Revision。</li><li>client_version_major (UInt32) — clickhouse-client 或其他TCP客户端的Major version。</li><li>client_version_minor (UInt32) — clickhouse-client 或其他TCP客户端的Minor version。</li><li>client_version_patch (UInt32) — clickhouse-client 或其他TCP客户端的Patch component。</li><li>http_method (UInt8) — 发起查询的HTTP方法. 可能值:<ul><li>0 — TCP接口的查询.</li><li>1 — GET</li><li>2 — POST</li></ul></li><li>http_user_agent (String) — http请求的客户端参数</li><li>quota_key (String) — 在quotas 配置里设置的“quota key” （见 keyed).</li><li>revision (UInt32) — ClickHouse revision.</li><li>ProfileEvents (Map(String, UInt64))) — 不同指标的计数器 </li><li>Settings (Map(String, String)) — 当前请求里的setting部分参数</li><li>thread_ids (Array(UInt64)) — 参与查询的线程数.</li><li>Settings.Names (Array（String)) — 客户端运行查询时更改的设置的名称。 要启用对设置的日志记录更改，请将log_query_settings参数设置为1。</li><li>Settings.Values (Array（String)) — Settings.Names 列中列出的设置的值。</li></ul></blockquote><h3 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h3><ul><li>查询当前时间内耗cpu最高的sql前10条<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">select initial_user, event_time, query,</span><br><span class="line">read_rows, read_bytes,</span><br><span class="line">written_rows, written_bytes,</span><br><span class="line">result_rows, result_bytes,</span><br><span class="line">memory_usage, length(thread_ids) as thread_count</span><br><span class="line">from system.query_log</span><br><span class="line">WHERE event_time &gt; &#39;2022-10-27 18:30:00&#39; AND event_time &lt; &#39;2022-10-27 18:35:00&#39; </span><br><span class="line">and initial_user&lt;&gt;&#39;default&#39;</span><br><span class="line">order by thread_count desc</span><br><span class="line">limit 10;</span><br></pre></td></tr></table></figure></li><li></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h3&gt;&lt;p&gt;clickhouse是分布式系统，一条查询sql会经过pipeline处理后通过后台的查询线程池开启多线程查询，而经常会收到
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse副本不同步问题排查</title>
    <link href="http://yoursite.com/2022/12/08/clickhouse%E5%89%AF%E6%9C%AC%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2022/12/08/clickhouse%E5%89%AF%E6%9C%AC%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/</id>
    <published>2022-12-08T08:04:11.000Z</published>
    <updated>2022-12-22T09:32:56.127Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>clickhouse的Replicated**MergeTree表是通过zookeeper来完成同一个shard之间的副本数据的同步，因为clickhouse本身不是master/slave的架构，我们通过proxy的方式，设定了同一个shard里某个副本是读/写节点角色，另一个节点是读角色，当用户写入时，proxy会路由到读/写节点去完成写入操作，然后通过zk发起同步任务，把日志进入到system.replcation_queue。<br>今天早上用户和我们反馈说数据查询时每一次结果都不一样，用户查询也是通过连我们的proxy进行读节点的路由，所以用户反馈的结果不一致，其实是第一次路由到读/写节点查询结果是a，第二次路由到读节点，查询结果是b，由于a和b两个副本数据没有同步，导致了查询结果不一致，下面是排查的过程。</p><h3 id="system-replication-queue"><a href="#system-replication-queue" class="headerlink" title="system.replication_queue"></a>system.replication_queue</h3><blockquote><p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/replication_queue/" target="_blank" rel="noopener">官方地址</a>所解释,该表记录了当前的副本任务队列的所有信息，如下图所示，我们看到当前副本同步出现大量异常错误  </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from system.replication_queue where data_files &gt; 0</span><br></pre></td></tr></table></figure><p><img src="/images/clickhouse/replicas_data_diff/1.png" alt="clickhouse"><br>如下图所示，<strong>type</strong>字段可以查看到当前是什么类型的操作导致的，发现是<strong>MUTATE_PART</strong>操作，<strong>last_exception</strong>字段显示当前我们在操作ttl时创建的元数据目录下columns.txt无法打开，这个是已知bug。<br><img src="/images/clickhouse/replicas_data_diff/2.png" alt="clickhouse"></p><h3 id="system-mutations"><a href="#system-mutations" class="headerlink" title="system.mutations"></a>system.mutations</h3><blockquote><p>如<a href="https://clickhouse.com/docs/en/operations/system-tables/mutations" target="_blank" rel="noopener">官方地址</a>，该表包含了所有mutation操作的日志信息，<a href="https://clickhouse.com/docs/en/sql-reference/statements/alter/#mutations" target="_blank" rel="noopener">mutation</a>操作包括修改字段类型/修改表ttl操作/按条件删表的数据/按条件更新表的数据等，这些操作都是异步后台线程去处理，都会去回溯该表的所有parts，需要rewrite每个part的信息并且这个操作还不是原子性的，所以如果某个节点操作失败，可能引发该表无法使用。  </p></blockquote><p>该表包含字段如下：</p><ul><li><p>database (String) — 数据库名称.</p></li><li><p>table (String) — 表名称.</p></li><li><p>data_path (String) — 本地文件的路径.</p></li><li><p>mutation_id (String) — mutation的唯一标识，可通过该标识直接kill mutation.</p></li><li><p>command (String) — mutation命令.</p></li><li><p>create_time (DateTime) —  mutation创建时间.</p></li><li><p>block_numbers (Map) — partition_id：需要进行mutation操作的分区id，number：需要进行mutation的分区对应的block序号.</p></li><li><p>parts_to_do_names (Array) — 即将完成的需要进行mutation的数组.</p></li><li><p>parts_to_do (Int64) — 准备进行mutation操作的part序号.</p></li><li><p>is_done (UInt8) — 该操作是否已完成.</p></li><li><p>latest_failed_part (String) — mutation操作最后失败的part名称.</p></li><li><p>latest_fail_time (DateTime) — 最后失败的时间.</p></li><li><p>latest_fail_reason (String) — 最后失败的原因.</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from system.mutations where latest_failed_part !&#x3D; &#39;&#39;</span><br></pre></td></tr></table></figure><p><img src="/images/clickhouse/replicas_data_diff/3.png" alt="clickhouse"></p><blockquote><p>根据异常错误的<strong>command</strong>字段，我们看到错误是通过<code>MATERIALIZE TTL FAST 16070400</code>引起的，mutation操作在写节点处理完成后，也会通过zookeeper进行副本数据同步</p></blockquote><h3 id="解决副本不同步问题"><a href="#解决副本不同步问题" class="headerlink" title="解决副本不同步问题"></a>解决副本不同步问题</h3><ul><li>终止该失败的mutation<br>具体操作语句可以查看<a href="https://clickhouse.com/docs/zh/sql-reference/statements/kill/#:~:text=KILL%20MUTATION%E2%80%8B&amp;text=Tries%20to%20cancel%20and%20remove,list%20of%20mutations%20to%20stop." target="_blank" rel="noopener">官方文档</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill mutation where database &#x3D; &#39;xx&#39; and table &#x3D; &#39;yy&#39; and mutation_id &#x3D; &#39;zz&#39;;</span><br></pre></td></tr></table></figure></li><li>操作之后，可以通过查询shard里每个副本的count是否一致来判断数据是否已经进行同步<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(dt), dt from xx.yy group by dt;</span><br></pre></td></tr></table></figure></li><li>操作之后，可以通过上面的<code>system.replication_queue</code>表来观察是否开始进行副本数据同步<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from system.replication_queue where type&#x3D;&#39;GET_PART&#39; and database &#x3D; &#39;xx&#39; and table &#x3D; &#39;yy&#39;</span><br></pre></td></tr></table></figure></li><li>如果还没恢复，则去对应出错的副本节点，将本地表删除后重建（出错节点可以从上一步里看出来）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drop table if exists xx.yy</span><br><span class="line">create table xx.yy</span><br></pre></td></tr></table></figure></li><li>此时再查询replication_queue表出错的队列应该已经被清理掉了<br>可以继续操作元数据修改</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h3&gt;&lt;p&gt;clickhouse的Replicated**MergeTree表是通过zookeeper来完成同一个shard之间的副本数
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>starrocks离线构建</title>
    <link href="http://yoursite.com/2022/11/19/starrocks-load/"/>
    <id>http://yoursite.com/2022/11/19/starrocks-load/</id>
    <published>2022-11-19T11:04:11.000Z</published>
    <updated>2023-01-07T15:58:45.654Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li><p>入口文件-&gt;StarRocksFE.java</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.....</span><br><span class="line">feServer.start();</span><br><span class="line">httpServer.start();</span><br><span class="line">qeService.start();</span><br></pre></td></tr></table></figure><p>主要是初始化配置和启动服务，分别是mysql server端口、thrift server端口、http端口</p></li><li><p>mysq服务启动-&gt;QeService.java</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void start() throws IOException &#123;</span><br><span class="line">        if (!mysqlServer.start()) &#123;</span><br><span class="line">            LOG.error(&quot;mysql server start failed&quot;);</span><br><span class="line">            System.exit(-1);</span><br><span class="line">        &#125;</span><br><span class="line">        LOG.info(&quot;QE service start.&quot;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>MysqlServer.java</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; start MySQL protocol service</span><br><span class="line">&#x2F;&#x2F; return true if success, otherwise false</span><br><span class="line">public boolean start() &#123;</span><br><span class="line">    if (scheduler &#x3D;&#x3D; null) &#123;</span><br><span class="line">        LOG.warn(&quot;scheduler is NULL.&quot;);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; open server socket</span><br><span class="line">    try &#123;</span><br><span class="line">        serverChannel &#x3D; ServerSocketChannel.open();</span><br><span class="line">        serverChannel.socket().bind(new InetSocketAddress(&quot;0.0.0.0&quot;, port), 2048);</span><br><span class="line">        serverChannel.configureBlocking(true);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        LOG.warn(&quot;Open MySQL network service failed.&quot;, e);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; start accept thread</span><br><span class="line">    listener &#x3D; ThreadPoolManager.newDaemonCacheThreadPool(1, &quot;MySQL-Protocol-Listener&quot;, true);</span><br><span class="line">    running &#x3D; true;</span><br><span class="line">    listenerFuture &#x3D; listener.submit(new Listener());</span><br><span class="line"></span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Listener 监听线程，实现Runnable接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    while (running &amp;&amp; serverChannel.isOpen()) &#123;</span><br><span class="line">        SocketChannel clientChannel;</span><br><span class="line">        try &#123;</span><br><span class="line">            clientChannel &#x3D; serverChannel.accept();</span><br><span class="line">            if (clientChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F; submit this context to scheduler</span><br><span class="line">            ConnectContext context &#x3D; new ConnectContext(clientChannel);</span><br><span class="line">            &#x2F;&#x2F; Set catalog here.</span><br><span class="line">            context.setCatalog(Catalog.getCurrentCatalog());</span><br><span class="line">            if (!scheduler.submit(context)) &#123;</span><br><span class="line">                LOG.warn(&quot;Submit one connect request failed. Client&#x3D;&quot; + clientChannel.toString());</span><br><span class="line">                &#x2F;&#x2F; clear up context</span><br><span class="line">                context.cleanup();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            &#x2F;&#x2F; ClosedChannelException</span><br><span class="line">            &#x2F;&#x2F; AsynchronousCloseException</span><br><span class="line">            &#x2F;&#x2F; ClosedByInterruptException</span><br><span class="line">            &#x2F;&#x2F; Other IOException, for example &quot;to many open files&quot; ...</span><br><span class="line">            LOG.warn(&quot;Query server encounter exception.&quot;, e);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(100);</span><br><span class="line">            &#125; catch (InterruptedException e1) &#123;</span><br><span class="line">                &#x2F;&#x2F; Do nothing</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            &#x2F;&#x2F; NotYetBoundException</span><br><span class="line">            &#x2F;&#x2F; SecurityException</span><br><span class="line">            LOG.warn(&quot;Query server failed when calling accept.&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line"></span><br><span class="line">+ submit提交连接的上下文给线程池</span><br></pre></td></tr></table></figure><p>// submit one MysqlContext to this scheduler.<br>// return true, if this connection has been successfully submitted, otherwise return false.<br>// Caller should close ConnectContext if return false.<br>public boolean submit(ConnectContext context) {<br>  if (context == null) {</p><pre><code>  return false;</code></pre><p>  }</p><p>  context.setConnectionId(nextConnectionId.getAndAdd(1));<br>  // no necessary for nio.<br>  if (context instanceof NConnectContext) {</p><pre><code>  return true;</code></pre><p>  }<br>  if (executor.submit(new LoopHandler(context)) == null) {</p><pre><code>  LOG.warn(&quot;Submit one thread failed.&quot;);  return false;</code></pre><p>  }<br>  return true;<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoopHandler.java (实现Runnable接口)</span><br></pre></td></tr></table></figure><p>public void run() {<br>  try {</p><pre><code>  // Set thread local info  context.setThreadLocalInfo();  context.setConnectScheduler(ConnectScheduler.this);  // authenticate check failed.  if (!MysqlProto.negotiate(context)) {      return;  }  if (registerConnection(context)) {      MysqlProto.sendResponsePacket(context);  } else {      context.getState().setError(&quot;Reach limit of connections&quot;);      MysqlProto.sendResponsePacket(context);      return;  }  context.setStartTime();  ConnectProcessor processor = new ConnectProcessor(context);  processor.loop();</code></pre><p>  } catch (Exception e) {</p><pre><code>  // for unauthrorized access such lvs probe request, may cause exception, just log it in debug level  if (context.getCurrentUserIdentity() != null) {      LOG.warn(&quot;connect processor exception because &quot;, e);  } else {      LOG.debug(&quot;connect processor exception because &quot;, e);  }</code></pre><p>  } finally {</p><pre><code>  unregisterConnection(context);  context.cleanup();</code></pre><p>  }<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; loop</span><br></pre></td></tr></table></figure><p>public void loop() {<br>  while (!ctx.isKilled()) {</p><pre><code>  try {      processOnce();  } catch (Exception e) {      // TODO(zhaochun): something wrong      LOG.warn(&quot;Exception happened in one seesion(&quot; + ctx + &quot;).&quot;, e);      ctx.setKilled();      break;  }</code></pre><p>  }<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; processOnce</span><br></pre></td></tr></table></figure><p>// handle one process<br>public void processOnce() throws IOException {<br>  // set status of query to OK.<br>  ctx.getState().reset();<br>  executor = null;</p><p>  // reset sequence id of MySQL protocol<br>  final MysqlChannel channel = ctx.getMysqlChannel();<br>  channel.setSequenceId(0);<br>  // read packet from channel<br>  try {</p><pre><code>  packetBuf = channel.fetchOnePacket();  if (packetBuf == null) {      throw new IOException(&quot;Error happened when receiving packet.&quot;);  }</code></pre><p>  } catch (AsynchronousCloseException e) {</p><pre><code>  // when this happened, timeout checker close this channel  // killed flag in ctx has been already set, just return  return;</code></pre><p>  }</p><p>  // dispatch<br>  dispatch();<br>  // finalize<br>  finalizeCommand();</p><p>  ctx.setCommand(MysqlCommand.COM_SLEEP);<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; dispatch</span><br></pre></td></tr></table></figure><p>int code = packetBuf.get();<br>MysqlCommand command = MysqlCommand.fromCode(code);<br>….<br>ctx.setCommand(command);<br>….</p></li></ul><p>switch (command) {<br>    case COM_INIT_DB:<br>        handleInitDb();<br>        break;<br>    case COM_QUIT:<br>        handleQuit();<br>        break;<br>    case COM_QUERY:<br>        handleQuery();<br>        ctx.setStartTime();<br>        break;<br>    case COM_FIELD_LIST:<br>        handleFieldList();<br>        break;<br>    case COM_CHANGE_USER:<br>        handleChangeUser();<br>        break;<br>    case COM_RESET_CONNECTION:<br>        handleResetConnnection();<br>        break;<br>    case COM_PING:<br>        handlePing();<br>        break;<br>    default:<br>        ctx.getState().setError(“Unsupported command(“ + command + “)”);<br>        LOG.warn(“Unsupported command(“ + command + “)”);<br>        break;<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; handleQuery</span><br></pre></td></tr></table></figure><br>….<br>List<StatementBase> stmts = analyze(originStmt);<br>for (int i = 0; i &lt; stmts.size(); ++i) {<br>    ctx.getState().reset();<br>    if (i &gt; 0) {<br>        ctx.resetRetureRows();<br>        ctx.setQueryId(UUIDUtil.genUUID());<br>    }<br>    parsedStmt = stmts.get(i);<br>    parsedStmt.setOrigStmt(new OriginStatement(originStmt, i));</p><pre><code>executor = new StmtExecutor(ctx, parsedStmt);ctx.setExecutor(executor);ctx.setIsLastStmt(i == stmts.size() - 1);executor.execute();// do not execute following stmt when current stmt failed, this is consistent with mysql serverif (ctx.getState().getStateType() == QueryState.MysqlStateType.ERR) {    break;}if (i != stmts.size() - 1) {    // NOTE: set serverStatus after executor.execute(),    //      because when execute() throws exception, the following stmt will not execute    //      and the serverStatus with MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS will    //      cause client error: Packet sequence number wrong    ctx.getState().serverStatus |= MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS;    finalizeCommand();}</code></pre><p>}<br>….</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; analyze</span><br></pre></td></tr></table></figure><p>// analyze the origin stmt and return multi-statements<br>private List<StatementBase> analyze(String originStmt) throws AnalysisException {<br>    LOG.debug(“the originStmts are: {}”, originStmt);<br>    // Parse statement with parser generated by CUP&amp;FLEX<br>    SqlScanner input = new SqlScanner(new StringReader(originStmt), ctx.getSessionVariable().getSqlMode());<br>    SqlParser parser = new SqlParser(input);<br>    try {<br>        return SqlParserUtils.getMultiStmts(parser);<br>    } catch (Error e) {<br>        throw new AnalysisException(“Please check your sql, we meet an error when parsing.”, e);<br>    } catch (AnalysisException e) {<br>        LOG.warn(“origin_stmt: “ + originStmt + “; Analyze error message: “ + parser.getErrorMsg(originStmt), e);<br>        String errorMessage = parser.getErrorMsg(originStmt);<br>        if (errorMessage == null) {<br>            throw e;<br>        } else {<br>            throw new AnalysisException(errorMessage, e);<br>        }<br>    } catch (Exception e) {<br>        // TODO(lingbin): we catch ‘Exception’ to prevent unexpected error,<br>        // should be removed this try-catch clause future.<br>        LOG.warn(“origin_stmt: “ + originStmt + “; exception: “, e);<br>        String errorMessage = e.getMessage();<br>        if (errorMessage == null) {<br>            throw new AnalysisException(“Internal Error”);<br>        } else {<br>            throw new AnalysisException(“Internal Error: “ + errorMessage);<br>        }<br>    }<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>} else if (parsedStmt instanceof DdlStmt) {<br>    handleDdlStmt();<br>}<br>……<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; handleDdlStmt</span><br></pre></td></tr></table></figure><br>private void handleDdlStmt() {<br>  try {<br>      DdlExecutor.execute(context.getCatalog(), (DdlStmt) parsedStmt);<br>      context.getState().setOk();<br>  } catch (QueryStateException e) {<br>      if (e.getQueryState().getStateType() != MysqlStateType.OK) {<br>          LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      }<br>      context.setState(e.getQueryState());<br>  } catch (UserException e) {<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      // Return message to info client what happened.<br>      context.getState().setError(e.getMessage());<br>  } catch (Exception e) {<br>      // Maybe our bug<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      context.getState().setError(“Unexpected exception: “ + e.getMessage());<br>  }<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ DdlExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>else if (ddlStmt instanceof LoadStmt) {<br>    LoadStmt loadStmt = (LoadStmt) ddlStmt;<br>    EtlJobType jobType = loadStmt.getEtlJobType();<br>    if (jobType == EtlJobType.UNKNOWN) {<br>        throw new DdlException(“Unknown load job type”);<br>    }<br>    if (jobType == EtlJobType.HADOOP &amp;&amp; Config.disable_hadoop_load) {<br>        throw new DdlException(“Load job by hadoop cluster is disabled.”</p><pre><code>            + &quot; Try using broker load. See &#39;help broker load;&#39;&quot;);}catalog.getLoadManager().createLoadJobFromStmt(loadStmt);</code></pre><p>}<br>……..<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadManager.java -&gt; createLoadJobFromStmt</span><br></pre></td></tr></table></figure><br>public void createLoadJobFromStmt(LoadStmt stmt) throws DdlException {<br>  Database database = checkDb(stmt.getLabel().getDbName());<br>  long dbId = database.getId();<br>  LoadJob loadJob = null;<br>  writeLock();<br>  try {<br>      checkLabelUsed(dbId, stmt.getLabel().getLabelName());<br>      if (stmt.getBrokerDesc() == null &amp;&amp; stmt.getResourceDesc() == null) {<br>          throw new DdlException(“LoadManager only support the broker and spark load.”);<br>      }<br>      if (loadJobScheduler.isQueueFull()) {<br>          throw new DdlException(<br>                  “There are more than “ + Config.desired_max_waiting_jobs + “ load jobs in waiting queue, “</p><pre><code>                      + &quot;please retry later.&quot;);  }  loadJob = BulkLoadJob.fromLoadStmt(stmt);  createLoadJob(loadJob);</code></pre><p>  } finally {<br>      writeUnlock();<br>  }<br>  Catalog.getCurrentCatalog().getEditLog().logCreateLoadJob(loadJob);</p><p>  // The job must be submitted after edit log.<br>  // It guarantee that load job has not been changed before edit log.<br>  loadJobScheduler.submitJob(loadJob);<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">通过 &#96;createLoadJobFromStmt&#96; 创建load任务</span><br><span class="line">+ LoadJobScheduler.java -&gt; process</span><br><span class="line">注意：LoadJobScheduler 继承自 MasterDaemon，MasterDaemon 继承自 Daemon，</span><br><span class="line">Daemon继承自Thread，重载了run方法，里面有一个loop，主要执行runOneCycle</span><br><span class="line">MasterDaemon 又重写了 runOneCycle，执行 runAfterCatalogReady 函数</span><br><span class="line">LoadJobScheduler 又重写了 runAfterCatalogReady 主要就是干process处理，里面是一个死循环，不断从LinkedBlockingQueue类型的needScheduleJobs里出栈取要珍惜的job</span><br></pre></td></tr></table></figure><br>while (true) {<br>  // take one load job from queue<br>  LoadJob loadJob = needScheduleJobs.poll();<br>  if (loadJob == null) {<br>      return;<br>  }</p><p>  // schedule job<br>  try {<br>      loadJob.execute();<br>  }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadJob.java -&gt; execute</span><br></pre></td></tr></table></figure><br>/**</p><ul><li>create pending task for load job and add pending task into pool</li><li>if job has been cancelled, this step will be ignored<br>*</li><li>@throws LabelAlreadyUsedException  the job is duplicated</li><li>@throws BeginTransactionException  the limit of load job is exceeded</li><li>@throws AnalysisException          there are error params in job</li><li><p>@throws DuplicatedRequestException<br>*/<br>public void execute() throws LabelAlreadyUsedException, BeginTransactionException, AnalysisException,</p><pre><code>DuplicatedRequestException, LoadException {</code></pre><p>writeLock();<br>try {</p><pre><code>unprotectedExecute();</code></pre><p>} finally {</p><pre><code>writeUnlock();</code></pre><p>}<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; unprotectedExecuteJob</span><br></pre></td></tr></table></figure><p>protected void unprotectedExecuteJob() throws LoadException {<br>// create pending task<br>LoadTask task = new SparkLoadPendingTask(this, fileGroupAggInfo.getAggKeyToFileGroups(),</p><pre><code>    sparkResource, brokerDesc);</code></pre><p>task.init();<br>idToTasks.put(task.getSignature(), task);<br>submitTask(Catalog.getCurrentCatalog().getPendingLoadTaskScheduler(), task);<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; init</span><br></pre></td></tr></table></figure><p>public void init() throws LoadException {<br>createEtlJobConf();<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadTask -&gt; exec</span><br></pre></td></tr></table></figure><p>@Override<br>protected void exec() {<br>boolean isFinished = false;<br>try {</p><pre><code>// execute pending taskexecuteTask();// callback on pending task finishedcallback.onTaskFinished(attachment);isFinished = true;</code></pre><p>} catch (UserException e) {</p><pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())        .add(&quot;error_msg&quot;, &quot;Failed to execute load task&quot;).build(), e);</code></pre><p>} catch (Exception e) {</p><pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())        .add(&quot;error_msg&quot;, &quot;Unexpected failed to execute load task&quot;).build(), e);</code></pre><p>} finally {</p><pre><code>if (!isFinished) {    // callback on pending task failed    callback.onTaskFailed(signature, failMsg);}</code></pre><p>}<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; executeTask</span><br></pre></td></tr></table></figure><p>void executeTask() throws LoadException {<br>LOG.info(“begin to execute spark pending task. load job id: {}”, loadJobId);<br>submitEtlJob();<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure><p>private void submitEtlJob() throws LoadException {<br>SparkPendingTaskAttachment sparkAttachment = (SparkPendingTaskAttachment) attachment;<br>// retry different output path<br>etlJobConfig.outputPath = EtlJobConfig.getOutputPath(resource.getWorkingDir(), dbId, loadLabel, signature);<br>sparkAttachment.setOutputPath(etlJobConfig.outputPath);</p><p>// handler submit etl job<br>SparkEtlJobHandler handler = new SparkEtlJobHandler();<br>handler.submitEtlJob(loadJobId, loadLabel, etlJobConfig, resource, brokerDesc, sparkLoadAppHandle,</p><pre><code>    sparkAttachment);</code></pre><p>LOG.info(“submit spark etl job success. load job id: {}, attachment: {}”, loadJobId, sparkAttachment);<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkEtlJobHandler.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure><p>public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobConfig, SparkResource resource,</p><pre><code>                     BrokerDesc brokerDesc, SparkLoadAppHandle handle, SparkPendingTaskAttachment attachment)</code></pre><p>  throws LoadException {<br>// delete outputPath<br>// init local dir<br>// prepare dpp archive<br>SparkLauncher launcher = new SparkLauncher(envs);<br>// master      |  deployMode<br>// ——————|——————-<br>// yarn        |  cluster<br>// spark://xx  |  client<br>launcher.setMaster(resource.getMaster())</p><pre><code>  .setDeployMode(resource.getDeployMode().name().toLowerCase())  .setAppResource(appResourceHdfsPath)  .setMainClass(SparkEtlJob.class.getCanonicalName())  .setAppName(String.format(ETL_JOB_NAME, loadLabel))  .setSparkHome(sparkHome)  .addAppArgs(jobConfigHdfsPath)  .redirectError();</code></pre><p>// spark configs</p><p>// start app<br>State state = null;<br>String appId = null;<br>String logPath = null;<br>String errMsg = “start spark app failed. error: “;<br>try {<br>  Process process = launcher.launch();<br>  handle.setProcess(process);<br>  if (!FeConstants.runningUnitTest) {</p><pre><code>  SparkLauncherMonitor.LogMonitor logMonitor = SparkLauncherMonitor.createLogMonitor(handle);  logMonitor.setSubmitTimeoutMs(GET_APPID_TIMEOUT_MS);  logMonitor.setRedirectLogPath(logFilePath);  logMonitor.start();  try {      logMonitor.join();  } catch (InterruptedException e) {      logMonitor.interrupt();      throw new LoadException(errMsg + e.getMessage());  }</code></pre><p>  }<br>  appId = handle.getAppId();<br>  state = handle.getState();<br>  logPath = handle.getLogPath();<br>} catch (IOException e) {<br>  LOG.warn(errMsg, e);<br>  throw new LoadException(errMsg + e.getMessage());<br>}<br>……….<br>// success<br>attachment.setAppId(appId);<br>attachment.setHandle(handle);<br>}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; onTaskFinished</span><br></pre></td></tr></table></figure><p>public void onTaskFinished(TaskAttachment attachment) {<br>if (attachment instanceof SparkPendingTaskAttachment) {</p><pre><code>onPendingTaskFinished((SparkPendingTaskAttachment) attachment);</code></pre><p>}<br>}</p></li></ul><p>private void onPendingTaskFinished(SparkPendingTaskAttachment attachment) {<br>    writeLock();<br>    try {<br>        // check if job has been cancelled<br>        if (isTxnDone()) {<br>            LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)<br>                    .add(“state”, state)<br>                    .add(“error_msg”, “this task will be ignored when job is: “ + state)<br>                    .build());<br>            return;<br>        }</p><pre><code>    if (finishedTaskIds.contains(attachment.getTaskId())) {        LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)                .add(&quot;task_id&quot;, attachment.getTaskId())                .add(&quot;error_msg&quot;, &quot;this is a duplicated callback of pending task &quot;                        + &quot;when broker already has loading task&quot;)                .build());        return;    }    // add task id into finishedTaskIds    finishedTaskIds.add(attachment.getTaskId());    sparkLoadAppHandle = attachment.getHandle();    appId = attachment.getAppId();    etlOutputPath = attachment.getOutputPath();    executeEtl();    // log etl state    unprotectedLogUpdateStateInfo();} finally {    writeUnlock();}</code></pre><p>}</p><p>```</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;入口文件-&amp;gt;StarRocksFE.java&lt;/p&gt;
&lt;figure class=&quot;highligh
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="cpp" scheme="http://yoursite.com/tags/cpp/"/>
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse解析器大揭秘</title>
    <link href="http://yoursite.com/2022/11/04/clickhouse-parser/"/>
    <id>http://yoursite.com/2022/11/04/clickhouse-parser/</id>
    <published>2022-11-04T06:09:55.000Z</published>
    <updated>2022-11-04T09:01:49.663Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>我们知道语法分析器的作用是根据给定的<a href="https://baike.baidu.com/item/%E5%BD%A2%E5%BC%8F%E6%96%87%E6%B3%95/2447403" target="_blank" rel="noopener">形式文法</a>对由词法单元（Token）序列构成的输入进行语法检查、并构建由输入的词法单元（Token）组成的数据结构（一般是<a href="https://baike.baidu.com/item/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E6%A0%91/20452541" target="_blank" rel="noopener">语法分析树</a>、<a href="https://baike.baidu.com/item/%E6%8A%BD%E8%B1%A1%E8%AF%AD%E6%B3%95%E6%A0%91/6129952" target="_blank" rel="noopener">抽象语法树</a>等层次化的数据结构）。而一提到语法解析目前市面上有很多语法解析器，其中解析sql更是数不胜数，例如最为人所知的antlr和jflex，而本文的主人公ClickHouse却自己去纯手工打造实现了一套sql解析器，本篇文章就来聊聊 ClickHouse 的纯手工解析器，看看它们的底层工作机制。</p><h2 id="简单入门"><a href="#简单入门" class="headerlink" title="简单入门"></a>简单入门</h2><blockquote><p>首先来简单入门解决个小问题，那就是我们如何去连接ck，如何将query传递ck呢，如何设置传递给ck的query长度呢？   </p></blockquote><h3 id="通过TCP方式请求"><a href="#通过TCP方式请求" class="headerlink" title="通过TCP方式请求"></a>通过TCP方式请求</h3><blockquote><p>通过tcp方式使用clickhouse自己的客户端，连接clickhouse，在会话session里先使用<strong>set max_query_size=xx</strong>的方式让当前这个会话修改query的长度，如下图：  </p></blockquote><p><img src="/images/clickhouse/maxquerysize/1.png" alt="clickhouse"></p><h3 id="通过HTTP方式请求"><a href="#通过HTTP方式请求" class="headerlink" title="通过HTTP方式请求"></a>通过HTTP方式请求</h3><blockquote><p>通过http方式请求，<a href="http://ip:port/database?user=xx&amp;password=yy&amp;max_query_size=xx，ck会传递这个参数给setting重写">http://ip:port/database?user=xx&amp;password=yy&amp;max_query_size=xx，ck会传递这个参数给setting重写</a><br>注意chproxy只允许最大max_query_size为512mb，超过此长度会直接报错  </p></blockquote><h3 id="通过sql创建setting授权给登陆用户"><a href="#通过sql创建setting授权给登陆用户" class="headerlink" title="通过sql创建setting授权给登陆用户"></a>通过sql创建setting授权给登陆用户</h3><ol><li>创建setting profile<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create settings profile if not exists role_max_query_size SETTINGS max_query_size &#x3D; 100000000000;</span><br></pre></td></tr></table></figure></li><li>将profile赋值给某个用户<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant role_max_query_size to prod_voyager_stats_events;</span><br></pre></td></tr></table></figure></li></ol><h3 id="源码解析ck是如何处理max-query-size的"><a href="#源码解析ck是如何处理max-query-size的" class="headerlink" title="源码解析ck是如何处理max_query_size的"></a>源码解析ck是如何处理max_query_size的</h3><blockquote><p>由于源码较多，只抽出具体实现函数进行源码讲解，本次讲解基于clickhouse v20.6.3.28-stable（该版本与最新版出入较大）。  </p></blockquote><p><img src="/images/clickhouse/maxquerysize/2.png" alt="clickhouse"></p><ol><li>如上图所示，在<code>HTTPHandler.cpp</code>下进行各种http的协议处理时，有一个变量叫<strong>HTMLForm</strong>类型的<code>params</code>，承载的是http请求里的<code>uri</code>，并且在代码的484行进行了此变量的处理，如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">for (const auto &amp; [key, value] : params)</span><br><span class="line">&#123;</span><br><span class="line">    if (key &#x3D;&#x3D; &quot;database&quot;)</span><br><span class="line">    &#123;</span><br><span class="line">        if (database.empty())</span><br><span class="line">            database &#x3D; value;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (key &#x3D;&#x3D; &quot;default_format&quot;)</span><br><span class="line">    &#123;</span><br><span class="line">        if (default_format.empty())</span><br><span class="line">            default_format &#x3D; value;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (param_could_be_skipped(key))</span><br><span class="line">    &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        &#x2F;&#x2F;&#x2F; Other than query parameters are treated as settings.</span><br><span class="line">        if (!customizeQueryParam(context, key, value))</span><br><span class="line">            settings_changes.push_back(&#123;key, value&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>而<code>customizeQueryParam</code>会判断该参数param是否等于query，如果是则不会进入setting的设置，再判断是否是param_开头的如果是则会传入context（理解为这次session会话中需要设置的各种上下文内容）则也不会进行setting处理，不是前面2个case则进行setting处理，重载系统默认的setting里的参数，如下图<br><img src="/images/clickhouse/maxquerysize/3.png" alt="clickhouse"></li><li>虽然第二步已经设置了setting，但注意代码的512行，这行代码会走向<strong>SettingsConstraints.cpp</strong>类的<strong>checkImpl</strong>校验逻辑里，有一些配置是不允许修改的，例如<strong>profile</strong>，例如配置就是如果已经通过grant授权配置了<strong>setting profile</strong>了，会去看这个用户的相关权限，如果不符合则会直接抛出exception，不再进行处理，注意这里还有一个问题，抛了异常后，不再将此次请求写入到system.query_log中，之后我们会修复此问题<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;&#x2F; For external data we also want settings</span><br><span class="line">context.checkSettingsConstraints(settings_changes);</span><br><span class="line">context.applySettingsChanges(settings_changes);</span><br></pre></td></tr></table></figure></li><li>做完setting的约束校验后，都符合条件，则我们已经重载了setting里的<strong>max_query_size</strong>，之后就走入了<strong>executeQuery.cpp</strong>执行query逻辑，在它的构造函数里我们就可以看到query是根据<strong>max_query_size</strong>来读取的，如下图<br><img src="/images/clickhouse/maxquerysize/4.png" alt="clickhouse"></li></ol><h2 id="深入探知"><a href="#深入探知" class="headerlink" title="深入探知"></a>深入探知</h2><p>介绍完了<strong>max_query_size</strong>的处理逻辑后，其实我们已经大致明白ck在query的处理流程是如何流转的，那么现在问题来了，我们知道可以通过<code>select xx from tb SETTINGS max_query_size=12112</code>这种方式传入自定义的setting参数，但是有些参数有生效，而select语法却对max_query_size不生效，原因是什么呢？好了，别着急现在我们就来解答ck是如何处理setting这层逻辑的。</p><h3 id="为什么max-query-size的select中不生效？"><a href="#为什么max-query-size的select中不生效？" class="headerlink" title="为什么max_query_size的select中不生效？"></a>为什么max_query_size的select中不生效？</h3><p><img src="/images/clickhouse/maxquerysize/5.png" alt="clickhouse"><br>原因很简单，只要我们读过了上面的流转过程，就知道max_query_size这个参数的处理系统默认是256kb，那么如果未通过uri方式传入<strong>max_query_size</strong>，则在截取query长度前，默认都是256kb，注意截取query时是还未进行ck的parser逻辑处理的，我们可以看到query里的setting是需要经过ck的parser解析后，才会重载进去(如下图6)，所以呢如果你的select query在256kb范围内，则截取完整query后，经过ck的parser解析出ast树，是会带上新的setting，但此时已经没有意义了，而相反的如果你的query超过了256kb，则只截取到256kb前的query，此时setting也不会走到<strong>ParserSelectQuery</strong>里，同时因为你的query被不完整截取后，会直接报ast语法错误<br><img src="/images/clickhouse/maxquerysize/6.png" alt="图6"></p><h2 id="源码看解析器"><a href="#源码看解析器" class="headerlink" title="源码看解析器"></a>源码看解析器</h2><h3 id="1-HTTPHandler-cpp-gt-processQuery"><a href="#1-HTTPHandler-cpp-gt-processQuery" class="headerlink" title="1. HTTPHandler.cpp =&gt; processQuery"></a>1. HTTPHandler.cpp =&gt; processQuery</h3><blockquote><p>每一个http请求都在clickhouse都会起一个叫<strong>HTTPHandler</strong>的线程去处理，根据http请求header和body，初始化请求上下文环境：包括session、用户信息、当前database、响应信息等，另外还处理限流，用户权限，根据配置取到setting信息进行设置，本文重点是调用<code>executeQuery</code>方法处理<code>query</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">executeQuery(*in, *used_output.out_maybe_delayed_and_compressed, &#x2F;* allow_into_outfile &#x3D; *&#x2F; false, context,</span><br><span class="line">        [&amp;response] (const String &amp; current_query_id, const String &amp; content_type, const String &amp; format, const String &amp; timezone)</span><br><span class="line">        &#123;</span><br><span class="line">            response.setContentType(content_type);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Query-Id&quot;, current_query_id);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Format&quot;, format);</span><br><span class="line">            response.add(&quot;X-ClickHouse-Timezone&quot;, timezone);</span><br><span class="line">        &#125;</span><br><span class="line">    );</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="2-executeQuery-cpp-gt-executeQuery"><a href="#2-executeQuery-cpp-gt-executeQuery" class="headerlink" title="2. executeQuery.cpp =&gt; executeQuery"></a>2. executeQuery.cpp =&gt; executeQuery</h3><p>从流中读出字节到buffer里，根据设置的<code>max_query_size</code>判断buffer是否已满，复制到LimitReadBuffer里，重点是执行<strong>executeQueryImpl</strong>，返回tuple类型的(ast, stream)，从stream里提取出<strong>pipeline(流水线)</strong>，根据ast构造出<code>IBlockInputStream</code>或者<code>IBlockOutputStream</code>，传给pipeline后执行pipeline的execute方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::tie(ast, streams) &#x3D; executeQueryImpl(begin, end, context, false, QueryProcessingStage::Complete, may_have_tail, &amp;istr);</span><br></pre></td></tr></table></figure></p><h3 id="2-executeQuery-cpp-gt-executeQueryImpl"><a href="#2-executeQuery-cpp-gt-executeQueryImpl" class="headerlink" title="2. executeQuery.cpp =&gt; executeQueryImpl"></a>2. executeQuery.cpp =&gt; executeQueryImpl</h3><p>按照解析出的ast，构造出Interpreter，调用Interpreter的exec方法去执行后返回pipeline，执行结果记录到query_log里，最后把构造出对应的ast和pipeline返回<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 这里是实现了ParserQuery对象，继承了IParserBase，IParserBase继承自IParser，等下走到6时，才知道虚函数parseImpl会通过ParserQuery对象实现</span><br><span class="line">ParserQuery parser(end, settings.enable_debug_queries);</span><br><span class="line">.........</span><br><span class="line">ast &#x3D; parseQuery(parser, begin, end, &quot;&quot;, max_query_size, settings.max_parser_depth);</span><br><span class="line">.........</span><br><span class="line">auto interpreter &#x3D; InterpreterFactory::get(ast, context, stage);</span><br><span class="line">.........</span><br><span class="line">res &#x3D; interpreter-&gt;execute();</span><br><span class="line">QueryPipeline &amp; pipeline &#x3D; res.pipeline;</span><br><span class="line">.........</span><br><span class="line">return std::make_tuple(ast, std::move(res));</span><br></pre></td></tr></table></figure></p><h3 id="3-parseQuery-cpp-gt-parseQueryAndMovePosition"><a href="#3-parseQuery-cpp-gt-parseQueryAndMovePosition" class="headerlink" title="3. parseQuery.cpp =&gt; parseQueryAndMovePosition"></a>3. parseQuery.cpp =&gt; parseQueryAndMovePosition</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ASTPtr res &#x3D; tryParseQuery(parser, pos, end, error_message, false, query_description, allow_multi_statements, max_query_size, max_parser_depth);</span><br></pre></td></tr></table></figure><h3 id="4-parseQuery-cpp-gt-tryParseQuery"><a href="#4-parseQuery-cpp-gt-tryParseQuery" class="headerlink" title="4. parseQuery.cpp =&gt; tryParseQuery"></a>4. parseQuery.cpp =&gt; tryParseQuery</h3><blockquote><p>尝试解析SQL，将sql通过语法树规则装入TokenIterator，返回ASTPtr  </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; ClickHouse词法分析器是由Tokens和Lexer类来实现，token是最基础的元祖，之间是没有任何关联的，只是一堆词组和符号，通过lexer语法进行解析后，把元祖里的token建立起关系。</span><br><span class="line">Tokens tokens(pos, end, max_query_size);</span><br><span class="line">IParser::Pos token_iterator(tokens, max_parser_depth);</span><br><span class="line">&#x2F;&#x2F; 注意这里，TokenIterator对-&gt;使用了重载，在重载函数里去初始化TOKEN，主要是从第一个字符开始使用pos++的方式进行判断，可以进入Token Lexer::nextTokenImpl()进行查看</span><br><span class="line">if (token_iterator-&gt;isEnd() || token_iterator-&gt;type &#x3D;&#x3D; TokenType::Semicolon) &#123;</span><br><span class="line">    out_error_message &#x3D; &quot;Empty query&quot;;</span><br><span class="line">    pos &#x3D; token_iterator-&gt;begin;</span><br><span class="line">    return nullptr;</span><br><span class="line">&#125;</span><br><span class="line">.....</span><br><span class="line">Expected expected;</span><br><span class="line">......</span><br><span class="line">ASTPtr res;</span><br><span class="line">bool parse_res &#x3D; parser.parse(token_iterator, res, expected);</span><br></pre></td></tr></table></figure><blockquote><p>注意：<code>IParser</code>的<code>parse</code>方法是<code>virtual</code>虚函数，<code>IParser</code>作为接口角色，被<code>IParserBase</code>继承，在<code>IParserBase</code>里实现了<code>parse</code>方法。</p></blockquote><h3 id="5-IParserBase-cpp-gt-parse"><a href="#5-IParserBase-cpp-gt-parse" class="headerlink" title="5. IParserBase.cpp =&gt; parse"></a>5. IParserBase.cpp =&gt; parse</h3><blockquote><p>在解每个token时都会根据当前的token进行预判（parseImpl返回的结果），返回true才会进入下一个子token  </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">bool IParserBase::parse(Pos &amp; pos, ASTPtr &amp; node, Expected &amp; expected)</span><br><span class="line">&#123;</span><br><span class="line">    expected.add(pos, getName());</span><br><span class="line"></span><br><span class="line">    return wrapParseImpl(pos, IncreaseDepthTag&#123;&#125;, [&amp;]</span><br><span class="line">    &#123;</span><br><span class="line">        bool res &#x3D; parseImpl(pos, node, expected);</span><br><span class="line">        if (!res)</span><br><span class="line">            node &#x3D; nullptr;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意到parseImpl在IParserBase中是一个虚函数，将被继承自IParserBase类的子类实现，而在 <strong><em> 第2步 </em></strong>中我们定义的子类是ParserQuery，所以此时是直接调用到ParserQuery子类的parseImpl方法</p></blockquote><h3 id="6-ParserQuery-cpp-gt-parseImpl"><a href="#6-ParserQuery-cpp-gt-parseImpl" class="headerlink" title="6. ParserQuery.cpp =&gt; parseImpl"></a>6. ParserQuery.cpp =&gt; parseImpl</h3><blockquote><p>Parser的主要类（也都是继承自IParserBase）分别定义出来后，每个去尝试解析，如果都不在这几个主要Parser里，则返回false，否则返回true，clickhouse把query分类成以下14类，但本质上可以归纳为2类，第一类是有结果输出可对应show/select/desc/create等，第二类是无结果输出可对应insert/use/set等  </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">bool ParserQuery::parseImpl(Pos &amp; pos, ASTPtr &amp; node, Expected &amp; expected)</span><br><span class="line">&#123;</span><br><span class="line">    ParserQueryWithOutput query_with_output_p(enable_explain);</span><br><span class="line">    ParserInsertQuery insert_p(end);</span><br><span class="line">    ParserUseQuery use_p;</span><br><span class="line">    ParserSetQuery set_p;</span><br><span class="line">    ParserSystemQuery system_p;</span><br><span class="line">    ParserCreateUserQuery create_user_p;</span><br><span class="line">    ParserCreateRoleQuery create_role_p;</span><br><span class="line">    ParserCreateQuotaQuery create_quota_p;</span><br><span class="line">    ParserCreateRowPolicyQuery create_row_policy_p;</span><br><span class="line">    ParserCreateSettingsProfileQuery create_settings_profile_p;</span><br><span class="line">    ParserDropAccessEntityQuery drop_access_entity_p;</span><br><span class="line">    ParserGrantQuery grant_p;</span><br><span class="line">    ParserSetRoleQuery set_role_p;</span><br><span class="line">    ParserExternalDDLQuery external_ddl_p;</span><br><span class="line"></span><br><span class="line">    bool res &#x3D; query_with_output_p.parse(pos, node, expected)</span><br><span class="line">        || insert_p.parse(pos, node, expected)</span><br><span class="line">        || use_p.parse(pos, node, expected)</span><br><span class="line">        || set_role_p.parse(pos, node, expected)</span><br><span class="line">        || set_p.parse(pos, node, expected)</span><br><span class="line">        || system_p.parse(pos, node, expected)</span><br><span class="line">        || create_user_p.parse(pos, node, expected)</span><br><span class="line">        || create_role_p.parse(pos, node, expected)</span><br><span class="line">        || create_quota_p.parse(pos, node, expected)</span><br><span class="line">        || create_row_policy_p.parse(pos, node, expected)</span><br><span class="line">        || create_settings_profile_p.parse(pos, node, expected)</span><br><span class="line">        || drop_access_entity_p.parse(pos, node, expected)</span><br><span class="line">        || grant_p.parse(pos, node, expected)</span><br><span class="line">        || external_ddl_p.parse(pos, node, expected);</span><br><span class="line"></span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意看这个parseImpl方法，进来后都会先去接<code>ParserQueryWithOutput</code>类解析相关ast，这里类涉及到了<code>explain</code>、<code>select</code>、<code>show</code>，<code>create</code>、<code>alter</code>等相关语法的解析，如果解析不过，则直接报错，解析成功后会处理我们这篇文章中提到的<strong>SETTING</strong>，如下图7定义的，将setting传入的变量存入到<code>s_settings</code>指针中。<br><img src="/images/clickhouse/maxquerysize/7.png" alt="图7"></p><h3 id="clcikhouse的parser总结："><a href="#clcikhouse的parser总结：" class="headerlink" title="clcikhouse的parser总结："></a>clcikhouse的parser总结：</h3><ul><li><ol><li>ClickHouse词法分析器<br>词法解析的主要任务是读入源程序的输入字符、将它们组成词素，生成并输出一个词法单元（Token）序列，每个词法单元对应于一个词素。<code>ClickHouse</code>中的每个词法单元（<code>Token</code>）使用一个<code>struct Tocken</code>结构体对象来进行存储，结构体中存储了词法单元的<code>type</code>和<code>value</code>。<br>ClickHouse词法分析器是由<code>Tokens</code>和<code>Lexer</code>类来实现， <strong><em>DB::Lexer::nextTokenImpl()</em></strong>函数用来对<code>SQL</code>语句进行词法分析的具体实现</li></ol></li><li><ol><li>ClickHouse语法解析器<br>ClickHouse中定义了不同的Parser用来对不同类型的SQL语句进行语法分析，例如：ParserInsertQuery（Insert语法分析器）、ParserCreateQuery（Create语法分析器）、ParserAlterQuery（Alter语法分析器）等等。<br>Parser首先判断输入的Token序列是否是该类型的SQL，若是该类型的SQL，则继续检查语法的正确性，正确则生成AST返回，语法错误的则抛出语法错误异常，否则直接返回空AST语法树</li></ol></li></ul><p><img src="/images/clickhouse/parser/1.png" alt="clickhouse"></p><h3 id="解答setting生效问题"><a href="#解答setting生效问题" class="headerlink" title="解答setting生效问题"></a>解答setting生效问题</h3><p><img src="/images/clickhouse/maxquerysize/8.png" alt="图7"><br>如上图所示，当前原生ck只支持InterpreterSelectQuery和InterpreterInsertQuery对query传入setting进行了重载处理。<br>InterpreterSelectQuery是在自己的构造函数里初始化了setting到context里<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void InterpreterSelectQuery::initSettings()</span><br><span class="line">&#123;</span><br><span class="line">    auto &amp; query &#x3D; getSelectQuery();</span><br><span class="line">    if (query.settings())</span><br><span class="line">        InterpreterSetQuery(query.settings(), *context).executeForCurrentContext();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>InterpreterInsertQuery是在parser解析出ast后，在<code>executeQueryImpl</code>进行的setting重载context。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auto * insert_query &#x3D; ast-&gt;as&lt;ASTInsertQuery&gt;();</span><br><span class="line"></span><br><span class="line">if (insert_query &amp;&amp; insert_query-&gt;settings_ast)</span><br><span class="line">    InterpreterSetQuery(insert_query-&gt;settings_ast, context).executeForCurrentContext();</span><br></pre></td></tr></table></figure><br>剩下的setting都已经是通过Interpreter执行结束后再处理的，对于我们需要在前置传入时没有效果了。</p><h3 id="解决业务困扰"><a href="#解决业务困扰" class="headerlink" title="解决业务困扰"></a>解决业务困扰</h3><p>当前我们的离线导入hive2ck，其实是通过将数据写入到临时表，这张临时表是按照目标表的表结构重新创建了一个MergeTree表，通过spark任务将hive数据以流式方式写入到临时表分区，生产出分区对应的多个part，生产过程中我们会将part拉回到临时表对应的detach目录，这个过程叫<a href="http://way.xiaojukeji.com/article/29557" target="_blank" rel="noopener">离线构建</a>，再将再将part通过ck的attach命令激活，这时候临时表就对该分区可见了，然后再通过replace partition的方式，将临时表的分区替换到我们的目标表去，这整个过程，就是我们的hive2ck处理流程，如下图所示：<br><img src="/images/clickhouse/maxquerysize/9.png" alt="图10"></p><blockquote><p>我们将此离线构建继承到数梦的同步中心后，陆续遇到了业务方来咨询相关问题，下面是问题汇总及如何解决的  </p></blockquote><h4 id="如何在离线导入中将明细数据写入到关联的物化视图"><a href="#如何在离线导入中将明细数据写入到关联的物化视图" class="headerlink" title="如何在离线导入中将明细数据写入到关联的物化视图"></a>如何在离线导入中将明细数据写入到关联的物化视图</h4><p>熟悉clickhouse的同学们都知道，原生ck对于物化视图的写入，唯一的方式是在明细表通过insert写入时，才会将数据经过物化视图的触发器写入关联的物化视图，而在离线构建过程中，ck是不支持的，但很多业务方跟我们提出这个需求，希望离线构建可以支持将分区数据写入到关联物化视图去，于是我们对ck的replace partition 进行了改造。<br>改造前的语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221102&#39; FROM test.visits_basic_tmp;</span><br></pre></td></tr></table></figure><br>改造后的语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221101&#39; FROM test.visits_basic_tmp AND TRIGGER VIEW;</span><br></pre></td></tr></table></figure><br>在离线构建走到替换分区这一步时，我们改造了AstAlterQuery，让<code>ParserAlterQuery</code>增加了对<code>and trigger view</code>的语法解析，解析之后进入到<code>InterpreterAlterQuery</code>时，如果ast返回的trigger view是true，则程序流程会流转到取出明细表元数据，查询是否有关联物化视图，重新构造出类似下面的sql，交过pipeline进行执行，由此将该分区数据写入到物化视图去。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into 物化视图 select from 明细表 where 分区&#x3D;xx</span><br></pre></td></tr></table></figure></p><h4 id="分区过大导入失败如何解决"><a href="#分区过大导入失败如何解决" class="headerlink" title="分区过大导入失败如何解决"></a>分区过大导入失败如何解决</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xxx has timed out! (120000ms) Possible deadlock avoided. Client should retry</span><br></pre></td></tr></table></figure><p><img src="/images/clickhouse/maxquerysize/10.png" alt="图10"><br>如上图所示，替换分区前，会给该明细表加一把锁，并设定锁时间（lock_acquire_timeout），系统默认时120s，如果该分区过大，替换过程超过120s，则会爆上面错误，而本文最开始已经讲解过如何处理setting，考虑到ck原生只支持insert和select时interpreter对setting重载，由此进行改造让InterpreterAlterQuery也支持通过sql传入锁时间，如下面语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE test.visits_basic REPLACE PARTITION &#39;20221108&#39; FROM test.visits_basic_tmp AND TRIGGER VIEW SETTINGS lock_acquire_timeout&#x3D;86400000;</span><br></pre></td></tr></table></figure><br>因为ParserQueryWithOutput已经对setting进行了解析，而AstAlterQuery其实是继承自ASTQueryWithOutput，所以我们已经获得了setting这一块的ast，无需再自己初始化新的ast，只要在InterpreterAlterQuery里把setting重载就行了，如图11<br><img src="/images/clickhouse/maxquerysize/11.png" alt="图10"></p><h4 id="替换分区成功，物化视图数据写入报错如何解决"><a href="#替换分区成功，物化视图数据写入报错如何解决" class="headerlink" title="替换分区成功，物化视图数据写入报错如何解决"></a>替换分区成功，物化视图数据写入报错如何解决</h4><ol><li>首先我们在数梦平台上控制了相关的ddl语句修改，如果用户要删明细表字段，则必须先去处理关联的物化视图字段，如果用户要删明细表，则必须先删物化视图</li><li>遇到替换分区成功，而物化视图写入失败，报错都是锁明细表超时，对于这种case可直接解锁明细表的锁，让物化视图自己去写，不再锁明细表，所以只需要做简单的锁释放便可</li></ol><p>以上是对ck进行改造过程中遇到的3个问题，此改造过程主要是满足离线导入可写入物化视图，未来我们还将对ck进行更多改造，以满足不同业务需求，各个 业务线大佬们如果在使用ck过程中有遇到任何问题，欢迎加入ck用户群，和我们一起沟通解决。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;我们知道语法分析器的作用是根据给定的&lt;a href=&quot;https://baike.baidu.com/item/%E5%BD
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>starrocks在滴滴的落地</title>
    <link href="http://yoursite.com/2022/10/17/starrocks%E5%9C%A8%E6%BB%B4%E6%BB%B4%E7%9A%84%E8%90%BD%E5%9C%B0/"/>
    <id>http://yoursite.com/2022/10/17/starrocks%E5%9C%A8%E6%BB%B4%E6%BB%B4%E7%9A%84%E8%90%BD%E5%9C%B0/</id>
    <published>2022-10-17T06:48:24.803Z</published>
    <updated>2023-01-07T15:53:33.781Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><h4 id="ClickHouse介绍"><a href="#ClickHouse介绍" class="headerlink" title="ClickHouse介绍"></a>ClickHouse介绍</h4><blockquote><p><code>ClickHouse</code>是由俄罗斯的第一大搜索引擎<code>Yandex</code>公司开源的列存数据库。令人惊喜的是，<code>ClickHouse</code>相较于很多商业<code>MPP</code>数据库，比如<code>Vertica</code>，<code>InfiniDB</code>有着极大的性能提升。除了<code>Yandex</code>以外，越来越多的公司开始尝试使用<code>ClickHouse</code>等列存数据库。对于一般的分析业务，结构性较强且数据变更不频繁，可以考虑将需要进行关联的表打平成宽表，放入<code>ClickHouse</code>中。</p><ul><li>配置丰富，只依赖与<code>Zookeeper</code></li><li>线性可扩展性，可以通过添加服务器扩展集群</li><li>容错性高，不同分片间采用异步多主复制</li><li>单表性能极佳，采用向量计算，支持采样和近似计算等优化手段</li><li>功能强大支持多种表引擎</li></ul></blockquote><h4 id="StarRocks介绍"><a href="#StarRocks介绍" class="headerlink" title="StarRocks介绍"></a>StarRocks介绍</h4><blockquote><p><code>StarRocks</code>是一款极速全场景MPP企业级数据库产品，具备水平在线扩缩容，金融级高可用，兼容<code>MySQL</code>协议和<code>MySQL</code>生态，提供全面向量化引擎与多种数据源联邦查询等重要特性。<code>StarRocks</code>致力于在全场景<code>OLAP</code>业务上为用户提供统一的解决方案，适用于对性能，实时性，并发能力和灵活性有较高要求的各类应用场景。</p><ul><li>不依赖于大数据生态，同时外表的联邦查询可以兼容大数据生态</li><li>提供多种不同的模型，支持不同维度的数据建模</li><li>支持在线弹性扩缩容，可以自动负载均衡</li><li>支持高并发分析查询</li><li>实时性好，支持数据秒级写入</li><li>兼容MySQL 5.7协议和MySQL生态</li></ul></blockquote><h4 id="二者的对比"><a href="#二者的对比" class="headerlink" title="二者的对比"></a>二者的对比</h4><p><strong>相似之处</strong></p><ul><li>都可以提供极致的性能</li><li>都不依赖于<code>Hadoop</code>生态</li><li>底层存储分片都提供了主主的复制高可用机制。</li><li>都是<code>MPP</code>架构</li><li>都是列式存储</li><li>都支持表述SQL语法</li><li>都提供了MOLAP库的预聚合能力</li></ul><p><strong>差异性</strong></p><ul><li><code>ClickHouse</code>在更适用于大宽表的场景，<code>TP</code>的数据通过<code>CDC</code>工具的，可以考虑在<code>Flink</code>中将需要关联的表打平，以大宽表的形式写入<code>ClickHouse</code></li><li><code>StarRocks</code>对于<code>join</code>的能力更强，<code>ClickHouse虽</code>然提供了<code>join</code>的语义，但使用上对大表关联的能力支撑较弱，复杂的关联查询经常会引起<code>OOM</code></li><li><code>ClickHouse</code>对高并发的业务并不友好，即使一个查询，也会用服务器一半的<code>CPU</code>去查询</li><li><code>StarRocks</code>可以支撑数千用户同时进行分析查询，在部分场景下，高并发能力能够达到万级。<code>StarRocks</code>在数据存储层，采用先分区再分桶的策略，增加了数据的指向性，利用前缀索引可以快读对数据进行过滤和查找，减少磁盘的<code>I/O</code>操作，提升查询性能</li><li>对于用户的原有的查询基表的 <code>SQL</code> 语句保持不变，<code>StarRocks</code> 会自动选择一个最优的物化视图，从物化视图中读取数据并计算。用户可以通过 <code>EXPLAIN</code> 命令来检查当前查询是否使用了物化视图。而<code>ClickHouse</code>则需要用户自行指定<code>SQL</code>中所需要使用的物化视图。</li></ul><h4 id="为什么推荐StarRocks"><a href="#为什么推荐StarRocks" class="headerlink" title="为什么推荐StarRocks"></a>为什么推荐StarRocks</h4><ol><li>滴滴大数据<code>OLAP</code>团队目前在维护的引擎有<code>StarRocks</code>、<code>ClickHouse</code>、<code>Druid</code>，3个引擎各有各的特点，现有的OLAP引擎(Kylin、Druid、ClickHouse)多表Join时的性能都比较差，甚至不支持多表Join，现有的引擎<code>Druid</code>虽然有<code>lookup</code>表的能力，但经过实际测试后性能不佳。<code>Apache Kylin</code>实际上也不支持<code>Join</code>，多表的<code>Join</code>需要通过在<code>cube</code>构建的时候底层打成宽表来实现。<code>ClickHouse</code>只支持本地<code>Hash join</code>的模式，不支持分布式<code>Shuffle join</code>，多数情况下灵活性受限，性能表现不佳。</li><li><code>OLAP</code>引擎需要同时具备明细数据查询和数据聚合的能力。由于<code>Apache Kylin</code>、<code>Druid</code>不能较好支持明细数据查询，我们引入了<code>ClickHouse</code>，通过在明细表基础上创建相应聚合物化视图来处理，但是不够灵活，对于上层应用来说，查明细和查聚合需要切到不同的表去处理。</li><li>目前我们团队在有限人员情况下需要维护这3个引擎的稳定性，导致我们对每一个引擎的理解深度都不够，特别像<code>ClickHouse</code>，运维成本非常高，ClickHouse集群的分片、副本信息，都是通过静态的配置文件的方式进行配置。当整个集群需要扩缩容的时候，就必须通过修改配置文件的方式进行刷新，数据的均衡都需要运维人员介入。此外ClickHouse通过zookeeper来做副本管理，当集群规模变大时，副本数过多会导致zookeeper的压力变大，集群的稳定性也就会相应变差。<br>为解决以上问题，滴滴大数据<code>OLAP</code>团队在2022年初开始调研<code>StarRocks</code>，在全面测试过从上面对<code>StarRocks</code>和<code>ClickHouse</code>的对比，我们也可以明显感受到<code>StarRocks</code>在多数场景下都是优于<code>ClickHouse</code>的，我们希望通过<code>StarRocks</code>来实现<code>OLAP</code>平台的多业务场景的查询引擎统一化。<br><img src="/images/starrocks/helloworld/20.png" alt="1"><br>注：这是我们针对<code>Druid</code>、<code>ClickHouse</code>、<code>StarRocks</code>进行的测试对比，<a href="http://wiki.intra.xiaojukeji.com/pages/viewpage.action?pageId=799050659" target="_blank" rel="noopener">链接</a>。</li></ol><h3 id="StarRocks特性"><a href="#StarRocks特性" class="headerlink" title="StarRocks特性"></a>StarRocks特性</h3><blockquote><p><code>StarRocks</code>的架构设计融合了<code>MPP</code>数据库，以及分布式系统的设计思想，其特性如下所示。</p><h4 id="架构精简"><a href="#架构精简" class="headerlink" title="架构精简"></a>架构精简</h4><ul><li><code>StarRocks</code>内部通过<code>MPP</code>计算框架完成<code>SQL</code>的具体执行工作。<code>MPP</code>框架能够充分的利用多节点的计算能力，整个查询可以并行执行，从而实现良好的交互式分析体验。</li><li><code>StarRocks</code>集群不需要依赖任何其他组件，易部署、易维护和极简的架构设计，降低了<code>StarRocks</code>系统的复杂度和维护成本，同时也提升了系统的可靠性和扩展性。管理员只需要专注于<code>StarRocks</code>系统，无需学习和管理任何其他外部系统。</li></ul></blockquote><h4 id="全面向量化引擎"><a href="#全面向量化引擎" class="headerlink" title="全面向量化引擎"></a>全面向量化引擎</h4><p><code>StarRocks</code>的计算层全面采用了向量化技术，将所有算子、函数、扫描过滤和导入导出模块进行了系统性优化。通过列式的内存布局、适配<code>CPU</code>的<code>SIMD</code>指令集等手段，充分发挥了现代<code>CPU</code>的并行计算能力，从而实现亚秒级别的多维分析能力。</p><h4 id="智能查询优化"><a href="#智能查询优化" class="headerlink" title="智能查询优化"></a>智能查询优化</h4><p><code>StarRocks</code>通过<code>CBO</code>优化器 <strong>（Cost Based Optimizer）</strong> 可以对复杂查询自动优化。无需人工干预，就可以通过统计信息合理估算执行成本，生成更优的执行计划，大大提高了<code>AdHoc</code>和<code>ETL</code>场景的数据分析效率。</p><h4 id="联邦查询"><a href="#联邦查询" class="headerlink" title="联邦查询"></a>联邦查询</h4><p><code>StarRocks</code>支持使用外表的方式进行联邦查询，当前可以支持<code>Hive</code>、<code>MySQL</code>、<code>Elasticsearch</code>、<code>Iceberg</code>和<code>Hudi</code>类型的外表，您无需通过数据导入，可以直接进行数据查询加速。</p><h4 id="高效更新"><a href="#高效更新" class="headerlink" title="高效更新"></a>高效更新</h4><p><code>StarRocks</code>支持明细模型(DUPLICATE KEY)、聚合模型(AGGREGATE KEY)、主键模型(PRIMARY KEY)和更新模型(UNIQUE KEY)，其中主键模型可以按照主键进行<code>Upsert</code>或<code>Delete</code>操作，通过存储和索引的优化可以在并发更新的同时实现高效的查询优化，更好的服务实时数仓的场景。</p><h4 id="智能物化视图"><a href="#智能物化视图" class="headerlink" title="智能物化视图"></a>智能物化视图</h4><ul><li><code>StarRocks</code>支持智能的物化视图。您可以通过创建物化视图，预先计算生成预聚合表用于加速聚合类查询请求。</li><li><code>StarRocks</code>的物化视图能够在数据导入时自动完成汇聚，与原始表数据保持一致。</li><li>查询的时候，您无需指定物化视图，<code>StarRocks</code>能够自动选择最优的物化视图来满足查询请求。</li></ul><h4 id="标准SQL"><a href="#标准SQL" class="headerlink" title="标准SQL"></a>标准SQL</h4><ul><li><code>StarRocks</code>支持标准的<code>SQL</code>语法，包括聚合、<code>JOIN</code>、排序、窗口函数和自定义函数等功能。</li><li><code>StarRocks</code>可以完整支持<code>TPC-H</code>的22个<code>SQL</code>和<code>TPC-DS</code>的99个<code>SQL</code>。</li><li><code>StarRocks</code>兼容<code>MySQL</code>协议语法，可以使用现有的各种客户端工具、<code>BI</code>软件访问<code>StarRocks</code>，对<code>StarRocks</code>中的数据进行拖拽式分析。</li></ul><h4 id="流批一体"><a href="#流批一体" class="headerlink" title="流批一体"></a>流批一体</h4><ul><li><code>StarRocks</code>支持实时和批量两种数据导入方式。</li><li><code>StarRocks</code>支持的数据源有<code>Kafka</code>、<code>HDFS</code>和本地文件。</li><li><code>StarRocks</code>支持的数据格式有<code>ORC</code>、<code>Parquet</code>和<code>CSV</code>等。</li><li><code>StarRocks</code>可以实时消费<code>Kafka</code>数据来完成数据导入，保证数据不丢不重 <strong>（exactly once）</strong>。</li><li><code>StarRocks</code>也可以从本地或者远程（HDFS）批量导入数据。</li></ul><h4 id="高可用易扩展"><a href="#高可用易扩展" class="headerlink" title="高可用易扩展"></a>高可用易扩展</h4><ul><li><code>StarRocks</code>的元数据和数据都是多副本存储，并且集群中服务有热备，多实例部署，避免了单点故障。</li><li>集群具有自愈能力，可弹性恢复，节点的宕机、下线和异常都不会影响<code>StarRocks</code>集群服务的整体稳定性。</li><li><code>StarRocks</code>采用分布式架构，存储容量和计算能力可近乎线性水平扩展。<code>StarRocks</code>单集群的节点规模可扩展到数百节点，数据规模可达到10 PB级别。</li><li>扩缩容期间无需停服，可以正常提供查询服务。</li><li><code>StarRocks</code>中表模式热变更，可通过一条简单<code>SQL</code>命令动态地修改表的定义，例如增加列、减少列和新建物化视图等。同时，处于模式变更中的表也可以正常导入和查询数据。</li></ul><h3 id="StarRocks应用场景"><a href="#StarRocks应用场景" class="headerlink" title="StarRocks应用场景"></a>StarRocks应用场景</h3><blockquote><p>StarRocks可以满足企业级用户的多种分析需求，具体的业务场景如下所示：</p><h4 id="OLAP多维分析"><a href="#OLAP多维分析" class="headerlink" title="OLAP多维分析"></a>OLAP多维分析</h4><ul><li>用户行为分析</li><li>用户画像、标签分析、圈人</li><li>高维业务指标报表</li><li>自助式报表平台</li><li>业务问题探查分析</li><li>跨主题业务分析</li><li>财务报表</li><li>系统监控分析</li></ul></blockquote><h4 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h4><ul><li>电商大促数据分析</li><li>教育行业的直播质量分析</li><li>物流行业的运单分析</li><li>金融行业绩效分析、指标计算</li><li>广告投放分析</li><li>管理驾驶舱</li><li>探针分析APM（Application Performance Management）</li></ul><h4 id="高并发查询"><a href="#高并发查询" class="headerlink" title="高并发查询"></a>高并发查询</h4><ul><li>广告主报表分析</li><li>零售行业渠道人员分析</li><li>saas行业面向用户分析报表</li><li>dashboard多页面分析</li></ul><h4 id="统一分析"><a href="#统一分析" class="headerlink" title="统一分析"></a>统一分析</h4><p>通过使用一套系统解决多维分析、高并发查询、实时分析和Ad-Hoc查询等场景，降低系统复杂度和多技术栈开发与维护成本。</p><h3 id="如何使用StarRocks"><a href="#如何使用StarRocks" class="headerlink" title="如何使用StarRocks"></a>如何使用StarRocks</h3><blockquote><p>我们olap团队已经将<code>StarRocks</code>接入到滴滴各个平台，下面会介绍如何使用滴滴内部的平台和工具方便快捷的使用<code>StarRocks</code>引擎。<br><img src="/images/starrocks/helloworld/19.png" alt="1"></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h3&gt;&lt;h4 id=&quot;ClickHouse介绍&quot;&gt;&lt;a href=&quot;#ClickHouse介绍&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>clickhouse离线导入大揭秘</title>
    <link href="http://yoursite.com/2022/09/26/replace-trigger/"/>
    <id>http://yoursite.com/2022/09/26/replace-trigger/</id>
    <published>2022-09-26T14:57:11.000Z</published>
    <updated>2022-09-28T06:01:34.018Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何按照hive表的表结构创建clickhouse表"><a href="#如何按照hive表的表结构创建clickhouse表" class="headerlink" title="如何按照hive表的表结构创建clickhouse表"></a>如何按照hive表的表结构创建clickhouse表</h3><p>点击<a href="http://studio.data.didichuxing.com/stream/create-table?tableType=clickHouse" target="_blank" rel="noopener">链接</a>通过数梦的实时平台可以快捷创建对应hive表结构的ck表，如下图所示：<br><img src="/images/clickhouse/hive2clickhouse/1.png" alt="clickhouse"></p><h3 id="hive表的数据如何导入clickhouse表"><a href="#hive表的数据如何导入clickhouse表" class="headerlink" title="hive表的数据如何导入clickhouse表"></a>hive表的数据如何导入clickhouse表</h3><h4 id="创建同步任务"><a href="#创建同步任务" class="headerlink" title="创建同步任务"></a>创建同步任务</h4><p>点击<a href="http://sync.data-pre.didichuxing.com/job/offline/edit/818177?step=1" target="_blank" rel="noopener">链接</a>通过数梦的同步中心可以快捷创建hive表映射到ck表的同步任务，如下图所示<br><img src="/images/clickhouse/hive2clickhouse/2.png" alt="clickhouse"></p><h4 id="同步任务流程"><a href="#同步任务流程" class="headerlink" title="同步任务流程"></a>同步任务流程</h4><p>如下图所示，我们按照这个流程处理hive数据导入到clickhouse<br><img src="/images/clickhouse/hive2clickhouse/3.png" alt="clickhouse"></p><ul><li><ol><li>创建临时表<br>按照ck表的表结构，我们会在集群的所有写节点创建同样表结构的单机表（MergeTree）引擎</li></ol></li><li><ol><li>起spark任务，利用clickhouse-local工具将hive表导入到临时表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat data.orc | clickhouse-local \</span><br><span class="line">--format&#x3D;Native \</span><br><span class="line">--query&#x3D;&#39;CREATE TABLE input (col1 String, col2 String, col3 String) ENGINE &#x3D; File(ORC, stdin);CREATE TABLE target_table (col1 String, col2 String, col3 String) ENGINE &#x3D; MergeTree() partition by tuple() order by col1;insert into target_table select *,&quot;$year&quot; as year,&quot;$month&quot; as month, &quot;$day&quot; as day from input;optimize table target_table final&#39; \</span><br><span class="line">--config-file&#x3D;config.xmls</span><br></pre></td></tr></table></figure></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;如何按照hive表的表结构创建clickhouse表&quot;&gt;&lt;a href=&quot;#如何按照hive表的表结构创建clickhouse表&quot; class=&quot;headerlink&quot; title=&quot;如何按照hive表的表结构创建clickhouse表&quot;&gt;&lt;/a&gt;如何按照hive
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse的写入流程</title>
    <link href="http://yoursite.com/2022/04/05/clickhouse-insert/"/>
    <id>http://yoursite.com/2022/04/05/clickhouse-insert/</id>
    <published>2022-04-05T07:09:55.000Z</published>
    <updated>2022-08-22T10:09:00.256Z</updated>
    
    <content type="html"><![CDATA[<h3 id="请求处理"><a href="#请求处理" class="headerlink" title="请求处理"></a>请求处理</h3><p>ck请求处理过程<br><img src="/images/clickhouse/insert/1.png" alt="clickhouse"></p><h4 id="客户端请求发给ck，ck接收到请求，放入请求队列"><a href="#客户端请求发给ck，ck接收到请求，放入请求队列" class="headerlink" title="客户端请求发给ck，ck接收到请求，放入请求队列"></a>客户端请求发给ck，ck接收到请求，放入请求队列</h4><h4 id="ck将请求队列的请求分发给Request-handler线程处理"><a href="#ck将请求队列的请求分发给Request-handler线程处理" class="headerlink" title="ck将请求队列的请求分发给Request handler线程处理"></a>ck将请求队列的请求分发给Request handler线程处理</h4><h4 id="Request-handler线程处理请求，解析sql语句，执行sql语句逻辑。"><a href="#Request-handler线程处理请求，解析sql语句，执行sql语句逻辑。" class="headerlink" title="Request handler线程处理请求，解析sql语句，执行sql语句逻辑。"></a>Request handler线程处理请求，解析sql语句，执行sql语句逻辑。</h4><h4 id="简单请求处理使用Request-handler线程直接执行（如create，insert，alter等），-复杂请求处理使用Pipeline-executor执行（如select，-insert-select等）"><a href="#简单请求处理使用Request-handler线程直接执行（如create，insert，alter等），-复杂请求处理使用Pipeline-executor执行（如select，-insert-select等）" class="headerlink" title="简单请求处理使用Request handler线程直接执行（如create，insert，alter等）， 复杂请求处理使用Pipeline executor执行（如select， insert select等）"></a>简单请求处理使用Request handler线程直接执行（如create，insert，alter等）， 复杂请求处理使用Pipeline executor执行（如select， insert select等）</h4><h4 id="请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求"><a href="#请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求" class="headerlink" title="请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求"></a>请求线程处理完当前请求后，发送请求结果给给客户端。然后接着处理后续请求</h4><h3 id="insert语句解析执行"><a href="#insert语句解析执行" class="headerlink" title="insert语句解析执行"></a>insert语句解析执行</h3><h4 id="初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息"><a href="#初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息" class="headerlink" title="初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息"></a>初始化请求上下文环境。包括session，用户信息，当前database等，限流，权限，设置等信息</h4><h4 id="解析sql语句"><a href="#解析sql语句" class="headerlink" title="解析sql语句"></a>解析sql语句</h4><h4 id="检查被写入的表是否存在，是否有写入权限，是否被限流"><a href="#检查被写入的表是否存在，是否有写入权限，是否被限流" class="headerlink" title="检查被写入的表是否存在，是否有写入权限，是否被限流"></a>检查被写入的表是否存在，是否有写入权限，是否被限流</h4><h4 id="对insert数据校验，字段是否存在，是否满足约束"><a href="#对insert数据校验，字段是否存在，是否满足约束" class="headerlink" title="对insert数据校验，字段是否存在，是否满足约束"></a>对insert数据校验，字段是否存在，是否满足约束</h4><h4 id="根据默认值填充空字段和物化字段"><a href="#根据默认值填充空字段和物化字段" class="headerlink" title="根据默认值填充空字段和物化字段"></a>根据默认值填充空字段和物化字段</h4><h4 id="缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。"><a href="#缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。" class="headerlink" title="缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。"></a>缓存单次insert语句中的数据，insert语句全部接收完成或缓存数据超过一定大小后批量写入数据。</h4><h4 id="将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree"><a href="#将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree" class="headerlink" title="将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree"></a>将insert的数据写入存储引擎，主要包含StorageDistributed和StorageReplicatedXXMergeTree</h4><h4 id="检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表"><a href="#检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表" class="headerlink" title="检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表"></a>检查是否有物化视图，如果有使用物化视图逻辑处理insert数据，写入物化视图表</h4><h3 id="分布式表写入"><a href="#分布式表写入" class="headerlink" title="分布式表写入"></a>分布式表写入</h3><blockquote><p>分布式表数据写入一般情况下是异步写入，只有对使用 remote(‘addresses_expr’, db, table[, ‘user’[, ‘password’], sharding_key]) 定义的表的写入是同步的。如果分布式表中含有local表或replical的表local副本，直接写本地表。<br><img src="/images/clickhouse/insert/2.png" alt="clickhouse"></p></blockquote><h4 id="将写入block数据按sharding逻辑分成多个block"><a href="#将写入block数据按sharding逻辑分成多个block" class="headerlink" title="将写入block数据按sharding逻辑分成多个block"></a>将写入block数据按sharding逻辑分成多个block</h4><h4 id="将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据"><a href="#将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据" class="headerlink" title="将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据"></a>将原insert语句改写，表名改成分布式表对应的底表，数据改成分shard后的block数据</h4><h4 id="检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎"><a href="#检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎" class="headerlink" title="检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎"></a>检查待写入的每个shard，如果shard在本机，则直接写入实际存储引擎</h4><h4 id="shard在远程，将新insert语句写入远程shard本地缓存文件。"><a href="#shard在远程，将新insert语句写入远程shard本地缓存文件。" class="headerlink" title="shard在远程，将新insert语句写入远程shard本地缓存文件。"></a>shard在远程，将新insert语句写入远程shard本地缓存文件。</h4><h4 id="通知后台线程发送本地缓存中的数据"><a href="#通知后台线程发送本地缓存中的数据" class="headerlink" title="通知后台线程发送本地缓存中的数据"></a>通知后台线程发送本地缓存中的数据</h4><h4 id="后台执行过程"><a href="#后台执行过程" class="headerlink" title="后台执行过程"></a>后台执行过程</h4><h4 id="读远程shard本地缓存目录"><a href="#读远程shard本地缓存目录" class="headerlink" title="读远程shard本地缓存目录"></a>读远程shard本地缓存目录</h4><h4 id="逐个处理每个文件"><a href="#逐个处理每个文件" class="headerlink" title="逐个处理每个文件"></a>逐个处理每个文件</h4><h4 id="根据配置的loadbalance策略，选择合适的机器连接"><a href="#根据配置的loadbalance策略，选择合适的机器连接" class="headerlink" title="根据配置的loadbalance策略，选择合适的机器连接"></a>根据配置的loadbalance策略，选择合适的机器连接</h4><h4 id="将文件的insert语句通过上步连接发送给远程机器执行"><a href="#将文件的insert语句通过上步连接发送给远程机器执行" class="headerlink" title="将文件的insert语句通过上步连接发送给远程机器执行"></a>将文件的insert语句通过上步连接发送给远程机器执行</h4><h4 id="执行成功后删除对应文件"><a href="#执行成功后删除对应文件" class="headerlink" title="执行成功后删除对应文件"></a>执行成功后删除对应文件</h4><h3 id="本地表写入"><a href="#本地表写入" class="headerlink" title="本地表写入"></a>本地表写入</h3><blockquote><p>本地表一般是StorageReplicatedXXMergeTree，其写入过程如下：<br><img src="/images/clickhouse/insert/3.png" alt="clickhouse"><br>本地表是以block为最小单元单次写入，一个block中的数据可能是一次insert的全部数据，也可以是部分数据。</p></blockquote><h4 id="检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。"><a href="#检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。" class="headerlink" title="检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。"></a>检查当前表part数量，如果part数量过多（接近part数限制）延时写入数据，如果part数量过限制则写入失败。</h4><h4 id="检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。"><a href="#检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。" class="headerlink" title="检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。"></a>检查写入block中parttition总数是否超过限制。如果超过限制，写入失败。</h4><h4 id="将写入block数据按partition-by-逻辑分成多个block"><a href="#将写入block数据按partition-by-逻辑分成多个block" class="headerlink" title="将写入block数据按partition by 逻辑分成多个block"></a>将写入block数据按partition by 逻辑分成多个block</h4><h4 id="依次将每个分区的block数据写入表中"><a href="#依次将每个分区的block数据写入表中" class="headerlink" title="依次将每个分区的block数据写入表中"></a>依次将每个分区的block数据写入表中</h4><h4 id="创建分区的临时part"><a href="#创建分区的临时part" class="headerlink" title="创建分区的临时part"></a>创建分区的临时part</h4><h4 id="计算part数据的sha1生成part对应的blockid"><a href="#计算part数据的sha1生成part对应的blockid" class="headerlink" title="计算part数据的sha1生成part对应的blockid"></a>计算part数据的sha1生成part对应的blockid</h4><h4 id="检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。"><a href="#检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。" class="headerlink" title="检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。"></a>检查该blockid在是否存在（表的zk中会记录所有已存在的part的blockid）。如果存在表示插入数据重复，忽略后续步骤。</h4><h4 id="将part信息发布到ck，通知其他副本拉去新添加part"><a href="#将part信息发布到ck，通知其他副本拉去新添加part" class="headerlink" title="将part信息发布到ck，通知其他副本拉去新添加part"></a>将part信息发布到ck，通知其他副本拉去新添加part</h4><h4 id="将临时part加入到commit到mergetree表"><a href="#将临时part加入到commit到mergetree表" class="headerlink" title="将临时part加入到commit到mergetree表"></a>将临时part加入到commit到mergetree表</h4><h4 id="如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件"><a href="#如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件" class="headerlink" title="如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件"></a>如果配置最小同步副本大于1，则等代其他副本数据同步达到满足条件</h4><h4 id="临时part创建过程"><a href="#临时part创建过程" class="headerlink" title="临时part创建过程"></a>临时part创建过程</h4><ul><li>创建block数据对应分区的临时part对象</li><li>计算分区min_max索引</li><li>处理排序和主键索引</li><li>ttl处理</li><li>其他二级索引处理</li><li>将处理过的block数据和索引写入临时part，根据配置的压缩方式压缩</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;请求处理&quot;&gt;&lt;a href=&quot;#请求处理&quot; class=&quot;headerlink&quot; title=&quot;请求处理&quot;&gt;&lt;/a&gt;请求处理&lt;/h3&gt;&lt;p&gt;ck请求处理过程&lt;br&gt;&lt;img src=&quot;/images/clickhouse/insert/1.png&quot; alt=&quot;cl
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse物化视图在滴滴的实践</title>
    <link href="http://yoursite.com/2022/04/01/clickhouse-materialized-view/"/>
    <id>http://yoursite.com/2022/04/01/clickhouse-materialized-view/</id>
    <published>2022-04-01T06:57:11.000Z</published>
    <updated>2022-08-22T10:09:00.256Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是物化视图"><a href="#什么是物化视图" class="headerlink" title="什么是物化视图"></a>什么是物化视图</h3><ul><li>普通视图（View）是从一张或者多张数据库表查询导出的虚拟表，可以反映出基础表之间的数据变化，但是本身是不存储数据的，每次的查询都会从基础表重新聚合出查询结果，所以普通视图查询其实等同于创建视图时的查询语句的查询效率。</li><li>物化视图（Materialized View）是查询结果集的一份持久化存储，也称为底表的快照（snapshot），查询结果集的范围很宽泛，可以是基础表中部分数据的一份简单拷贝，也可以是多表join之后产生的结果或其子集，或者原始数据的聚合指标等等。物化视图不会随着基础表的变化而变化，如果要更新数据的话，需要用户手动进行，如周期性执行SQL，或利用触发器等机制。</li></ul><p><img src="/images/clickhouse/crud/5.png" alt="avatar"></p><h3 id="如何创建物化视图"><a href="#如何创建物化视图" class="headerlink" title="如何创建物化视图"></a>如何创建物化视图</h3><blockquote><h4 id="MergeTree排序引擎"><a href="#MergeTree排序引擎" class="headerlink" title="MergeTree排序引擎"></a>MergeTree排序引擎</h4></blockquote><h4 id="ReplacingMergeTree去重引擎"><a href="#ReplacingMergeTree去重引擎" class="headerlink" title="ReplacingMergeTree去重引擎"></a>ReplacingMergeTree去重引擎</h4><h4 id="AggregatingMergeTree聚合引擎"><a href="#AggregatingMergeTree聚合引擎" class="headerlink" title="AggregatingMergeTree聚合引擎"></a>AggregatingMergeTree聚合引擎</h4><h4 id="UniqueMergeTree-实时去重引擎"><a href="#UniqueMergeTree-实时去重引擎" class="headerlink" title="UniqueMergeTree 实时去重引擎"></a>UniqueMergeTree 实时去重引擎</h4><h4 id="SummingMergeTree-求和引擎"><a href="#SummingMergeTree-求和引擎" class="headerlink" title="SummingMergeTree 求和引擎"></a>SummingMergeTree 求和引擎</h4><h4 id="CollapsingMergeTree-折叠引擎"><a href="#CollapsingMergeTree-折叠引擎" class="headerlink" title="CollapsingMergeTree 折叠引擎"></a>CollapsingMergeTree 折叠引擎</h4><h4 id="VersionedCollapsingMergeTree-版本折叠引擎"><a href="#VersionedCollapsingMergeTree-版本折叠引擎" class="headerlink" title="VersionedCollapsingMergeTree 版本折叠引擎"></a>VersionedCollapsingMergeTree 版本折叠引擎</h4><h3 id="如何写入物化视图"><a href="#如何写入物化视图" class="headerlink" title="如何写入物化视图"></a>如何写入物化视图</h3><h4 id="底表触发"><a href="#底表触发" class="headerlink" title="底表触发"></a>底表触发</h4><h4 id="同步任务触发"><a href="#同步任务触发" class="headerlink" title="同步任务触发"></a>同步任务触发</h4><h4 id="直接写入到分布式表"><a href="#直接写入到分布式表" class="headerlink" title="直接写入到分布式表"></a>直接写入到分布式表</h4><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;什么是物化视图&quot;&gt;&lt;a href=&quot;#什么是物化视图&quot; class=&quot;headerlink&quot; title=&quot;什么是物化视图&quot;&gt;&lt;/a&gt;什么是物化视图&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;普通视图（View）是从一张或者多张数据库表查询导出的虚拟表，可以反映出基础表之间的数据
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>alibaba.druid配置</title>
    <link href="http://yoursite.com/2022/03/21/java-druid-config/"/>
    <id>http://yoursite.com/2022/03/21/java-druid-config/</id>
    <published>2022-03-21T07:09:55.000Z</published>
    <updated>2022-08-22T10:09:00.259Z</updated>
    
    <content type="html"><![CDATA[<h4 id="两种思路"><a href="#两种思路" class="headerlink" title="两种思路"></a>两种思路</h4><ul><li>后端服务主动淘汰空闲超时120s的连接，然后再主动创建连接。</li><li>后端服务对空闲连接保活，周期小于120秒进行一次mysql.ping或select 1操作。（确认过dba两个操作均可使dbproxy保活连接）</li></ul><h4 id="hikari连接池能否支持上述方案："><a href="#hikari连接池能否支持上述方案：" class="headerlink" title="hikari连接池能否支持上述方案："></a>hikari连接池能否支持上述方案：</h4><ul><li>idleTimeout：设置最大空闲时间小于120秒，空闲超时主动淘汰链接，并且hikari会自动创建新连接填充。实际发现该参数不能解决此问题，因为该参数优先级低于minimumIdle，若池中已经保持低于minimumIdle的连接数就不会再进行空闲连接淘汰。所以该参数不能解决问题。</li><li>maxLifetime：设置最大生存时间小于120秒，生存超时主动淘汰连接，并且hikari会自动创建新连接填充。能够解决该问题，但是会每120s就要淘汰且新建连接。</li></ul><h4 id="druid连接池能否支持上述方案："><a href="#druid连接池能否支持上述方案：" class="headerlink" title="druid连接池能否支持上述方案："></a>druid连接池能否支持上述方案：</h4><ul><li>testWhileIdle：设置true开启周期性健康检查 会主动淘汰掉失效的连接。</li><li>maxEvictableIdleTimeMillis：最大空闲时间设置小于120s，该参数不受minIdle参数约束，只要超过最大空闲时间就会自动淘汰连接。<br>看似上面两个参数均能解决，但是由于durid默认不会主动创建新链接，所以上面两个参数使连接清空后 查询时仍旧会因创建连接而耗时增加。</li><li>keepAlive：设置true开启保活机制，可解决该问题</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">druid:</span><br><span class="line"># 初始化大小</span><br><span class="line">initialSize: 10</span><br><span class="line"># 最大连接数</span><br><span class="line">maxActive: 30</span><br><span class="line"># 最小空闲数（周期性清除时保留的最小连接数）</span><br><span class="line">minIdle: 10</span><br><span class="line"># 最大空闲数（返还连接时若超过最大空闲连接数就丢弃）</span><br><span class="line">maxIdle: 20</span><br><span class="line"># 有效性校验</span><br><span class="line">validationQuery: select 1</span><br><span class="line"># 周期性check空闲连接</span><br><span class="line">testWhileIdle: true</span><br><span class="line"># 借出时check（影响性能）</span><br><span class="line">testOnBorrow: false</span><br><span class="line"># 返还时check（影响性能）</span><br><span class="line">testOnReturn: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 周期性检查的间隔时间，单位是毫秒</span><br><span class="line">timeBetweenEvictionRunsMillis: 60000</span><br><span class="line"># 连接的最小空闲时间，小于该时间不会被周期性check清除。单位是毫秒</span><br><span class="line">minEvictableIdleTimeMillis: 50000</span><br><span class="line"># 连接的最大空闲时间，大于该时间会被周期性check清除，且优先级大于minIdle。单位是毫秒</span><br><span class="line">maxEvictableIdleTimeMillis: 100000</span><br><span class="line"># 开启连接保活策略。作用：https:&#x2F;&#x2F;www.bookstack.cn&#x2F;read&#x2F;Druid&#x2F;d90f9643acdca5c0.md</span><br><span class="line">keepAlive: true</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;两种思路&quot;&gt;&lt;a href=&quot;#两种思路&quot; class=&quot;headerlink&quot; title=&quot;两种思路&quot;&gt;&lt;/a&gt;两种思路&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;后端服务主动淘汰空闲超时120s的连接，然后再主动创建连接。&lt;/li&gt;
&lt;li&gt;后端服务对空闲连接保活，周期小于
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="druid" scheme="http://yoursite.com/tags/druid/"/>
    
  </entry>
  
  <entry>
    <title>为什么需要关闭连接</title>
    <link href="http://yoursite.com/2022/03/21/java-why-need-close-connection/"/>
    <id>http://yoursite.com/2022/03/21/java-why-need-close-connection/</id>
    <published>2022-03-21T07:09:55.000Z</published>
    <updated>2022-08-22T10:09:00.259Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://stackoverflow.com/questions/25864235/why-we-should-close-the-connection-in-jdbc-if-we-dont-do-it-what-will-happen" target="_blank" rel="noopener">链接</a></p><h3 id="TCP标志"><a href="#TCP标志" class="headerlink" title="TCP标志"></a>TCP标志</h3><p>SYN: (同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。</p><p>ACK: (确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。</p><p>FIN: (结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。</p><h3 id="TCP状态"><a href="#TCP状态" class="headerlink" title="TCP状态"></a>TCP状态</h3><blockquote><p>TCP状态在系统里都有对应的解释或设置,可见<code>man tcp</code>，以下介绍主要常见的几种</p></blockquote><p>1)、LISTEN: 首先服务端需要打开一个socket进行监听，状态为LISTEN.<br>/<em> The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 </em>/</p><p>2)、SYN_SENT: 客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT.<br>/<em>The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 </em>/</p><p>3)、SYN_RECV: 服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN. 之后状态置为SYN_RECV<br>/<em> A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 </em>/</p><p>4)、ESTABLISHED: 代表一个打开的连接，双方可以进行或已经在数据交互了。<br>/<em> The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 </em>/</p><p>5)、FIN_WAIT1:主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态.<br>/<em> The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 </em>/</p><p>6)、CLOSE_WAIT: 被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT.<br>/<em> The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 </em>/</p><p>7)、FIN_WAIT2: 主动关闭端接到ACK后，就进入了FIN-WAIT-2 .<br>/<em> Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 </em>/</p><p>8)、LAST_ACK: 被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK .<br>/<em> The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 </em>/</p><p>9)、TIME_WAIT: 只发生在主动关闭连接的一方。主动关闭方在接收到被动关闭方的FIN请求后，发送成功给对方一个ACK后,将自己的状态由FIN_WAIT2修改为TIME_WAIT，而必须再等2倍 的MSL(Maximum Segment Lifetime,MSL是一个数据报在internetwork中能存在的时间)时间之后双方才能把状态 都改为CLOSED以关闭连接。目前RHEL里保持TIME_WAIT状态的时间为60秒。<br>/<em> The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 </em>/</p><p>10)、CLOSING: 比较少见.<br>/<em> Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 </em>/</p><p>11)、CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束.<br>/<em> The socket is not being used. 没有任何连接状态 </em>/</p><h3 id="为什么创建的连接需要关闭？"><a href="#为什么创建的连接需要关闭？" class="headerlink" title="为什么创建的连接需要关闭？"></a>为什么创建的连接需要关闭？</h3><p>如果不关闭连接，这些系统资源将一直在内存中，等待下一次系统gc时才会被回收，而如果系统频繁的fgc将会导致你的程序明显卡顿，如果一直没有gc，也会导致你的内存泄漏</p><h3 id="如果一定要关闭，那是不是可以使用单例模式在所有地方使用？"><a href="#如果一定要关闭，那是不是可以使用单例模式在所有地方使用？" class="headerlink" title="如果一定要关闭，那是不是可以使用单例模式在所有地方使用？"></a>如果一定要关闭，那是不是可以使用单例模式在所有地方使用？</h3><h3 id="是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？"><a href="#是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？" class="headerlink" title="是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？"></a>是不是可以使用连接池，一次创建n个连接，用完归还到池子里等下次再被使用？</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/25864235/why-we-should-close-the-connection-in-jdbc-if-we-dont-do-it-what-will-happen&quot; targe
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>使用clickhouse实现索引</title>
    <link href="http://yoursite.com/2022/02/21/clickhouse-index/"/>
    <id>http://yoursite.com/2022/02/21/clickhouse-index/</id>
    <published>2022-02-21T06:57:11.000Z</published>
    <updated>2022-08-22T10:09:00.256Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一级索引"><a href="#一级索引" class="headerlink" title="一级索引"></a>一级索引</h3><h4 id="index-granularity"><a href="#index-granularity" class="headerlink" title="index_granularity"></a>index_granularity</h4><p><img src="/images/clickhouse/crud/5.png" alt="avatar"></p><h3 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h3><h4 id="granularity"><a href="#granularity" class="headerlink" title="granularity"></a>granularity</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一级索引&quot;&gt;&lt;a href=&quot;#一级索引&quot; class=&quot;headerlink&quot; title=&quot;一级索引&quot;&gt;&lt;/a&gt;一级索引&lt;/h3&gt;&lt;h4 id=&quot;index-granularity&quot;&gt;&lt;a href=&quot;#index-granularity&quot; class=&quot;he
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>聊聊linux下的软硬链接</title>
    <link href="http://yoursite.com/2022/02/16/linux-ln/"/>
    <id>http://yoursite.com/2022/02/16/linux-ln/</id>
    <published>2022-02-16T07:48:18.000Z</published>
    <updated>2022-08-22T10:09:00.260Z</updated>
    
    <content type="html"><![CDATA[<h3 id="链接概念"><a href="#链接概念" class="headerlink" title="链接概念"></a>链接概念</h3><p>Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。<br>默认情况下，ln命令产生硬链接。</p><h3 id="硬连接"><a href="#硬连接" class="headerlink" title="硬连接"></a>硬连接</h3><ul><li>硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。</li><li>硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。</li></ul><h3 id="软连接"><a href="#软连接" class="headerlink" title="软连接"></a>软连接</h3><p>另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#创建一个测试文件f1</span><br><span class="line">[oracle@Linux]$ touch f1</span><br><span class="line"></span><br><span class="line">#创建f1的一个硬连接文件f2</span><br><span class="line">[oracle@Linux]$ ln f1 f2</span><br><span class="line"></span><br><span class="line">#创建f1的一个符号连接文件f3</span><br><span class="line">[oracle@Linux]$ ln -s f1 f3</span><br><span class="line"></span><br><span class="line"># -i参数显示文件的inode节点信息</span><br><span class="line">[oracle@Linux]$ ls -li   </span><br><span class="line">total 0</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f1</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f2</span><br><span class="line">9797649 lrwxrwxrwx  1 oracle oinstall 2 Apr 21 08:11 f3 -&gt; f1</span><br></pre></td></tr></table></figure><p>从上面的结果中可以看出，硬连接文件f2与原文件f1的inode节点相同，均为9797648，然而符号连接文件的inode节点不同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 修改文件内容</span><br><span class="line">[oracle@Linux]$ echo &quot;I am f1 file&quot; &gt;&gt;f1</span><br><span class="line"></span><br><span class="line"># 打印f1文件内容</span><br><span class="line">[oracle@Linux]$ cat f1</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">I am f1 file</span><br><span class="line"># 删除f1</span><br><span class="line">[oracle@Linux]$ rm -f f1</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容，未受到影响，所以硬链接未受源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容，提示找不到该文件或者目录，所以软连接会受到源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">cat: f3: No such file or directory</span><br></pre></td></tr></table></figure><p>通过上面的测试可以看出：当删除原始文件f1后，硬连接f2不受影响，但是符号连接f1文件无效</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1).删除符号连接f3,对f1,f2无影响；<br>2).删除硬连接f2，对f1,f3也无影响；<br>3).删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效；<br>4).同时删除原文件f1,硬连接f2，整个文件会真正的被删除。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;链接概念&quot;&gt;&lt;a href=&quot;#链接概念&quot; class=&quot;headerlink&quot; title=&quot;链接概念&quot;&gt;&lt;/a&gt;链接概念&lt;/h3&gt;&lt;p&gt;Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。&lt;br&gt;默
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>由于overlay占用磁盘空间导致磁盘告警</title>
    <link href="http://yoursite.com/2022/02/15/linux-overlay-full/"/>
    <id>http://yoursite.com/2022/02/15/linux-overlay-full/</id>
    <published>2022-02-15T07:09:08.000Z</published>
    <updated>2022-08-22T10:09:00.260Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>早上突然收到告警短信，xxx服务磁盘使用率超过80%，如下图，赶紧上机器进行排查，下面是排查的过程<br><img src="/images/linux/disk_full/1.png" alt="avatar"></p><h3 id="查看机器整体磁盘使用情况"><a href="#查看机器整体磁盘使用情况" class="headerlink" title="查看机器整体磁盘使用情况"></a>查看机器整体磁盘使用情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 下面是结果</span><br><span class="line">root@xxx.docker.ys:~&#x2F;dlap-manager$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">overlay          20G   18G  2.7G  87% &#x2F;</span><br><span class="line">tmpfs            64M     0   64M   0% &#x2F;dev</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">&#x2F;dev&#x2F;sda3       219G   15G  193G   8% &#x2F;etc&#x2F;hosts</span><br><span class="line">shm              64M     0   64M   0% &#x2F;dev&#x2F;shm</span><br><span class="line">&#x2F;dev&#x2F;sdb1       4.4T  949G  3.5T  22% &#x2F;etc&#x2F;hostname</span><br><span class="line">tmpfs            63G   12K   63G   1% &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;acpi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;scsi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;firmware</span><br></pre></td></tr></table></figure><p>看到overlay这个文件目录占了<code>87%</code>，仔细研究下这个文件夹是什么</p><h4 id="overlay介绍"><a href="#overlay介绍" class="headerlink" title="overlay介绍"></a>overlay介绍</h4><p>OverlayFS是一种堆叠文件系统，它依赖并建立在其它的文件系统之上（例如ext4fs和xfs等等），并不直接参与磁盘空间结构的划分，仅仅将原来底层文件系统中不同的目录进行“合并”，然后向用户呈现，这也就是联合挂载技术，对比于AUFS，OverlayFS速度更快，实现更简单。 而Linux 内核为Docker提供的OverlayFS驱动有两种：overlay和overlay2。而overlay2是相对于overlay的一种改进，在inode利用率方面比overlay更有效。但是overlay有环境需求：docker版本17.06.02+，宿主机文件系统需要是ext4或xfs格式。<br>overlayfs通过三个目录：lower目录、upper目录、以及work目录实现，其中lower目录可以是多个，work目录为工作基础目录，挂载后内容会被清空，且在使用过程中其内容用户不可见，最后联合挂载完成给用户呈现的统一视图称为为merged目录<br><img src="/images/linux/disk_full/2.png" alt="avatar"><br>在上述图中可以看到三个层结构，即：lowerdir、uperdir、merged，其中lowerdir是只读的image layer，其实就是rootfs，对应的lowerdir是可以有多个目录。而upperdir则是在lowerdir之上的一层，这层是读写层，在启动一个容器时候会进行创建，所有的对容器数据更改都发生在这里层。最后merged目录是容器的挂载点，也就是给用户暴露的统一视角。</p><h4 id="overlay如何工作"><a href="#overlay如何工作" class="headerlink" title="overlay如何工作"></a>overlay如何工作</h4><p>当容器中发生数据修改时候overlayfs存储驱动又是如何进行工作的？以下将阐述其读写过程：</p><ul><li><ol><li>读：</li></ol><ul><li>如果文件在容器层（upperdir），直接读取文件；</li><li>如果文件不在容器层（upperdir），则从镜像层（lowerdir）读取；</li></ul></li><li><ol><li>写：</li></ol><ul><li>首次写入： 如果在upperdir中不存在，overlay和overlay2执行copy_up操作，把文件从lowdir拷贝到upperdir，由于overlayfs是文件级别的（即使文件只有很少的一点修改，也会产生的copy_up的行为），后续对同一文件的在此写入操作将对已经复制到容器的文件的副本进行操作。这也就是常常说的写时复制（copy-on-write）</li><li>删除文件和目录： 当文件在容器被删除时，在容器层（upperdir）创建whiteout文件，镜像层(lowerdir)的文件是不会被删除的，因为他们是只读的，但without文件会阻止他们显示，当目录在容器内被删除时，在容器层（upperdir）一个不透明的目录，这个和上面whiteout原理一样，阻止用户继续访问，即便镜像层仍然存在。 </li></ul></li><li><ol><li>注意事项</li></ol><ul><li>copy_up操作只发生在文件首次写入，以后都是只修改副本,</li><li>overlayfs只适用两层目录，相比于比AUFS，查找搜索都更快。</li><li>容器层的文件删除只是一个“障眼法”，是靠whiteout文件将其遮挡，image层并没有删除，这也就是为什么使用docker commit 提交保存的镜像会越来越大，无论在容器层怎么删除数据，image层都不会改变。</li></ul></li></ul><h4 id="overlay镜像存储结构"><a href="#overlay镜像存储结构" class="headerlink" title="overlay镜像存储结构"></a>overlay镜像存储结构</h4><p>从仓库拉取ubuntu镜像，结果显示总共拉取了6层镜像如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-xxx.ys ~]$ sudo docker pull ubuntu-test:xenial</span><br><span class="line">Trying to pull repository ubuntu-test ...</span><br><span class="line">xenial: Pulling from ubuntu-test</span><br><span class="line">58690f9b18fc: Pull complete</span><br><span class="line">b51569e7c507: Pull complete</span><br><span class="line">da8ef40b9eca: Pull complete</span><br><span class="line">fb15d46c38dc: Pull complete</span><br><span class="line">4c7a0de79adc: Pull complete</span><br><span class="line">5eff12cba838: Pull complete</span><br><span class="line">Digest: sha256:d21c70f1203a5b0fe1d8a1b60bd1924ca5458ba450828f6b88c4e973db84c8e8</span><br><span class="line">Status: Downloaded newer image for ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>此时6层镜像被存储在/var/lib/docker/overlay2下，将镜像运行起来一个容器，如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -itd --name ubuntu-test ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>运行容器之后，查询出容器的元数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取容器ID</span><br><span class="line">sudo docker ps -a | grep ubuntu</span><br><span class="line">&#x2F;&#x2F; 通过容器ID查看元数据</span><br><span class="line">sudo docker inspect container-id</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/4.png" alt="avatar"></p><p>进入容器创建一个文件，如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo docker exec -it ubuntu-test bash</span><br><span class="line">echo &#39;xxxxxx&#39; &gt; helloworld.txt</span><br></pre></td></tr></table></figure></p><p>通过tree命令查看新创建的文件出现在哪里<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree -L 3 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;f90282cedadf6b7765ba06ea8983af306f78773baeca9ff1e418651d0b9d14f2&#x2F;diff</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/3.png" alt="avatar"></p><h3 id="回到问题本身"><a href="#回到问题本身" class="headerlink" title="回到问题本身"></a>回到问题本身</h3><p>overlay目录使用了87%的存储，触发了磁盘告警，overlay目录是我们的弹性云容器运行的目录，发现通过nohup启动的jar包将所有stdout/stderr都输出到了nohup.out文件，该文件也持久化存在/var/lib/docker/overlay2下，所以需要对nohup.out进行处理，不可直接删除，因为jar启动后所有的输出流都会转存到nohup.out，这个文件句柄已经打开，所有的stdout/stderr仍然会输出，只是输出在/proc/pid/fd/1或者/proc/pid/fd/2这些目录下。</p><blockquote><p>0描述符 标准输入<br>1描述符 标注输出<br>2描述符 标注错误输出  </p></blockquote><p><strong>linux一切到可以看作文件</strong>，/proc/pid/fd/1 就是pid进程的标准输出，/proc/pid/fd/1 就是pid进程的标准错误输出，我们通过测试可以看到下面结果，就算我们删除了nohup.out文件，任何会将stdout/stderro输出到这个文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@xxx.ys ~]$ tree -L 3 &#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">&#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">├── 0 -&gt; &#x2F;dev&#x2F;null</span><br><span class="line">├── 1 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">├── 2 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">└── 3 -&gt; &#x2F;home&#x2F;hadoop&#x2F;test.txt</span><br><span class="line"></span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure></p><ul><li><ol><li>重启jar包，将所有错误/标准输出忽略<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; &gt;&#x2F;dev&#x2F;null是表示linux的空设备，是一个特殊的文件，写入到它的内容都会被丢弃(等同于 1&gt;&#x2F;dev&#x2F;null)</span><br><span class="line">&#x2F;&#x2F; 2&gt;&amp;1表示所有错误输出都重定向到标准输出</span><br><span class="line">&#x2F;&#x2F; 所以就是将错误输出重定向到标准输出，将标准输出重定向到空设备，就是禁止所有输出&#x2F;错误</span><br><span class="line">nohup java -jar xx.jar &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>删除nohup.out文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f nohup.out</span><br></pre></td></tr></table></figure></li></ol></li></ul><h3 id="修改docker的根目录"><a href="#修改docker的根目录" class="headerlink" title="修改docker的根目录"></a>修改docker的根目录</h3><h4 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h4><ol><li>停止docker服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure></li><li><p>创建新的docker工作目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure><p>这个目录可以自定义，但是一定要保证在/root里面</p></li><li><p>迁移/var/lib/docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -avz &#x2F;var&#x2F;lib&#x2F;docker &#x2F;data2&#x2F;docker&#x2F;</span><br></pre></td></tr></table></figure></li><li>配置devicemapper.conf<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 不存在就创建</span><br><span class="line">sudo mkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;</span><br><span class="line"># 不存在就创建</span><br><span class="line">sudo vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;devicemapper.conf</span><br></pre></td></tr></table></figure></li><li><p>在devicemapper.conf中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd  --graph&#x3D;&#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure></li><li><p>重启docker服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"> </span><br><span class="line">systemctl restart docker</span><br><span class="line"> </span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure></li><li><p>确认是否配置成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure><p><img src="/images/linux/disk_full/5.png" alt="avatar"></p></li></ol><p>重新启动所有容器后，确认无误。即可删除/var/lib/docker里面所有文件。</p><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>如果报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error response from daemon: Cannot restart container linyu: shim error: docker-runc not installed on system</span><br></pre></td></tr></table></figure></p><ul><li><ol><li>判断是否安装runc<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qi runc</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>未安装则先安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install runc</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>创建软连接<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;</span><br><span class="line">sudo ln -s docker-runc-current docker-runc</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>重启服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker restart container_id</span><br></pre></td></tr></table></figure></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;早上突然收到告警短信，xxx服务磁盘使用率超过80%，如下图，赶紧上机器进行排查，下面是排查的过程&lt;br&gt;&lt;img src=&quot;/images
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>使用clickhouse实现数据更新和删除</title>
    <link href="http://yoursite.com/2022/02/03/clickhouse-crud/"/>
    <id>http://yoursite.com/2022/02/03/clickhouse-crud/</id>
    <published>2022-02-03T14:57:11.000Z</published>
    <updated>2022-08-22T10:09:00.255Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是CRUD"><a href="#什么是CRUD" class="headerlink" title="什么是CRUD"></a>什么是CRUD</h3><blockquote><p><code>CRUD</code>是指在做计算处理时的增加(<code>Create</code>)、检索(<code>Retrieve</code>)、更新(<code>Update</code>)和删除(<code>Delete</code>)几个单词的首字母简写。<code>crud</code>主要被用在描述软件系统中数据库或者持久层的基本操作功能</p></blockquote><h3 id="clickhouse物理上的crud"><a href="#clickhouse物理上的crud" class="headerlink" title="clickhouse物理上的crud"></a>clickhouse物理上的crud</h3><ul><li><ol><li>create创建表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create table account(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  is_delete UInt8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; MergeTree </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure><img src="/images/clickhouse/crud/5.png" alt="avatar"></li></ol></li><li><ol><li>insert写入数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.account(time, name, alias, age, version, is_delete) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 0)</span><br></pre></td></tr></table></figure><blockquote><p>写入数据后会按照partitionby生成对应的分区part目录<br><img src="/images/clickhouse/crud/6.png" alt="avatar"></p></blockquote></li></ol></li><li><ol><li>update更新<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table default.account</span><br><span class="line">update alias &#x3D; &#39;super_hero&#39;</span><br><span class="line">where alias &#x3D; &#39;superhero&#39;</span><br></pre></td></tr></table></figure><blockquote><p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/4.png" alt="avatar"></p></blockquote></li></ol></li><li><ol><li>delete删除<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table delete where id &#x3D; 1</span><br></pre></td></tr></table></figure><blockquote><p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/7.png" alt="avatar"></p></blockquote></li></ol></li><li><ol><li>retrieve检索<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, is_delete from account where is_delete &#x3D; 0 order by version desc</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>可以通过system.mutations查询执行计划<br><img src="/images/clickhouse/crud/9.png" alt="avatar"><br>当mutation操作执行完成后，system.mutations表中对应的mutation记录中is_done字段的值会变为1。</li></ol></li><li><ol><li>可以通过system.parts查询执行结果<br><img src="/images/clickhouse/crud/8.png" alt="avatar"><br>当旧的数据片段移除后，system.parts表中旧数据片段对应的记录会被移除。</li></ol></li></ul><blockquote><p>可以看到mutation操作完成后，之前的目录已经被删除<br><img src="/images/clickhouse/crud/10.png" alt="avatar"></p></blockquote><h3 id="clickhouse的mutation是什么"><a href="#clickhouse的mutation是什么" class="headerlink" title="clickhouse的mutation是什么"></a>clickhouse的mutation是什么</h3><h4 id="官方文档解释"><a href="#官方文档解释" class="headerlink" title="官方文档解释"></a>官方文档解释</h4><p>从官方对于mutaiton的解释<a href="https://clickhouse.com/docs/zh/sql-reference/statements/alter/#alter-mutations" target="_blank" rel="noopener">链接</a>中，我们需要注意到几个关键词，如下</p><ul><li><ol><li>manipulate table data<br>操作表数据</li></ol></li><li><ol><li>asynchronous background processes<br>异步后台处理</li></ol></li><li><ol><li>rewriting whole data parts<br>重写全部数据part</li></ol></li><li><ol><li>a SELECT query that started executing during a mutation will see data from parts that have already been mutated along with data from parts that have not been mutated yet<br>在突变期间的查询语句，将看到已经完成突变的数据part和还未发生突变的part</li></ol></li><li><ol><li>data that was inserted into the table before the mutation was submitted will be mutated and data that was inserted after that will not be mutated<br>在提交突变之前插入表中的数据将被突变，而在此之后插入的数据将不会被突变</li></ol></li><li><ol><li>There is no way to roll back the mutation once it is submitted, but if the mutation is stuck for some reason it can be cancelled with the KILL MUTATION query<br>突变一旦被提交就没有方式可以回滚，但是如果突变由于一些原因被卡住，可以使用<code>KILL MUTATION</code>取消突变</li></ol></li></ul><h4 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h4><p>当用户执行一个如上的Mutation操作获得返回时，ClickHouse内核其实只做了两件事情：<br><img src="/images/clickhouse/crud/1.png" alt="avatar"></p><ul><li><ol><li>检查Mutation操作是否合法；<blockquote><p>主体逻辑在MutationsInterpreter::validate函数</p></blockquote></li></ol></li><li><ol><li>保存Mutation命令到存储文件中，唤醒一个异步处理merge和mutation的工作线程；<blockquote><p>主体逻辑在StorageMergeTree::mutate函数中。</p></blockquote></li></ol></li></ul><p>Merge逻辑<br><strong>StorageMergeTree::merge</strong>函数是<code>MergeTree</code>异步<code>Merge</code>的核心逻辑，<code>Data Part Merge</code>的工作除了通过后台工作线程自动完成，用户还可以通过<code>Optimize</code>命令来手动触发。自动触发的场景中，系统会根据后台空闲线程的数据来启发式地决定本次<code>Merge</code>最大可以处理的数据量大小，<strong>max_bytes_to_merge_at_min_space_in_pool</strong>: 决定当空闲线程数最大时可处理的数据量上限（默认150GB）<br><strong>max_bytes_to_merge_at_max_space_in_pool</strong>: 决定只剩下一个空闲线程时可处理的数据量上限（默认1MB）<br>当用户的写入量非常大的时候，应该适当调整工作线程池的大小和这两个参数。当用户手动触发<code>merge</code>时，系统则是根据<code>disk</code>剩余容量来决定可处理的最大数据量。</p><p>Mutation逻辑<br>系统每次都只会订正一个<code>Data Part</code>，但是会聚合多个<code>mutation</code>任务批量完成，这点实现非常的棒。因为在用户真实业务场景中一次数据订正逻辑中可能会包含多个<code>Mutation</code>命令，把这多个<code>mutation</code>操作聚合到一起订正效率上就非常高。系统每次选择一个排序键最小的并且需要订正<code>Data Part</code>进行操作，本意上就是把数据从前往后进行依次订正。<br><img src="/images/clickhouse/crud/11.png" alt="avatar"><br><img src="/images/clickhouse/crud/13.png" alt="avatar"><br><img src="/images/clickhouse/crud/12.png" alt="avatar"></p><p>mutation和merge相互独立执行。看完本文前面的分析，大家应该也注意到了目前Data Part的merge和mutation是相互独立执行的，Data Part在同一时刻只能是在merge或者mutation操作中。对于MergeTree这种存储彻底Immutable的设计，数据频繁merge、mutation会引入巨大的IO负载。实时上merge和mutation操作是可以合并到一起去考虑的，这样可以省去数据一次读写盘的开销。对数据写入压力很大又有频繁mutation的场景，会有很大帮助</p><h3 id="clickhouse逻辑CRUD"><a href="#clickhouse逻辑CRUD" class="headerlink" title="clickhouse逻辑CRUD"></a>clickhouse逻辑CRUD</h3><p><a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/versionedcollapsingmergetree/" target="_blank" rel="noopener">VersionedCollapsingMergeTree介绍</a>，引擎继承自 <code>MergeTree</code> 并将折叠行的逻辑添加到合并数据部分的算法中。 <code>VersionedCollapsingMergeTree</code> 用于相同的目的 折叠树 但使用不同的折叠算法，允许以多个线程的任何顺序插入数据。 特别是， <code>Version</code> 列有助于正确折叠行，即使它们以错误的顺序插入。 相比之下, <code>CollapsingMergeTree</code> 只允许严格连续插入。</p><h4 id="创建VersionedCollapsingMergeTree表"><a href="#创建VersionedCollapsingMergeTree表" class="headerlink" title="创建VersionedCollapsingMergeTree表"></a>创建VersionedCollapsingMergeTree表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create table test_version_collapsing(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  sign Int8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; VersionedCollapsingMergeTree(sign, version) </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure><h4 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 1)</span><br></pre></td></tr></table></figure><h4 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h4><ul><li><ol><li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>假设要更新alias=update_super_hero，其他值不变，将version由1.捞出的值上+1，类似以下sql<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 先将旧行标示为删除，就是将sign &#x3D; -1</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, -1);</span><br><span class="line"></span><br><span class="line"># 再去插入新行，包含要更新的列</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, 1).</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure></li></ol></li></ul><h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><ul><li><ol><li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>假设要删除alias=update_super_hero，其他值不变，将sign=1,类似以下sql<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, -1)</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure></li></ol></li></ul><h4 id="注意项"><a href="#注意项" class="headerlink" title="注意项"></a>注意项</h4><ul><li><ol><li>只有相同分区内的数据才能删除和更新</li></ol></li><li><ol><li>如果不使用 <strong>having sum(sign) &gt; 0</strong>的方式去查询，则可以使用<code>final</code>方式查询<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from test_version_collapsing final;</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>也可以使用<code>optimize</code>方式强制合并分区，再查询，但是这个方式可能会造成集群cpu飙高，而且<code>optimize</code>一个大表需要时间很长，效率极低<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimize table test_version_collapsing final</span><br></pre></td></tr></table></figure></li></ol></li><li><ol><li>sign必须要唯一，添加用1，则删除一定是-1，才可以被折叠处理</li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;什么是CRUD&quot;&gt;&lt;a href=&quot;#什么是CRUD&quot; class=&quot;headerlink&quot; title=&quot;什么是CRUD&quot;&gt;&lt;/a&gt;什么是CRUD&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;CRUD&lt;/code&gt;是指在做计算处理时的增加(&lt;code&gt;C
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse query on cluster源码解读</title>
    <link href="http://yoursite.com/2022/01/21/clickhouse-ddl-on-cluster/"/>
    <id>http://yoursite.com/2022/01/21/clickhouse-ddl-on-cluster/</id>
    <published>2022-01-21T07:04:11.000Z</published>
    <updated>2022-08-22T10:09:00.255Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分布式DDL执行链路"><a href="#分布式DDL执行链路" class="headerlink" title="分布式DDL执行链路"></a>分布式DDL执行链路</h3><blockquote><p>在介绍具体的分布式<code>DDL</code>执行链路之前，先为大家梳理一下哪些操作是可以走分布式<code>DDL</code>执行链路的，大家也可以自己在源码中查看一下<code>ASTQueryWithOnCluster</code>的继承类有哪些：<br><img src="/images/clickhouse/ddloncluster/1.png" alt="cgi">  </p></blockquote><ul><li>ASTAlterQuery：<br>包括<code>ATTACH_PARTITION</code>、<code>FETCH_PARTITION</code>、<code>FREEZE_PARTITION</code>、<code>FREEZE_ALL</code>等操作（对表的数据分区粒度进行操作）。</li><li>ASTCreateQuery：<br>包括常见的建库、建表、建视图，还有<code>ClickHouse</code>独有的<code>Attach Table</code>（可以从存储文件中直接加载一个之前卸载的数据表）。</li><li>ASTCreateQuotaQuery:<br>包括对租户的配额操作语句，例如<code>create quaota</code>，或者<code>alter quota</code>语句</li><li>ASTCreateRoleQuery：<br>包括对租户角色操作语句，例如<code>create/alter/drop/set/set default/show create role</code>语句，或者<code>show roles</code></li><li>ASTCreateRowPolicyQuery<br>对表的查询做行级别的策略限制，例如<code>create row policy</code> 或者 <code>alter row policy</code></li><li>ASTCreateSettingsProfileQuery<br>对角色或者租户的资源限制和约束，例如<code>create settings profile</code> 或者 <code>alter settings profile</code></li><li>ASTCreateUserQuery<br>对租户的操作语句，例如<code>create create user</code> 或者 <code>alter create user</code></li><li>ASTDropAccessEntityQuery<br>涉及到了clickhouse权限相关的所有删除语句，包括<code>DROP USER</code>,<code>DROP ROLE</code>,<code>DROP QUOTA</code>,<code>DROP [ROW] POLICY</code>,<code>DROP [SETTINGS] PROFILE</code></li><li>ASTDropQuery：<br>其中包含了三种不同的删除操作（<code>Drop</code> / <code>Truncate</code> / <code>Detach</code>），<code>Detach Table</code>和<code>Attach Table</code>对应，它是表的卸载动作，把表的存储目录整个移到专门的<code>detach</code>文件夹下，然后关闭表在节点<code>RAM</code>中的”引用”，这张表在节点中不再可见。</li><li>ASTGrantQuery:<br>这是授权相关的<code>RBAC</code>，可以对库/表授予或者撤销读/写等权限命令，例如<code>GRANT insert on db.tb to acount</code>，或者<code>REVOKE all on db.tb from account</code>。</li><li>ASTKillQueryQuery：<br>可以<code>Kill</code>正在运行的<code>Query</code>，也可以<code>Kill</code>之前发送的<code>Mutation</code>命令。</li><li>ASTOptimizeQuery：<br>这是<code>MergeTree</code>表引擎特有的操作命令，它可以手动触发<code>MergeTree</code>表的合并动作，并可以强制数据分区下的所有<code>Data Part</code>合并成一个。</li><li>ASTRenameQuery：<br>修改表名，可更改到不同库下。</li></ul><h3 id="DDL-Query-Task分发"><a href="#DDL-Query-Task分发" class="headerlink" title="DDL Query Task分发"></a>DDL Query Task分发</h3><p><img src="/images/clickhouse/ddloncluster/2.png" alt="cgi"><br><code>ClickHouse</code>内核对每种<code>SQL</code>操作都有对应的<code>IInterpreter</code>实现类，其中的<code>execute</code>方法负责具体的操作逻辑。而以上列举的<code>ASTQuery</code>对应的<code>IInterpreter</code>实现类中的<code>execute</code>方法都加入了分布式<code>DDL</code>执行判断逻辑，把所有分布式<code>DDL</code>执行链路统一都<code>DDLWorker::executeDDLQueryOnCluster</code>方法中。<br><code>executeDDLQueryOnCluster</code>的过程大致可以分为三个步骤：</p><h4 id="检查DDLQuery的合法性，"><a href="#检查DDLQuery的合法性，" class="headerlink" title="检查DDLQuery的合法性，"></a>检查<code>DDLQuery</code>的合法性，</h4><ul><li>1、校验query规则<br><img src="/images/clickhouse/ddloncluster/3.png" alt="cgi"></li><li>2、初始化DDLWorker，取config.xml表的配置<br><img src="/images/clickhouse/ddloncluster/4.png" alt="cgi"></li><li>3、替换query里的数据库名称<br><img src="/images/clickhouse/ddloncluster/5.png" alt="cgi"><br>这里替换库名的逻辑是，</li><li>3.1、如果query里有带上库名称，则直接使用，若无，则走2</li><li>3.2、metrika.xml里配置了shard的默认库<code>&lt;default_database&gt;default&lt;/default_database&gt;</code>，则使用默认库，否则走3</li><li>3.3、使用当前session的database<br><img src="/images/clickhouse/ddloncluster/6.png" alt="cgi"></li></ul><h4 id="把DDLQuery写入到Zookeeper任务队列中"><a href="#把DDLQuery写入到Zookeeper任务队列中" class="headerlink" title="把DDLQuery写入到Zookeeper任务队列中"></a>把<code>DDLQuery</code>写入到<code>Zookeeper</code>任务队列中</h4><ul><li>1、构造DDLLogEntry对象，把entry对象加入到queue队列中<br><img src="/images/clickhouse/ddloncluster/7.png" alt="cgi"><br>注意：queue_dir是由<strong>config.xml</strong>配置的，如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;distributed_ddl&gt;</span><br><span class="line">    &lt;path&gt;&#x2F;clickhouse&#x2F;task_queue&#x2F;ddl&lt;&#x2F;path&gt;</span><br><span class="line">&lt;&#x2F;distributed_ddl&gt;</span><br></pre></td></tr></table></figure></li><li>2、去zookeeper执行创建znode，把entry序列化存入znode<br><img src="/images/clickhouse/ddloncluster/8.png" alt="cgi"></li><li>3、在znode下创建active和finished的znode<br><img src="/images/clickhouse/ddloncluster/9.png" alt="cgi"><blockquote><p>下面截图为query-xxx的记录的entry内容<br><img src="/images/clickhouse/ddloncluster/10.png" alt="cgi"></p></blockquote></li></ul><h4 id="等待Zookeeper任务队列的反馈把结果返回给用户。"><a href="#等待Zookeeper任务队列的反馈把结果返回给用户。" class="headerlink" title="等待Zookeeper任务队列的反馈把结果返回给用户。"></a>等待<code>Zookeeper</code>任务队列的反馈把结果返回给用户。</h4><p><img src="/images/clickhouse/ddloncluster/11.png" alt="cgi"></p><h4 id="DDL-Query-Task执行线程"><a href="#DDL-Query-Task执行线程" class="headerlink" title="DDL Query Task执行线程"></a>DDL Query Task执行线程</h4><ul><li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li><li>2、执行线程加入到线程池后，执行ddl task<br><img src="/images/clickhouse/ddloncluster/13.png" alt="cgi"></li><li>3、过滤掉 query 中带有 on cluster xxx的语句，根据不同的query选择不同执行方式<br><img src="/images/clickhouse/ddloncluster/14.png" alt="cgi"></li><li>4、alter、optimize、truncate语句需要在leader节点执行<br><img src="/images/clickhouse/ddloncluster/15.png" alt="cgi"><blockquote><p>注意：Replcated表的alter、optimize、truncate这些query是会先判断是否leader节点，不是则不处理，在执行时，会先给zookeeper加一个分布式锁，锁住这个任务防止被修改，执行时都是把自己的host:port注册到znode/query-xxx/active下，执行完成后，结果写到znode/query-xxx/finished下。</p></blockquote></li></ul><h4 id="DDL-Query-Task清理线程"><a href="#DDL-Query-Task清理线程" class="headerlink" title="DDL Query Task清理线程"></a>DDL Query Task清理线程</h4><ul><li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li><li>2、执行清理逻辑，每次执行后，下一次执行需要过1分钟后才可以接着做清理<br><img src="/images/clickhouse/ddloncluster/16.png" alt="cgi"></li></ul><h3 id="分布式DDL的执行链路总结"><a href="#分布式DDL的执行链路总结" class="headerlink" title="分布式DDL的执行链路总结"></a>分布式DDL的执行链路总结</h3><ul><li><p>1）节点收到用户的分布式<code>DDL</code>请求</p></li><li><p>2）节点校验分布式DDL请求合法性，在<code>Zookeeper</code>的任务队列中创建<code>Znode</code>并上传<strong>DDL LogEntry（query-xxxx）</strong>，同时在<code>LogEntry</code>的<code>Znode</code>下创建<code>active</code>和<code>finish</code>两个状态同步的<code>Znode</code></p></li><li><p>3）<code>Cluster</code>中的节点后台线程消费<code>Zookeeper</code>中的<code>LogEntry</code>队列执行处理逻辑，处理过程中把自己注册到<code>acitve Znode</code>下，并把处理结果写回到<code>finish Znode</code>下<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></p></li><li><p>4）用户的原始请求节点，不断轮询<code>LogEntry Znode</code>下的<code>active</code>和<code>finish</code>状态<code>Znode</code>，当目标节点全部执行完成任务或者触发超时逻辑时，用户就会获得结果反馈</p></li></ul><p>这个分发逻辑中有个值得注意的点：分布式<code>DDL</code>执行链路中有超时逻辑，如果触发超时用户将无法从客户端返回中确定最终执行结果，需要自己去<code>Zookeeper</code>上<code>check</code>节点返回结果（也可以通过<strong>system.zookeeper</strong>系统表查看）。<strong>每个节点只有一个后台线程在消费执行DDL任务</strong>，碰到某个DDL任务（典型的是optimize任务）执行时间很长时，会导致DDL任务队列积压从而产生大面积的超时反馈。</p><p>可以看出Zookeeper在分布式DDL执行过程中主要充当DDL Task的分发、串行化执行、结果收集的一致性介质。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;分布式DDL执行链路&quot;&gt;&lt;a href=&quot;#分布式DDL执行链路&quot; class=&quot;headerlink&quot; title=&quot;分布式DDL执行链路&quot;&gt;&lt;/a&gt;分布式DDL执行链路&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;在介绍具体的分布式&lt;code&gt;DDL&lt;/code&gt;
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
  <entry>
    <title>记一次线上fgc排查过程</title>
    <link href="http://yoursite.com/2022/01/19/java_full_gc/"/>
    <id>http://yoursite.com/2022/01/19/java_full_gc/</id>
    <published>2022-01-19T11:04:11.000Z</published>
    <updated>2022-08-22T10:09:00.259Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>用户反馈api请求时快时慢，慢的时候网页打开很久都没有结果，直到超时给出500错误</p><h3 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h3><h4 id="初步怀疑"><a href="#初步怀疑" class="headerlink" title="初步怀疑"></a>初步怀疑</h4><p>当前程序分布式部署在多个节点上，通过<code>vip</code>进行负载均衡，所以对于直接将反馈慢的页面打开的请求通过<code>curl</code>方式登陆生产环境所有节点，进行轮训一遍，发现其中02节点需要等待很久，其他节点均正常，所以问题应该出在02节点，<br>注意：这个定位过程当然也可以使用监控图就一目了然了。推荐使用<code>grafana prometheus spring boot dashboard</code>在<code>google</code>搜寻下相关配置就可以了。<br><img src="/images/java/fgc/8.png" alt="cgi"></p><h4 id="查询该节点负载"><a href="#查询该节点负载" class="headerlink" title="查询该节点负载"></a>查询该节点负载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 得到进程的pid</span><br><span class="line">jps -mlv </span><br><span class="line"># 通过top命令查询节点实际负载</span><br><span class="line">top -Hp pid</span><br></pre></td></tr></table></figure><p><img src="/images/java/fgc/1.png" alt="cgi"></p><blockquote><p>通过top命令发现该节点memory使用了接近<code>90%</code>，怀疑出现内存泄露</p></blockquote><h4 id="查询该节点内存使用情况"><a href="#查询该节点内存使用情况" class="headerlink" title="查询该节点内存使用情况"></a>查询该节点内存使用情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat -gcutil pid 1000</span><br></pre></td></tr></table></figure><p><img src="/images/java/fgc/2.png" alt="cgi"></p><blockquote><p>如我所料，几乎不到<code>1s</code>就开始做一次<code>fgc</code>，所以服务才越来越慢响应</p></blockquote><h3 id="内存分析"><a href="#内存分析" class="headerlink" title="内存分析"></a>内存分析</h3><h4 id="使用jmap分析内存概要"><a href="#使用jmap分析内存概要" class="headerlink" title="使用jmap分析内存概要"></a>使用jmap分析内存概要</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -heap pid ｜ head -n20</span><br></pre></td></tr></table></figure><p><img src="/images/java/fgc/10.png" alt="cgi"></p><h4 id="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"><a href="#使用jmap打印堆内存的对象，带上live，则只统计活着的对象" class="headerlink" title="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"></a>使用jmap打印堆内存的对象，带上live，则只统计活着的对象</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jmap -histo pid ｜ head -n20</span><br><span class="line">jmap -histo:live pid ｜ head -n20</span><br></pre></td></tr></table></figure><p><img src="/images/java/fgc/11.png" alt="cgi"></p><h4 id="打印进程的内存使用情况"><a href="#打印进程的内存使用情况" class="headerlink" title="打印进程的内存使用情况"></a>打印进程的内存使用情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -dump:format&#x3D;b,file&#x3D;dumpFileName pid</span><br></pre></td></tr></table></figure><p><img src="/images/java/fgc/3.png" alt="cgi"></p><blockquote><p>dump出来了<code>12G</code>的文件，通过scp工具转存到本地</p></blockquote><h4 id="jprofiler分析堆内存"><a href="#jprofiler分析堆内存" class="headerlink" title="jprofiler分析堆内存"></a>jprofiler分析堆内存</h4><ul><li>1、把dumpFileName文件转存为.hprof格式后直接双击打开，按照instance count逆序排列<br><img src="/images/java/fgc/5.png" alt="cgi"></li><li>2、会发现有hashmap类型占了最大头，但是这个类型，双击它，选择<code>merged incoming reference</code>，查看合并后的来源引用统计<br><img src="/images/java/fgc/6.png" alt="cgi"></li><li>3、还是选最大头的文件数一直拆到最里层，找出来源引用是<code>org.apache.ibatis.executor.result.DefaultResultHandler</code>这个类，基本能定位到问题根源了，是我们连接<code>clickhouse</code>客户端去查询结果时，未对结果集做限制，导致了一个很大的结果集返回到内存中。<br><img src="/images/java/fgc/7.png" alt="cgi"></li></ul><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>当然是对结果集做限制，检测用户输入的sql，是否包含limit条数限制，若未限制，则对sql进行改写，增加<code>500</code>条数限制<br><img src="/images/java/fgc/9.png" alt="cgi"></p><h3 id="GC的运行原理"><a href="#GC的运行原理" class="headerlink" title="GC的运行原理"></a>GC的运行原理</h3><p><code>GC</code>（<code>garbage collection</code>）：垃圾回收，主要是指<code>YGC</code>和<code>FGC</code><br><code>YGC</code>（minor garbage collection）：新生代垃圾回收<br><code>FGC</code>（major garbage collection）：老年代垃圾回收</p><h4 id="堆内存结构"><a href="#堆内存结构" class="headerlink" title="堆内存结构"></a>堆内存结构</h4><p><img src="/images/java/fgc/12.png" alt="cgi"><br>堆内存采用了分代结构，包括新生代和老年代，新生代分为：<code>eden</code>区、<code>from survivor</code>区（简称<code>s0</code>）、<code>to survivor</code>区（简称<code>s1</code>），三者默认比例上8:1:1，另外新生代和老年代的比例则是1:2。<br>堆内存之所以采用分代结构，是因为绝大多数对象都是短生命周期的，这样设计可以把不同的生命周期的对象放在不同的区域中，然后针对新生代和老年代采用不同的垃圾回收算法，从而使得<code>GC</code>效率最高。</p><h4 id="YGC是什么时候触发的？"><a href="#YGC是什么时候触发的？" class="headerlink" title="YGC是什么时候触发的？"></a>YGC是什么时候触发的？</h4><p>大多数情况下，对象直接在年轻代中的<code>Eden</code>区进行分配，如果<code>Eden</code>区域没有足够的空间，那么就会触发<code>YGC</code>（<code>Minor GC</code>），<code>YGC</code>处理的区域只有新生代。因为大部分对象在短时间内都是可收回掉的，因此YGC后只有极少数的对象能存活下来，而被移动到S0区（采用的是复制算法）。<br>当触发下一次YGC时，会将Eden区和S0区的存活对象移动到S1区，同时清空Eden区和S0区。当再次触发YGC时，这时候处理的区域就变成了Eden区和S1区（即S0和S1进行角色交换）。每经过一次YGC，存活对象的年龄就会加1。</p><h4 id="FGC是什么时候触发的？"><a href="#FGC是什么时候触发的？" class="headerlink" title="FGC是什么时候触发的？"></a>FGC是什么时候触发的？</h4><ul><li><p>1、<code>YGC</code>时，<code>To Survivor</code>区不足以存放存活的对象，对象会直接进入到老年代。经过多次<code>YGC</code>后，如果存活对象的年龄达到了设定阈值，则会晋升到老年代中。动态年龄判定规则，<code>To Survivor</code>区中相同年龄的对象，如果其大小之和占到了 <code>To Survivor</code> 区一半以上的空间，那么大于此年龄的对象会直接进入老年代，而不需要达到默认的分代年龄。大对象：由<code>-XX:PretenureSizeThreshold</code>启动参数控制，若对象大小大于此值，就会绕过新生代, 直接在老年代中分配。当晋升到老年代的对象大于了老年代的剩余空间时，就会触发<code>FGC</code>（<code>Major GC</code>），<code>FGC</code>处理的区域同时包括新生代和老年代。老年代的内存使用率达到了一定阈值（可通过参数调整），直接触发<code>FGC</code>。</p></li><li><p>2、空间分配担保：在<code>YGC</code>之前，会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，说明<code>YGC</code>是不安全的，则会查看参数 <code>HandlePromotionFailure</code> 是否被设置成了允许担保失败，如果不允许则直接触发<code>Full GC</code>；如果允许，那么会进一步检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于也会触发 <code>Full GC</code>。</p></li><li><p>3、<code>Metaspace</code>（元空间）在空间不足时会进行扩容，当扩容到了<code>-XX:MetaspaceSize</code> 参数的指定值时，也会触发<code>FGC</code>。</p></li><li><p>4、<code>System.gc</code>() 或者<code>Runtime.gc</code>() 被显式调用时，触发<code>FGC</code>。</p></li></ul><h4 id="GC对程序会产生什么影响"><a href="#GC对程序会产生什么影响" class="headerlink" title="GC对程序会产生什么影响"></a>GC对程序会产生什么影响</h4><p>不管是YGC还是FGC，都会造成一定程度上的程序卡顿（stop the world问题：GC线程开始工作，其他工作线程被挂起），即使采用ParNew、CMS、G1这些更先进的垃圾回收算法，也只是减少卡顿的时间，并不能完全消除卡顿</p><ul><li>FGC过于频繁：<br>FGC通常是比较慢的，少则几百号秒，多则几秒，正常情况下FGC每隔几个小时或者几天才会执行一次，对系统的影响是可接受的，所以一旦出现FGC频繁（比如几分钟/几十分钟出现一次）会导致工作线程频繁被停掉，让系统看起来就一直卡顿，使得程序的整体性能变差。</li><li>YGC耗时过长：<br>一般来说YGC的总耗时指需要几十毫秒或上百毫秒，对于系统来说几乎无感知，所以如果YGC耗时达到1秒甚至几秒（快赶上FGC的耗时），那么卡顿就会加剧，加上YGC本身会比较频繁发生，就可能导致服务响应时间超时。</li><li>FGC耗时过长：<br>FGC耗时增加，卡顿时间也会随之增加，尤其对于高并发服务，可能导致FGC期间比较多的超时问题，可用性降低，这种也需要关注</li><li>YGC过于频繁：<br>即使YGC不会引起服务超时，但是YGC过于频繁也会降低服务的整体性能，对于高并发服务也是需要关注的。</li></ul><blockquote><p>其中，「FGC过于频繁」和「YGC耗时过长」，这两种情况属于比较典型的GC问题，大概率会对程序的服务质量产生影响。剩余两种情况的严重程度低一些，但是对于高并发或者高可用的程序也需要关注。</p></blockquote><h4 id="导致FGC的原因总结"><a href="#导致FGC的原因总结" class="headerlink" title="导致FGC的原因总结"></a>导致FGC的原因总结</h4><ul><li>大对象：系统一次性加载了过多数据到内存中（比如SQL查询未做分页），导致大对象进入了老年代。（即本文中的案例）</li><li>内存泄漏：频繁创建了大量对象，但是无法被回收（比如IO对象使用完后未调用close方法释放资源），先引发FGC，最后导致OOM.</li><li>程序频繁生成一些长生命周期的对象，当这些对象的存活年龄超过分代年龄时便会进入老年代，最后引发FGC. </li><li>程序BUG导致动态生成了很多新类，使得 Metaspace 不断被占用，先引发FGC，最后导致OOM.</li><li>代码中显式调用了gc方法，包括自己的代码甚至框架中的代码。</li><li>JVM参数设置问题：包括总内存大小、新生代和老年代的大小、Eden区和S区的大小、元空间大小、垃圾回收算法等等。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h3&gt;&lt;p&gt;用户反馈api请求时快时慢，慢的时候网页打开很久都没有结果，直到超时给出500错误&lt;/p&gt;
&lt;h3 id=&quot;排查过程&quot;&gt;&lt;a
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>记一次线上core dump</title>
    <link href="http://yoursite.com/2022/01/19/linux_min_free_kbytes/"/>
    <id>http://yoursite.com/2022/01/19/linux_min_free_kbytes/</id>
    <published>2022-01-19T11:04:11.000Z</published>
    <updated>2022-08-22T10:41:13.800Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>官方解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">min_free_kbytes:</span><br><span class="line">This is used to force the Linux VM to keep a minimum number</span><br><span class="line">of kilobytes free.  The VM uses this number to compute a</span><br><span class="line">watermark[WMARK_MIN] value for each lowmem zone in the system.</span><br><span class="line">Each lowmem zone gets a number of reserved free pages based</span><br><span class="line">proportionally on its size.</span><br><span class="line">Some minimal amount of memory is needed to satisfy PF_MEMALLOC</span><br><span class="line">allocations; if you set this to lower than 1024KB, your system will</span><br><span class="line">become subtly broken, and prone to deadlock under high loads.</span><br><span class="line">Setting this too high will OOM your machine instantly.</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 3145728 &gt;&gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;min_free_kbytes</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -a | grep min_free</span><br></pre></td></tr></table></figure><p><img src="/images/min_free_kbytes/2.png" alt="docker-bridge"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -a | grep oom</span><br></pre></td></tr></table></figure><p><img src="/images/min_free_kbytes/1.png" alt="docker-bridge"></p><p>min_free_kbytes大小的影响<br>min_free_kbytes设的越大，watermark的线越高，同时三个线之间的buffer量也相应会增加。这意味着会较早的启动kswapd进行回收，且会回收上来较多的内存（直至watermark[high]才会停止），这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量。极端情况下设置min_free_kbytes接近内存大小时，留给应用程序的内存就会太少而可能会频繁地导致OOM的发生。</p><p>min_free_kbytes设的过小，则会导致系统预留内存过小。kswapd回收的过程中也会有少量的内存分配行为（会设上PF_MEMALLOC）标志，这个标志会允许kswapd使用预留内存；另外一种情况是被OOM选中杀死的进程在退出过程中，如果需要申请内存也可以使用预留部分。这两种情况下让他们使用预留内存可以避免系统进入deadlock状态。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h3&gt;&lt;p&gt;官方解释&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;
      
    
    </summary>
    
    
      <category term="sre" scheme="http://yoursite.com/categories/sre/"/>
    
    
      <category term="cpp" scheme="http://yoursite.com/tags/cpp/"/>
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse报错Metadata on replica的解决方法</title>
    <link href="http://yoursite.com/2022/01/13/clickhouse-mutation-problem/"/>
    <id>http://yoursite.com/2022/01/13/clickhouse-mutation-problem/</id>
    <published>2022-01-13T11:04:11.000Z</published>
    <updated>2022-08-22T10:09:00.256Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClickHouse exception, code: 517, host: xx.xx.xx.xx, port: xxxx; Code: 517, e.displayText() &#x3D; DB::Exception: Metadata on replica is not up to date with common metadata in Zookeeper. Cannot alter: Bad version</span><br></pre></td></tr></table></figure><p>我们在修改表结构（例如<code>alter table drop column xxx</code>）时经常会遇到以上报错，原因副本上的元数据和在zookeeper上的元数据不一致，无法更新，因为版本号不一样。</p><h3 id="查找system-replication-queue"><a href="#查找system-replication-queue" class="headerlink" title="查找system.replication_queue"></a>查找system.replication_queue</h3><ul><li>表介绍<br><a href="https://clickhouse.com/docs/en/operations/system-tables/replication_queue/" target="_blank" rel="noopener">链接地址</a>包含了所有<code>ReplicatedMergeTree</code>复制表家族在<code>zookeeper</code>上存储的副本任务队列的相关信息。</li><li><p>列信息</p><ul><li>database (String) — 数据库名称.</li><li>table (String) — 表名称.</li><li>replica_name (String) — zookeeper上副本名称，同表不同副本有不同名字.</li><li>position (UInt32) — 当前任务队列的位置.</li><li>node_name (String) — ZooKeeper上节点名称.</li><li>type (String) — 任务队列的名称，分别是:<ul><li>GET_PART — 从另一个副本拿到part.</li><li>ATTACH_PART — 加载part, 有可能来自我们自己的副本 (如果是在detached目录上发现). 您可以认为它是带有一些优化的GET_PART，因为他们接近相似.</li><li>MERGE_PARTS — 合并part.</li><li>DROP_RANGE — 删除指定范围内的指定分区列表.</li><li>CLEAR_COLUMN — 注意：从指定分区删除特殊列（已弃用）.</li><li>CLEAR_INDEX — 注意：从指定分区删除指定索引（已弃用）.</li><li>REPLACE_RANGE — 删除一定范围内的part，并用新part替换.</li><li>MUTATE_PART — 对part应用用一个或多个mutation.</li><li>ALTER_METADATA — 根据/metadata和/columns路径应用alter修改.</li></ul></li><li>create_time (Datetime) — 任务被提交执行后的时间.</li><li>required_quorum (UInt32) — 等待任务完成并且确认完成的副本数. 这个字段仅跟GET_PARTS任务相关.</li><li>source_replica (String) — 源副本的名称.</li><li>new_part_name (String) — 新part的名称.</li><li>parts_to_merge (Array (String)) — 要更新或者合并的part名称.</li><li>is_detach (UInt8) — DETACH_PARTS任务是否在任务队列里的标示位.</li><li>is_currently_executing (UInt8) — 当然任务是否正在执行的标示位.</li><li>num_tries (UInt32) — 尝试完成任务失败的次数.</li><li>last_exception (String) — 上次错误发生的详情.</li><li>last_attempt_time (Datetime) — 任务最后一次尝试的时间</li><li>num_postponed (UInt32) — 延期任务数.</li><li>postpone_reason (String) — 任务延期时间.</li><li>last_postpone_time (Datetime) — 任务上次延期的时间.</li><li>merge_type (String) — 当前合并的类型. 如果是mutation则为空.</li></ul></li><li><p>通过该表捞出zookeeper的节点副本信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select node_name from system.replication_queue where database &#x3D; &#39;xx&#39; and table &#x3D; &#39;xx&#39; and is_currently_executing &#x3D; 1</span><br></pre></td></tr></table></figure><h3 id="system-replcas"><a href="#system-replcas" class="headerlink" title="system.replcas"></a>system.replcas</h3></li></ul><h3 id="system-mutations"><a href="#system-mutations" class="headerlink" title="system.mutations"></a>system.mutations</h3><h3 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h3><p>+ </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pr
      
    
    </summary>
    
    
      <category term="bigdata" scheme="http://yoursite.com/categories/bigdata/"/>
    
    
      <category term="clickhouse" scheme="http://yoursite.com/tags/clickhouse/"/>
    
  </entry>
  
</feed>
