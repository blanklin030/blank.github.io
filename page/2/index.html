<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="say something about me">
<meta property="og:type" content="website">
<meta property="og:title" content="BlankLin">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="BlankLin">
<meta property="og:description" content="say something about me">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Blank Lin">
<meta property="article:tag" content="lazy and boring">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>BlankLin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="BlankLin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">BlankLin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">lazy and boring</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/16/linux-ln/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/16/linux-ln/" class="post-title-link" itemprop="url">聊聊linux下的软硬链接</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-16 15:48:18" itemprop="dateCreated datePublished" datetime="2022-02-16T15:48:18+08:00">2022-02-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sre/" itemprop="url" rel="index"><span itemprop="name">sre</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="链接概念"><a href="#链接概念" class="headerlink" title="链接概念"></a>链接概念</h3><p>Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。<br>默认情况下，ln命令产生硬链接。</p>
<h3 id="硬连接"><a href="#硬连接" class="headerlink" title="硬连接"></a>硬连接</h3><ul>
<li>硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。</li>
<li>硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。</li>
</ul>
<h3 id="软连接"><a href="#软连接" class="headerlink" title="软连接"></a>软连接</h3><p>另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#创建一个测试文件f1</span><br><span class="line">[oracle@Linux]$ touch f1</span><br><span class="line"></span><br><span class="line">#创建f1的一个硬连接文件f2</span><br><span class="line">[oracle@Linux]$ ln f1 f2</span><br><span class="line"></span><br><span class="line">#创建f1的一个符号连接文件f3</span><br><span class="line">[oracle@Linux]$ ln -s f1 f3</span><br><span class="line"></span><br><span class="line"># -i参数显示文件的inode节点信息</span><br><span class="line">[oracle@Linux]$ ls -li   </span><br><span class="line">total 0</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f1</span><br><span class="line">9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f2</span><br><span class="line">9797649 lrwxrwxrwx  1 oracle oinstall 2 Apr 21 08:11 f3 -&gt; f1</span><br></pre></td></tr></table></figure>
<p>从上面的结果中可以看出，硬连接文件f2与原文件f1的inode节点相同，均为9797648，然而符号连接文件的inode节点不同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 修改文件内容</span><br><span class="line">[oracle@Linux]$ echo &quot;I am f1 file&quot; &gt;&gt;f1</span><br><span class="line"></span><br><span class="line"># 打印f1文件内容</span><br><span class="line">[oracle@Linux]$ cat f1</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">I am f1 file</span><br><span class="line"># 删除f1</span><br><span class="line">[oracle@Linux]$ rm -f f1</span><br><span class="line"></span><br><span class="line"># 打印f2文件内容，未受到影响，所以硬链接未受源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f2</span><br><span class="line">I am f1 file</span><br><span class="line"></span><br><span class="line"># 打印f3文件内容，提示找不到该文件或者目录，所以软连接会受到源文件删除的影响</span><br><span class="line">[oracle@Linux]$ cat f3</span><br><span class="line">cat: f3: No such file or directory</span><br></pre></td></tr></table></figure>
<p>通过上面的测试可以看出：当删除原始文件f1后，硬连接f2不受影响，但是符号连接f1文件无效</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1).删除符号连接f3,对f1,f2无影响；<br>2).删除硬连接f2，对f1,f3也无影响；<br>3).删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效；<br>4).同时删除原文件f1,硬连接f2，整个文件会真正的被删除。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/15/linux-overlay-full/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/15/linux-overlay-full/" class="post-title-link" itemprop="url">由于overlay占用磁盘空间导致磁盘告警</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-15 15:09:08" itemprop="dateCreated datePublished" datetime="2022-02-15T15:09:08+08:00">2022-02-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sre/" itemprop="url" rel="index"><span itemprop="name">sre</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>早上突然收到告警短信，xxx服务磁盘使用率超过80%，如下图，赶紧上机器进行排查，下面是排查的过程<br><img src="/images/linux/disk_full/1.png" alt="avatar"></p>
<h3 id="查看机器整体磁盘使用情况"><a href="#查看机器整体磁盘使用情况" class="headerlink" title="查看机器整体磁盘使用情况"></a>查看机器整体磁盘使用情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 下面是结果</span><br><span class="line">root@xxx.docker.ys:~&#x2F;dlap-manager$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">overlay          20G   18G  2.7G  87% &#x2F;</span><br><span class="line">tmpfs            64M     0   64M   0% &#x2F;dev</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">&#x2F;dev&#x2F;sda3       219G   15G  193G   8% &#x2F;etc&#x2F;hosts</span><br><span class="line">shm              64M     0   64M   0% &#x2F;dev&#x2F;shm</span><br><span class="line">&#x2F;dev&#x2F;sdb1       4.4T  949G  3.5T  22% &#x2F;etc&#x2F;hostname</span><br><span class="line">tmpfs            63G   12K   63G   1% &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;acpi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;proc&#x2F;scsi</span><br><span class="line">tmpfs            63G     0   63G   0% &#x2F;sys&#x2F;firmware</span><br></pre></td></tr></table></figure>
<p>看到overlay这个文件目录占了<code>87%</code>，仔细研究下这个文件夹是什么</p>
<h4 id="overlay介绍"><a href="#overlay介绍" class="headerlink" title="overlay介绍"></a>overlay介绍</h4><p>OverlayFS是一种堆叠文件系统，它依赖并建立在其它的文件系统之上（例如ext4fs和xfs等等），并不直接参与磁盘空间结构的划分，仅仅将原来底层文件系统中不同的目录进行“合并”，然后向用户呈现，这也就是联合挂载技术，对比于AUFS，OverlayFS速度更快，实现更简单。 而Linux 内核为Docker提供的OverlayFS驱动有两种：overlay和overlay2。而overlay2是相对于overlay的一种改进，在inode利用率方面比overlay更有效。但是overlay有环境需求：docker版本17.06.02+，宿主机文件系统需要是ext4或xfs格式。<br>overlayfs通过三个目录：lower目录、upper目录、以及work目录实现，其中lower目录可以是多个，work目录为工作基础目录，挂载后内容会被清空，且在使用过程中其内容用户不可见，最后联合挂载完成给用户呈现的统一视图称为为merged目录<br><img src="/images/linux/disk_full/2.png" alt="avatar"><br>在上述图中可以看到三个层结构，即：lowerdir、uperdir、merged，其中lowerdir是只读的image layer，其实就是rootfs，对应的lowerdir是可以有多个目录。而upperdir则是在lowerdir之上的一层，这层是读写层，在启动一个容器时候会进行创建，所有的对容器数据更改都发生在这里层。最后merged目录是容器的挂载点，也就是给用户暴露的统一视角。</p>
<h4 id="overlay如何工作"><a href="#overlay如何工作" class="headerlink" title="overlay如何工作"></a>overlay如何工作</h4><p>当容器中发生数据修改时候overlayfs存储驱动又是如何进行工作的？以下将阐述其读写过程：</p>
<ul>
<li><ol>
<li>读：</li>
</ol>
<ul>
<li>如果文件在容器层（upperdir），直接读取文件；</li>
<li>如果文件不在容器层（upperdir），则从镜像层（lowerdir）读取；</li>
</ul>
</li>
<li><ol>
<li>写：</li>
</ol>
<ul>
<li>首次写入： 如果在upperdir中不存在，overlay和overlay2执行copy_up操作，把文件从lowdir拷贝到upperdir，由于overlayfs是文件级别的（即使文件只有很少的一点修改，也会产生的copy_up的行为），后续对同一文件的在此写入操作将对已经复制到容器的文件的副本进行操作。这也就是常常说的写时复制（copy-on-write）</li>
<li>删除文件和目录： 当文件在容器被删除时，在容器层（upperdir）创建whiteout文件，镜像层(lowerdir)的文件是不会被删除的，因为他们是只读的，但without文件会阻止他们显示，当目录在容器内被删除时，在容器层（upperdir）一个不透明的目录，这个和上面whiteout原理一样，阻止用户继续访问，即便镜像层仍然存在。 </li>
</ul>
</li>
<li><ol>
<li>注意事项</li>
</ol>
<ul>
<li>copy_up操作只发生在文件首次写入，以后都是只修改副本,</li>
<li>overlayfs只适用两层目录，相比于比AUFS，查找搜索都更快。</li>
<li>容器层的文件删除只是一个“障眼法”，是靠whiteout文件将其遮挡，image层并没有删除，这也就是为什么使用docker commit 提交保存的镜像会越来越大，无论在容器层怎么删除数据，image层都不会改变。</li>
</ul>
</li>
</ul>
<h4 id="overlay镜像存储结构"><a href="#overlay镜像存储结构" class="headerlink" title="overlay镜像存储结构"></a>overlay镜像存储结构</h4><p>从仓库拉取ubuntu镜像，结果显示总共拉取了6层镜像如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@bigdata-xxx.ys ~]$ sudo docker pull ubuntu-test:xenial</span><br><span class="line">Trying to pull repository ubuntu-test ...</span><br><span class="line">xenial: Pulling from ubuntu-test</span><br><span class="line">58690f9b18fc: Pull complete</span><br><span class="line">b51569e7c507: Pull complete</span><br><span class="line">da8ef40b9eca: Pull complete</span><br><span class="line">fb15d46c38dc: Pull complete</span><br><span class="line">4c7a0de79adc: Pull complete</span><br><span class="line">5eff12cba838: Pull complete</span><br><span class="line">Digest: sha256:d21c70f1203a5b0fe1d8a1b60bd1924ca5458ba450828f6b88c4e973db84c8e8</span><br><span class="line">Status: Downloaded newer image for ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>此时6层镜像被存储在/var/lib/docker/overlay2下，将镜像运行起来一个容器，如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -itd --name ubuntu-test ubuntu-test:xenial</span><br></pre></td></tr></table></figure><br>运行容器之后，查询出容器的元数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取容器ID</span><br><span class="line">sudo docker ps -a | grep ubuntu</span><br><span class="line">&#x2F;&#x2F; 通过容器ID查看元数据</span><br><span class="line">sudo docker inspect container-id</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/4.png" alt="avatar"></p>
<p>进入容器创建一个文件，如下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo docker exec -it ubuntu-test bash</span><br><span class="line">echo &#39;xxxxxx&#39; &gt; helloworld.txt</span><br></pre></td></tr></table></figure></p>
<p>通过tree命令查看新创建的文件出现在哪里<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree -L 3 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;f90282cedadf6b7765ba06ea8983af306f78773baeca9ff1e418651d0b9d14f2&#x2F;diff</span><br></pre></td></tr></table></figure><br><img src="/images/linux/disk_full/3.png" alt="avatar"></p>
<h3 id="回到问题本身"><a href="#回到问题本身" class="headerlink" title="回到问题本身"></a>回到问题本身</h3><p>overlay目录使用了87%的存储，触发了磁盘告警，overlay目录是我们的弹性云容器运行的目录，发现通过nohup启动的jar包将所有stdout/stderr都输出到了nohup.out文件，该文件也持久化存在/var/lib/docker/overlay2下，所以需要对nohup.out进行处理，不可直接删除，因为jar启动后所有的输出流都会转存到nohup.out，这个文件句柄已经打开，所有的stdout/stderr仍然会输出，只是输出在/proc/pid/fd/1或者/proc/pid/fd/2这些目录下。</p>
<blockquote>
<p>0描述符 标准输入<br>1描述符 标注输出<br>2描述符 标注错误输出  </p>
</blockquote>
<p><strong>linux一切到可以看作文件</strong>，/proc/pid/fd/1 就是pid进程的标准输出，/proc/pid/fd/1 就是pid进程的标准错误输出，我们通过测试可以看到下面结果，就算我们删除了nohup.out文件，任何会将stdout/stderro输出到这个文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@xxx.ys ~]$ tree -L 3 &#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">&#x2F;proc&#x2F;143645&#x2F;fd</span><br><span class="line">├── 0 -&gt; &#x2F;dev&#x2F;null</span><br><span class="line">├── 1 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">├── 2 -&gt; &#x2F;home&#x2F;hadoop&#x2F;nohup.out\ (deleted)</span><br><span class="line">└── 3 -&gt; &#x2F;home&#x2F;hadoop&#x2F;test.txt</span><br><span class="line"></span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure></p>
<ul>
<li><ol>
<li>重启jar包，将所有错误/标准输出忽略<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; &gt;&#x2F;dev&#x2F;null是表示linux的空设备，是一个特殊的文件，写入到它的内容都会被丢弃(等同于 1&gt;&#x2F;dev&#x2F;null)</span><br><span class="line">&#x2F;&#x2F; 2&gt;&amp;1表示所有错误输出都重定向到标准输出</span><br><span class="line">&#x2F;&#x2F; 所以就是将错误输出重定向到标准输出，将标准输出重定向到空设备，就是禁止所有输出&#x2F;错误</span><br><span class="line">nohup java -jar xx.jar &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>删除nohup.out文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f nohup.out</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h3 id="修改docker的根目录"><a href="#修改docker的根目录" class="headerlink" title="修改docker的根目录"></a>修改docker的根目录</h3><h4 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h4><ol>
<li>停止docker服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure></li>
<li><p>创建新的docker工作目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p &#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure>
<p>这个目录可以自定义，但是一定要保证在/root里面</p>
</li>
<li><p>迁移/var/lib/docker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -avz &#x2F;var&#x2F;lib&#x2F;docker &#x2F;data2&#x2F;docker&#x2F;</span><br></pre></td></tr></table></figure></li>
<li>配置devicemapper.conf<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 不存在就创建</span><br><span class="line">sudo mkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;</span><br><span class="line"># 不存在就创建</span><br><span class="line">sudo vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;devicemapper.conf</span><br></pre></td></tr></table></figure></li>
<li><p>在devicemapper.conf中添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd  --graph&#x3D;&#x2F;data2&#x2F;docker</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启docker服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"> </span><br><span class="line">systemctl restart docker</span><br><span class="line"> </span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure>
</li>
<li><p>确认是否配置成功</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure>
<p><img src="/images/linux/disk_full/5.png" alt="avatar"></p>
</li>
</ol>
<p>重新启动所有容器后，确认无误。即可删除/var/lib/docker里面所有文件。</p>
<h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>如果报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error response from daemon: Cannot restart container linyu: shim error: docker-runc not installed on system</span><br></pre></td></tr></table></figure></p>
<ul>
<li><ol>
<li>判断是否安装runc<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qi runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>未安装则先安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>创建软连接<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;libexec&#x2F;docker&#x2F;</span><br><span class="line">sudo ln -s docker-runc-current docker-runc</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>重启服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker restart container_id</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/03/clickhouse-crud/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/03/clickhouse-crud/" class="post-title-link" itemprop="url">使用clickhouse实现数据更新和删除</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-03 22:57:11" itemprop="dateCreated datePublished" datetime="2022-02-03T22:57:11+08:00">2022-02-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="什么是CRUD"><a href="#什么是CRUD" class="headerlink" title="什么是CRUD"></a>什么是CRUD</h3><blockquote>
<p><code>CRUD</code>是指在做计算处理时的增加(<code>Create</code>)、检索(<code>Retrieve</code>)、更新(<code>Update</code>)和删除(<code>Delete</code>)几个单词的首字母简写。<code>crud</code>主要被用在描述软件系统中数据库或者持久层的基本操作功能</p>
</blockquote>
<h3 id="clickhouse物理上的crud"><a href="#clickhouse物理上的crud" class="headerlink" title="clickhouse物理上的crud"></a>clickhouse物理上的crud</h3><ul>
<li><ol>
<li>create创建表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create table account(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  is_delete UInt8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; MergeTree </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure>
<img src="/images/clickhouse/crud/5.png" alt="avatar"></li>
</ol>
</li>
<li><ol>
<li>insert写入数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.account(time, name, alias, age, version, is_delete) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 0)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>写入数据后会按照partitionby生成对应的分区part目录<br><img src="/images/clickhouse/crud/6.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>update更新<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table default.account</span><br><span class="line">update alias &#x3D; &#39;super_hero&#39;</span><br><span class="line">where alias &#x3D; &#39;superhero&#39;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/4.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>delete删除<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table delete where id &#x3D; 1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里是 mutation 操作,会生成一个mutation_version.txt<br><img src="/images/clickhouse/crud/7.png" alt="avatar"></p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>retrieve检索<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, is_delete from account where is_delete &#x3D; 0 order by version desc</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><ol>
<li>可以通过system.mutations查询执行计划<br><img src="/images/clickhouse/crud/9.png" alt="avatar"><br>当mutation操作执行完成后，system.mutations表中对应的mutation记录中is_done字段的值会变为1。</li>
</ol>
</li>
<li><ol>
<li>可以通过system.parts查询执行结果<br><img src="/images/clickhouse/crud/8.png" alt="avatar"><br>当旧的数据片段移除后，system.parts表中旧数据片段对应的记录会被移除。</li>
</ol>
</li>
</ul>
<blockquote>
<p>可以看到mutation操作完成后，之前的目录已经被删除<br><img src="/images/clickhouse/crud/10.png" alt="avatar"></p>
</blockquote>
<h3 id="clickhouse的mutation是什么"><a href="#clickhouse的mutation是什么" class="headerlink" title="clickhouse的mutation是什么"></a>clickhouse的mutation是什么</h3><h4 id="官方文档解释"><a href="#官方文档解释" class="headerlink" title="官方文档解释"></a>官方文档解释</h4><p>从官方对于mutaiton的解释<a href="https://clickhouse.com/docs/zh/sql-reference/statements/alter/#alter-mutations" target="_blank" rel="noopener">链接</a>中，我们需要注意到几个关键词，如下</p>
<ul>
<li><ol>
<li>manipulate table data<br>操作表数据</li>
</ol>
</li>
<li><ol>
<li>asynchronous background processes<br>异步后台处理</li>
</ol>
</li>
<li><ol>
<li>rewriting whole data parts<br>重写全部数据part</li>
</ol>
</li>
<li><ol>
<li>a SELECT query that started executing during a mutation will see data from parts that have already been mutated along with data from parts that have not been mutated yet<br>在突变期间的查询语句，将看到已经完成突变的数据part和还未发生突变的part</li>
</ol>
</li>
<li><ol>
<li>data that was inserted into the table before the mutation was submitted will be mutated and data that was inserted after that will not be mutated<br>在提交突变之前插入表中的数据将被突变，而在此之后插入的数据将不会被突变</li>
</ol>
</li>
<li><ol>
<li>There is no way to roll back the mutation once it is submitted, but if the mutation is stuck for some reason it can be cancelled with the KILL MUTATION query<br>突变一旦被提交就没有方式可以回滚，但是如果突变由于一些原因被卡住，可以使用<code>KILL MUTATION</code>取消突变</li>
</ol>
</li>
</ul>
<h4 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h4><p>当用户执行一个如上的Mutation操作获得返回时，ClickHouse内核其实只做了两件事情：<br><img src="/images/clickhouse/crud/1.png" alt="avatar"></p>
<ul>
<li><ol>
<li>检查Mutation操作是否合法；<blockquote>
<p>主体逻辑在MutationsInterpreter::validate函数</p>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>保存Mutation命令到存储文件中，唤醒一个异步处理merge和mutation的工作线程；<blockquote>
<p>主体逻辑在StorageMergeTree::mutate函数中。</p>
</blockquote>
</li>
</ol>
</li>
</ul>
<p>Merge逻辑<br><strong>StorageMergeTree::merge</strong>函数是<code>MergeTree</code>异步<code>Merge</code>的核心逻辑，<code>Data Part Merge</code>的工作除了通过后台工作线程自动完成，用户还可以通过<code>Optimize</code>命令来手动触发。自动触发的场景中，系统会根据后台空闲线程的数据来启发式地决定本次<code>Merge</code>最大可以处理的数据量大小，<strong>max_bytes_to_merge_at_min_space_in_pool</strong>: 决定当空闲线程数最大时可处理的数据量上限（默认150GB）<br><strong>max_bytes_to_merge_at_max_space_in_pool</strong>: 决定只剩下一个空闲线程时可处理的数据量上限（默认1MB）<br>当用户的写入量非常大的时候，应该适当调整工作线程池的大小和这两个参数。当用户手动触发<code>merge</code>时，系统则是根据<code>disk</code>剩余容量来决定可处理的最大数据量。</p>
<p>Mutation逻辑<br>系统每次都只会订正一个<code>Data Part</code>，但是会聚合多个<code>mutation</code>任务批量完成，这点实现非常的棒。因为在用户真实业务场景中一次数据订正逻辑中可能会包含多个<code>Mutation</code>命令，把这多个<code>mutation</code>操作聚合到一起订正效率上就非常高。系统每次选择一个排序键最小的并且需要订正<code>Data Part</code>进行操作，本意上就是把数据从前往后进行依次订正。<br><img src="/images/clickhouse/crud/11.png" alt="avatar"><br><img src="/images/clickhouse/crud/13.png" alt="avatar"><br><img src="/images/clickhouse/crud/12.png" alt="avatar"></p>
<p>mutation和merge相互独立执行。看完本文前面的分析，大家应该也注意到了目前Data Part的merge和mutation是相互独立执行的，Data Part在同一时刻只能是在merge或者mutation操作中。对于MergeTree这种存储彻底Immutable的设计，数据频繁merge、mutation会引入巨大的IO负载。实时上merge和mutation操作是可以合并到一起去考虑的，这样可以省去数据一次读写盘的开销。对数据写入压力很大又有频繁mutation的场景，会有很大帮助</p>
<h3 id="clickhouse逻辑CRUD"><a href="#clickhouse逻辑CRUD" class="headerlink" title="clickhouse逻辑CRUD"></a>clickhouse逻辑CRUD</h3><p><a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/versionedcollapsingmergetree/" target="_blank" rel="noopener">VersionedCollapsingMergeTree介绍</a>，引擎继承自 <code>MergeTree</code> 并将折叠行的逻辑添加到合并数据部分的算法中。 <code>VersionedCollapsingMergeTree</code> 用于相同的目的 折叠树 但使用不同的折叠算法，允许以多个线程的任何顺序插入数据。 特别是， <code>Version</code> 列有助于正确折叠行，即使它们以错误的顺序插入。 相比之下, <code>CollapsingMergeTree</code> 只允许严格连续插入。</p>
<h4 id="创建VersionedCollapsingMergeTree表"><a href="#创建VersionedCollapsingMergeTree表" class="headerlink" title="创建VersionedCollapsingMergeTree表"></a>创建VersionedCollapsingMergeTree表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create table test_version_collapsing(</span><br><span class="line">  time DateTime default now() comment &#39;创建时间&#39;,</span><br><span class="line">  name String default &#39;&#39; comment &#39;唯一标示&#39;,</span><br><span class="line">  alias String default &#39;&#39; comment &#39;别名&#39;,</span><br><span class="line">  age UInt64 default 0 comment &#39;年龄&#39;,</span><br><span class="line">  version UInt64 default 0 comment &#39;版本号&#39;,</span><br><span class="line">  sign Int8 default 0 comment &#39;是否删除，0否，1是&#39;</span><br><span class="line">) </span><br><span class="line">engine &#x3D; VersionedCollapsingMergeTree(sign, version) </span><br><span class="line">partition by toYYYYMMDD(time) </span><br><span class="line">order by name</span><br></pre></td></tr></table></figure>
<h4 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, 1)</span><br></pre></td></tr></table></figure>
<h4 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h4><ul>
<li><ol>
<li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>假设要更新alias=update_super_hero，其他值不变，将version由1.捞出的值上+1，类似以下sql<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 先将旧行标示为删除，就是将sign &#x3D; -1</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;superhero&#39;, 20, 1, -1);</span><br><span class="line"></span><br><span class="line"># 再去插入新行，包含要更新的列</span><br><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, 1).</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h4 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h4><ul>
<li><ol>
<li>先找出要更新的这条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select time, name, alias, age, version, sign from default.test_version_collapsing</span><br><span class="line">where name &#x3D; &#39;blanklin&#39; and sign &#x3D; 1</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>假设要删除alias=update_super_hero，其他值不变，将sign=1,类似以下sql<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.test_version_collapsing(time, name, alias, age, version, sign) values (&#39;2022-01-01 11:11:11&#39;, &#39;blanklin&#39;, &#39;update_superhero&#39;, 20, 2, -1)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>捞出更新后的那条数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name, argMax(age, version), argMax(alias, version) from default.test_version_collapsing group by name having sum(sign) &gt; 0;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h4 id="注意项"><a href="#注意项" class="headerlink" title="注意项"></a>注意项</h4><ul>
<li><ol>
<li>只有相同分区内的数据才能删除和更新</li>
</ol>
</li>
<li><ol>
<li>如果不使用 <strong>having sum(sign) &gt; 0</strong>的方式去查询，则可以使用<code>final</code>方式查询<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from test_version_collapsing final;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>也可以使用<code>optimize</code>方式强制合并分区，再查询，但是这个方式可能会造成集群cpu飙高，而且<code>optimize</code>一个大表需要时间很长，效率极低<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimize table test_version_collapsing final</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><ol>
<li>sign必须要唯一，添加用1，则删除一定是-1，才可以被折叠处理</li>
</ol>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/21/clickhouse-ddl-on-cluster/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/21/clickhouse-ddl-on-cluster/" class="post-title-link" itemprop="url">clickhouse query on cluster源码解读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-21 15:04:11" itemprop="dateCreated datePublished" datetime="2022-01-21T15:04:11+08:00">2022-01-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="分布式DDL执行链路"><a href="#分布式DDL执行链路" class="headerlink" title="分布式DDL执行链路"></a>分布式DDL执行链路</h3><blockquote>
<p>在介绍具体的分布式<code>DDL</code>执行链路之前，先为大家梳理一下哪些操作是可以走分布式<code>DDL</code>执行链路的，大家也可以自己在源码中查看一下<code>ASTQueryWithOnCluster</code>的继承类有哪些：<br><img src="/images/clickhouse/ddloncluster/1.png" alt="cgi">  </p>
</blockquote>
<ul>
<li>ASTAlterQuery：<br>包括<code>ATTACH_PARTITION</code>、<code>FETCH_PARTITION</code>、<code>FREEZE_PARTITION</code>、<code>FREEZE_ALL</code>等操作（对表的数据分区粒度进行操作）。</li>
<li>ASTCreateQuery：<br>包括常见的建库、建表、建视图，还有<code>ClickHouse</code>独有的<code>Attach Table</code>（可以从存储文件中直接加载一个之前卸载的数据表）。</li>
<li>ASTCreateQuotaQuery:<br>包括对租户的配额操作语句，例如<code>create quaota</code>，或者<code>alter quota</code>语句</li>
<li>ASTCreateRoleQuery：<br>包括对租户角色操作语句，例如<code>create/alter/drop/set/set default/show create role</code>语句，或者<code>show roles</code></li>
<li>ASTCreateRowPolicyQuery<br>对表的查询做行级别的策略限制，例如<code>create row policy</code> 或者 <code>alter row policy</code></li>
<li>ASTCreateSettingsProfileQuery<br>对角色或者租户的资源限制和约束，例如<code>create settings profile</code> 或者 <code>alter settings profile</code></li>
<li>ASTCreateUserQuery<br>对租户的操作语句，例如<code>create create user</code> 或者 <code>alter create user</code></li>
<li>ASTDropAccessEntityQuery<br>涉及到了clickhouse权限相关的所有删除语句，包括<code>DROP USER</code>,<code>DROP ROLE</code>,<code>DROP QUOTA</code>,<code>DROP [ROW] POLICY</code>,<code>DROP [SETTINGS] PROFILE</code></li>
<li>ASTDropQuery：<br>其中包含了三种不同的删除操作（<code>Drop</code> / <code>Truncate</code> / <code>Detach</code>），<code>Detach Table</code>和<code>Attach Table</code>对应，它是表的卸载动作，把表的存储目录整个移到专门的<code>detach</code>文件夹下，然后关闭表在节点<code>RAM</code>中的”引用”，这张表在节点中不再可见。</li>
<li>ASTGrantQuery:<br>这是授权相关的<code>RBAC</code>，可以对库/表授予或者撤销读/写等权限命令，例如<code>GRANT insert on db.tb to acount</code>，或者<code>REVOKE all on db.tb from account</code>。</li>
<li>ASTKillQueryQuery：<br>可以<code>Kill</code>正在运行的<code>Query</code>，也可以<code>Kill</code>之前发送的<code>Mutation</code>命令。</li>
<li>ASTOptimizeQuery：<br>这是<code>MergeTree</code>表引擎特有的操作命令，它可以手动触发<code>MergeTree</code>表的合并动作，并可以强制数据分区下的所有<code>Data Part</code>合并成一个。</li>
<li>ASTRenameQuery：<br>修改表名，可更改到不同库下。</li>
</ul>
<h3 id="DDL-Query-Task分发"><a href="#DDL-Query-Task分发" class="headerlink" title="DDL Query Task分发"></a>DDL Query Task分发</h3><p><img src="/images/clickhouse/ddloncluster/2.png" alt="cgi"><br><code>ClickHouse</code>内核对每种<code>SQL</code>操作都有对应的<code>IInterpreter</code>实现类，其中的<code>execute</code>方法负责具体的操作逻辑。而以上列举的<code>ASTQuery</code>对应的<code>IInterpreter</code>实现类中的<code>execute</code>方法都加入了分布式<code>DDL</code>执行判断逻辑，把所有分布式<code>DDL</code>执行链路统一都<code>DDLWorker::executeDDLQueryOnCluster</code>方法中。<br><code>executeDDLQueryOnCluster</code>的过程大致可以分为三个步骤：</p>
<h4 id="检查DDLQuery的合法性，"><a href="#检查DDLQuery的合法性，" class="headerlink" title="检查DDLQuery的合法性，"></a>检查<code>DDLQuery</code>的合法性，</h4><ul>
<li>1、校验query规则<br><img src="/images/clickhouse/ddloncluster/3.png" alt="cgi"></li>
<li>2、初始化DDLWorker，取config.xml表的配置<br><img src="/images/clickhouse/ddloncluster/4.png" alt="cgi"></li>
<li>3、替换query里的数据库名称<br><img src="/images/clickhouse/ddloncluster/5.png" alt="cgi"><br>这里替换库名的逻辑是，</li>
<li>3.1、如果query里有带上库名称，则直接使用，若无，则走2</li>
<li>3.2、metrika.xml里配置了shard的默认库<code>&lt;default_database&gt;default&lt;/default_database&gt;</code>，则使用默认库，否则走3</li>
<li>3.3、使用当前session的database<br><img src="/images/clickhouse/ddloncluster/6.png" alt="cgi"></li>
</ul>
<h4 id="把DDLQuery写入到Zookeeper任务队列中"><a href="#把DDLQuery写入到Zookeeper任务队列中" class="headerlink" title="把DDLQuery写入到Zookeeper任务队列中"></a>把<code>DDLQuery</code>写入到<code>Zookeeper</code>任务队列中</h4><ul>
<li>1、构造DDLLogEntry对象，把entry对象加入到queue队列中<br><img src="/images/clickhouse/ddloncluster/7.png" alt="cgi"><br>注意：queue_dir是由<strong>config.xml</strong>配置的，如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;distributed_ddl&gt;</span><br><span class="line">    &lt;path&gt;&#x2F;clickhouse&#x2F;task_queue&#x2F;ddl&lt;&#x2F;path&gt;</span><br><span class="line">&lt;&#x2F;distributed_ddl&gt;</span><br></pre></td></tr></table></figure></li>
<li>2、去zookeeper执行创建znode，把entry序列化存入znode<br><img src="/images/clickhouse/ddloncluster/8.png" alt="cgi"></li>
<li>3、在znode下创建active和finished的znode<br><img src="/images/clickhouse/ddloncluster/9.png" alt="cgi"><blockquote>
<p>下面截图为query-xxx的记录的entry内容<br><img src="/images/clickhouse/ddloncluster/10.png" alt="cgi"></p>
</blockquote>
</li>
</ul>
<h4 id="等待Zookeeper任务队列的反馈把结果返回给用户。"><a href="#等待Zookeeper任务队列的反馈把结果返回给用户。" class="headerlink" title="等待Zookeeper任务队列的反馈把结果返回给用户。"></a>等待<code>Zookeeper</code>任务队列的反馈把结果返回给用户。</h4><p><img src="/images/clickhouse/ddloncluster/11.png" alt="cgi"></p>
<h4 id="DDL-Query-Task执行线程"><a href="#DDL-Query-Task执行线程" class="headerlink" title="DDL Query Task执行线程"></a>DDL Query Task执行线程</h4><ul>
<li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li>
<li>2、执行线程加入到线程池后，执行ddl task<br><img src="/images/clickhouse/ddloncluster/13.png" alt="cgi"></li>
<li>3、过滤掉 query 中带有 on cluster xxx的语句，根据不同的query选择不同执行方式<br><img src="/images/clickhouse/ddloncluster/14.png" alt="cgi"></li>
<li>4、alter、optimize、truncate语句需要在leader节点执行<br><img src="/images/clickhouse/ddloncluster/15.png" alt="cgi"><blockquote>
<p>注意：Replcated表的alter、optimize、truncate这些query是会先判断是否leader节点，不是则不处理，在执行时，会先给zookeeper加一个分布式锁，锁住这个任务防止被修改，执行时都是把自己的host:port注册到znode/query-xxx/active下，执行完成后，结果写到znode/query-xxx/finished下。</p>
</blockquote>
</li>
</ul>
<h4 id="DDL-Query-Task清理线程"><a href="#DDL-Query-Task清理线程" class="headerlink" title="DDL Query Task清理线程"></a>DDL Query Task清理线程</h4><ul>
<li>1、DDLWorker构造函数去取了config.xml配置，并且开启了2个线程，分别是执行线程和清理线程<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></li>
<li>2、执行清理逻辑，每次执行后，下一次执行需要过1分钟后才可以接着做清理<br><img src="/images/clickhouse/ddloncluster/16.png" alt="cgi"></li>
</ul>
<h3 id="分布式DDL的执行链路总结"><a href="#分布式DDL的执行链路总结" class="headerlink" title="分布式DDL的执行链路总结"></a>分布式DDL的执行链路总结</h3><ul>
<li><p>1）节点收到用户的分布式<code>DDL</code>请求</p>
</li>
<li><p>2）节点校验分布式DDL请求合法性，在<code>Zookeeper</code>的任务队列中创建<code>Znode</code>并上传<strong>DDL LogEntry（query-xxxx）</strong>，同时在<code>LogEntry</code>的<code>Znode</code>下创建<code>active</code>和<code>finish</code>两个状态同步的<code>Znode</code></p>
</li>
<li><p>3）<code>Cluster</code>中的节点后台线程消费<code>Zookeeper</code>中的<code>LogEntry</code>队列执行处理逻辑，处理过程中把自己注册到<code>acitve Znode</code>下，并把处理结果写回到<code>finish Znode</code>下<br><img src="/images/clickhouse/ddloncluster/12.png" alt="cgi"></p>
</li>
<li><p>4）用户的原始请求节点，不断轮询<code>LogEntry Znode</code>下的<code>active</code>和<code>finish</code>状态<code>Znode</code>，当目标节点全部执行完成任务或者触发超时逻辑时，用户就会获得结果反馈</p>
</li>
</ul>
<p>这个分发逻辑中有个值得注意的点：分布式<code>DDL</code>执行链路中有超时逻辑，如果触发超时用户将无法从客户端返回中确定最终执行结果，需要自己去<code>Zookeeper</code>上<code>check</code>节点返回结果（也可以通过<strong>system.zookeeper</strong>系统表查看）。<strong>每个节点只有一个后台线程在消费执行DDL任务</strong>，碰到某个DDL任务（典型的是optimize任务）执行时间很长时，会导致DDL任务队列积压从而产生大面积的超时反馈。</p>
<p>可以看出Zookeeper在分布式DDL执行过程中主要充当DDL Task的分发、串行化执行、结果收集的一致性介质。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/19/java_full_gc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/19/java_full_gc/" class="post-title-link" itemprop="url">记一次线上fgc排查过程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-19 19:04:11" itemprop="dateCreated datePublished" datetime="2022-01-19T19:04:11+08:00">2022-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sre/" itemprop="url" rel="index"><span itemprop="name">sre</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>用户反馈api请求时快时慢，慢的时候网页打开很久都没有结果，直到超时给出500错误</p>
<h3 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h3><h4 id="初步怀疑"><a href="#初步怀疑" class="headerlink" title="初步怀疑"></a>初步怀疑</h4><p>当前程序分布式部署在多个节点上，通过<code>vip</code>进行负载均衡，所以对于直接将反馈慢的页面打开的请求通过<code>curl</code>方式登陆生产环境所有节点，进行轮训一遍，发现其中02节点需要等待很久，其他节点均正常，所以问题应该出在02节点，<br>注意：这个定位过程当然也可以使用监控图就一目了然了。推荐使用<code>grafana prometheus spring boot dashboard</code>在<code>google</code>搜寻下相关配置就可以了。<br><img src="/images/java/fgc/8.png" alt="cgi"></p>
<h4 id="查询该节点负载"><a href="#查询该节点负载" class="headerlink" title="查询该节点负载"></a>查询该节点负载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 得到进程的pid</span><br><span class="line">jps -mlv </span><br><span class="line"># 通过top命令查询节点实际负载</span><br><span class="line">top -Hp pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/1.png" alt="cgi"></p>
<blockquote>
<p>通过top命令发现该节点memory使用了接近<code>90%</code>，怀疑出现内存泄露</p>
</blockquote>
<h4 id="查询该节点内存使用情况"><a href="#查询该节点内存使用情况" class="headerlink" title="查询该节点内存使用情况"></a>查询该节点内存使用情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstat -gcutil pid 1000</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/2.png" alt="cgi"></p>
<blockquote>
<p>如我所料，几乎不到<code>1s</code>就开始做一次<code>fgc</code>，所以服务才越来越慢响应</p>
</blockquote>
<h3 id="内存分析"><a href="#内存分析" class="headerlink" title="内存分析"></a>内存分析</h3><h4 id="使用jmap分析内存概要"><a href="#使用jmap分析内存概要" class="headerlink" title="使用jmap分析内存概要"></a>使用jmap分析内存概要</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -heap pid ｜ head -n20</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/10.png" alt="cgi"></p>
<h4 id="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"><a href="#使用jmap打印堆内存的对象，带上live，则只统计活着的对象" class="headerlink" title="使用jmap打印堆内存的对象，带上live，则只统计活着的对象"></a>使用jmap打印堆内存的对象，带上live，则只统计活着的对象</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jmap -histo pid ｜ head -n20</span><br><span class="line">jmap -histo:live pid ｜ head -n20</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/11.png" alt="cgi"></p>
<h4 id="打印进程的内存使用情况"><a href="#打印进程的内存使用情况" class="headerlink" title="打印进程的内存使用情况"></a>打印进程的内存使用情况</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -dump:format&#x3D;b,file&#x3D;dumpFileName pid</span><br></pre></td></tr></table></figure>
<p><img src="/images/java/fgc/3.png" alt="cgi"></p>
<blockquote>
<p>dump出来了<code>12G</code>的文件，通过scp工具转存到本地</p>
</blockquote>
<h4 id="jprofiler分析堆内存"><a href="#jprofiler分析堆内存" class="headerlink" title="jprofiler分析堆内存"></a>jprofiler分析堆内存</h4><ul>
<li>1、把dumpFileName文件转存为.hprof格式后直接双击打开，按照instance count逆序排列<br><img src="/images/java/fgc/5.png" alt="cgi"></li>
<li>2、会发现有hashmap类型占了最大头，但是这个类型，双击它，选择<code>merged incoming reference</code>，查看合并后的来源引用统计<br><img src="/images/java/fgc/6.png" alt="cgi"></li>
<li>3、还是选最大头的文件数一直拆到最里层，找出来源引用是<code>org.apache.ibatis.executor.result.DefaultResultHandler</code>这个类，基本能定位到问题根源了，是我们连接<code>clickhouse</code>客户端去查询结果时，未对结果集做限制，导致了一个很大的结果集返回到内存中。<br><img src="/images/java/fgc/7.png" alt="cgi"></li>
</ul>
<h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>当然是对结果集做限制，检测用户输入的sql，是否包含limit条数限制，若未限制，则对sql进行改写，增加<code>500</code>条数限制<br><img src="/images/java/fgc/9.png" alt="cgi"></p>
<h3 id="GC的运行原理"><a href="#GC的运行原理" class="headerlink" title="GC的运行原理"></a>GC的运行原理</h3><p><code>GC</code>（<code>garbage collection</code>）：垃圾回收，主要是指<code>YGC</code>和<code>FGC</code><br><code>YGC</code>（minor garbage collection）：新生代垃圾回收<br><code>FGC</code>（major garbage collection）：老年代垃圾回收</p>
<h4 id="堆内存结构"><a href="#堆内存结构" class="headerlink" title="堆内存结构"></a>堆内存结构</h4><p><img src="/images/java/fgc/12.png" alt="cgi"><br>堆内存采用了分代结构，包括新生代和老年代，新生代分为：<code>eden</code>区、<code>from survivor</code>区（简称<code>s0</code>）、<code>to survivor</code>区（简称<code>s1</code>），三者默认比例上8:1:1，另外新生代和老年代的比例则是1:2。<br>堆内存之所以采用分代结构，是因为绝大多数对象都是短生命周期的，这样设计可以把不同的生命周期的对象放在不同的区域中，然后针对新生代和老年代采用不同的垃圾回收算法，从而使得<code>GC</code>效率最高。</p>
<h4 id="YGC是什么时候触发的？"><a href="#YGC是什么时候触发的？" class="headerlink" title="YGC是什么时候触发的？"></a>YGC是什么时候触发的？</h4><p>大多数情况下，对象直接在年轻代中的<code>Eden</code>区进行分配，如果<code>Eden</code>区域没有足够的空间，那么就会触发<code>YGC</code>（<code>Minor GC</code>），<code>YGC</code>处理的区域只有新生代。因为大部分对象在短时间内都是可收回掉的，因此YGC后只有极少数的对象能存活下来，而被移动到S0区（采用的是复制算法）。<br>当触发下一次YGC时，会将Eden区和S0区的存活对象移动到S1区，同时清空Eden区和S0区。当再次触发YGC时，这时候处理的区域就变成了Eden区和S1区（即S0和S1进行角色交换）。每经过一次YGC，存活对象的年龄就会加1。</p>
<h4 id="FGC是什么时候触发的？"><a href="#FGC是什么时候触发的？" class="headerlink" title="FGC是什么时候触发的？"></a>FGC是什么时候触发的？</h4><ul>
<li><p>1、<code>YGC</code>时，<code>To Survivor</code>区不足以存放存活的对象，对象会直接进入到老年代。经过多次<code>YGC</code>后，如果存活对象的年龄达到了设定阈值，则会晋升到老年代中。动态年龄判定规则，<code>To Survivor</code>区中相同年龄的对象，如果其大小之和占到了 <code>To Survivor</code> 区一半以上的空间，那么大于此年龄的对象会直接进入老年代，而不需要达到默认的分代年龄。大对象：由<code>-XX:PretenureSizeThreshold</code>启动参数控制，若对象大小大于此值，就会绕过新生代, 直接在老年代中分配。当晋升到老年代的对象大于了老年代的剩余空间时，就会触发<code>FGC</code>（<code>Major GC</code>），<code>FGC</code>处理的区域同时包括新生代和老年代。老年代的内存使用率达到了一定阈值（可通过参数调整），直接触发<code>FGC</code>。</p>
</li>
<li><p>2、空间分配担保：在<code>YGC</code>之前，会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，说明<code>YGC</code>是不安全的，则会查看参数 <code>HandlePromotionFailure</code> 是否被设置成了允许担保失败，如果不允许则直接触发<code>Full GC</code>；如果允许，那么会进一步检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于也会触发 <code>Full GC</code>。</p>
</li>
<li><p>3、<code>Metaspace</code>（元空间）在空间不足时会进行扩容，当扩容到了<code>-XX:MetaspaceSize</code> 参数的指定值时，也会触发<code>FGC</code>。</p>
</li>
<li><p>4、<code>System.gc</code>() 或者<code>Runtime.gc</code>() 被显式调用时，触发<code>FGC</code>。</p>
</li>
</ul>
<h4 id="GC对程序会产生什么影响"><a href="#GC对程序会产生什么影响" class="headerlink" title="GC对程序会产生什么影响"></a>GC对程序会产生什么影响</h4><p>不管是YGC还是FGC，都会造成一定程度上的程序卡顿（stop the world问题：GC线程开始工作，其他工作线程被挂起），即使采用ParNew、CMS、G1这些更先进的垃圾回收算法，也只是减少卡顿的时间，并不能完全消除卡顿</p>
<ul>
<li>FGC过于频繁：<br>FGC通常是比较慢的，少则几百号秒，多则几秒，正常情况下FGC每隔几个小时或者几天才会执行一次，对系统的影响是可接受的，所以一旦出现FGC频繁（比如几分钟/几十分钟出现一次）会导致工作线程频繁被停掉，让系统看起来就一直卡顿，使得程序的整体性能变差。</li>
<li>YGC耗时过长：<br>一般来说YGC的总耗时指需要几十毫秒或上百毫秒，对于系统来说几乎无感知，所以如果YGC耗时达到1秒甚至几秒（快赶上FGC的耗时），那么卡顿就会加剧，加上YGC本身会比较频繁发生，就可能导致服务响应时间超时。</li>
<li>FGC耗时过长：<br>FGC耗时增加，卡顿时间也会随之增加，尤其对于高并发服务，可能导致FGC期间比较多的超时问题，可用性降低，这种也需要关注</li>
<li>YGC过于频繁：<br>即使YGC不会引起服务超时，但是YGC过于频繁也会降低服务的整体性能，对于高并发服务也是需要关注的。</li>
</ul>
<blockquote>
<p>其中，「FGC过于频繁」和「YGC耗时过长」，这两种情况属于比较典型的GC问题，大概率会对程序的服务质量产生影响。剩余两种情况的严重程度低一些，但是对于高并发或者高可用的程序也需要关注。</p>
</blockquote>
<h4 id="导致FGC的原因总结"><a href="#导致FGC的原因总结" class="headerlink" title="导致FGC的原因总结"></a>导致FGC的原因总结</h4><ul>
<li>大对象：系统一次性加载了过多数据到内存中（比如SQL查询未做分页），导致大对象进入了老年代。（即本文中的案例）</li>
<li>内存泄漏：频繁创建了大量对象，但是无法被回收（比如IO对象使用完后未调用close方法释放资源），先引发FGC，最后导致OOM.</li>
<li>程序频繁生成一些长生命周期的对象，当这些对象的存活年龄超过分代年龄时便会进入老年代，最后引发FGC. </li>
<li>程序BUG导致动态生成了很多新类，使得 Metaspace 不断被占用，先引发FGC，最后导致OOM.</li>
<li>代码中显式调用了gc方法，包括自己的代码甚至框架中的代码。</li>
<li>JVM参数设置问题：包括总内存大小、新生代和老年代的大小、Eden区和S区的大小、元空间大小、垃圾回收算法等等。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/19/linux_min_free_kbytes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/19/linux_min_free_kbytes/" class="post-title-link" itemprop="url">记一次线上core dump</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-19 19:04:11" itemprop="dateCreated datePublished" datetime="2022-01-19T19:04:11+08:00">2022-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:41:13" itemprop="dateModified" datetime="2022-08-22T18:41:13+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sre/" itemprop="url" rel="index"><span itemprop="name">sre</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>官方解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">min_free_kbytes:</span><br><span class="line">This is used to force the Linux VM to keep a minimum number</span><br><span class="line">of kilobytes free.  The VM uses this number to compute a</span><br><span class="line">watermark[WMARK_MIN] value for each lowmem zone in the system.</span><br><span class="line">Each lowmem zone gets a number of reserved free pages based</span><br><span class="line">proportionally on its size.</span><br><span class="line">Some minimal amount of memory is needed to satisfy PF_MEMALLOC</span><br><span class="line">allocations; if you set this to lower than 1024KB, your system will</span><br><span class="line">become subtly broken, and prone to deadlock under high loads.</span><br><span class="line">Setting this too high will OOM your machine instantly.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 3145728 &gt;&gt; &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;min_free_kbytes</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -a | grep min_free</span><br></pre></td></tr></table></figure>
<p><img src="/images/min_free_kbytes/2.png" alt="docker-bridge"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -a | grep oom</span><br></pre></td></tr></table></figure>
<p><img src="/images/min_free_kbytes/1.png" alt="docker-bridge"></p>
<p>min_free_kbytes大小的影响<br>min_free_kbytes设的越大，watermark的线越高，同时三个线之间的buffer量也相应会增加。这意味着会较早的启动kswapd进行回收，且会回收上来较多的内存（直至watermark[high]才会停止），这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量。极端情况下设置min_free_kbytes接近内存大小时，留给应用程序的内存就会太少而可能会频繁地导致OOM的发生。</p>
<p>min_free_kbytes设的过小，则会导致系统预留内存过小。kswapd回收的过程中也会有少量的内存分配行为（会设上PF_MEMALLOC）标志，这个标志会允许kswapd使用预留内存；另外一种情况是被OOM选中杀死的进程在退出过程中，如果需要申请内存也可以使用预留部分。这两种情况下让他们使用预留内存可以避免系统进入deadlock状态。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/19/starrocks-load/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/19/starrocks-load/" class="post-title-link" itemprop="url">starrocks离线构建</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-19 19:04:11" itemprop="dateCreated datePublished" datetime="2022-01-19T19:04:11+08:00">2022-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-24 21:18:39" itemprop="dateModified" datetime="2022-08-24T21:18:39+08:00">2022-08-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sre/" itemprop="url" rel="index"><span itemprop="name">sre</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul>
<li><p>入口文件-&gt;StarRocksFE.java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.....</span><br><span class="line">feServer.start();</span><br><span class="line">httpServer.start();</span><br><span class="line">qeService.start();</span><br></pre></td></tr></table></figure>
<p>主要是初始化配置和启动服务，分别是mysql server端口、thrift server端口、http端口</p>
</li>
<li><p>mysq服务启动-&gt;QeService.java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void start() throws IOException &#123;</span><br><span class="line">        if (!mysqlServer.start()) &#123;</span><br><span class="line">            LOG.error(&quot;mysql server start failed&quot;);</span><br><span class="line">            System.exit(-1);</span><br><span class="line">        &#125;</span><br><span class="line">        LOG.info(&quot;QE service start.&quot;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>MysqlServer.java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; start MySQL protocol service</span><br><span class="line">&#x2F;&#x2F; return true if success, otherwise false</span><br><span class="line">public boolean start() &#123;</span><br><span class="line">    if (scheduler &#x3D;&#x3D; null) &#123;</span><br><span class="line">        LOG.warn(&quot;scheduler is NULL.&quot;);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; open server socket</span><br><span class="line">    try &#123;</span><br><span class="line">        serverChannel &#x3D; ServerSocketChannel.open();</span><br><span class="line">        serverChannel.socket().bind(new InetSocketAddress(&quot;0.0.0.0&quot;, port), 2048);</span><br><span class="line">        serverChannel.configureBlocking(true);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        LOG.warn(&quot;Open MySQL network service failed.&quot;, e);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; start accept thread</span><br><span class="line">    listener &#x3D; ThreadPoolManager.newDaemonCacheThreadPool(1, &quot;MySQL-Protocol-Listener&quot;, true);</span><br><span class="line">    running &#x3D; true;</span><br><span class="line">    listenerFuture &#x3D; listener.submit(new Listener());</span><br><span class="line"></span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Listener 监听线程，实现Runnable接口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    while (running &amp;&amp; serverChannel.isOpen()) &#123;</span><br><span class="line">        SocketChannel clientChannel;</span><br><span class="line">        try &#123;</span><br><span class="line">            clientChannel &#x3D; serverChannel.accept();</span><br><span class="line">            if (clientChannel &#x3D;&#x3D; null) &#123;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F; submit this context to scheduler</span><br><span class="line">            ConnectContext context &#x3D; new ConnectContext(clientChannel);</span><br><span class="line">            &#x2F;&#x2F; Set catalog here.</span><br><span class="line">            context.setCatalog(Catalog.getCurrentCatalog());</span><br><span class="line">            if (!scheduler.submit(context)) &#123;</span><br><span class="line">                LOG.warn(&quot;Submit one connect request failed. Client&#x3D;&quot; + clientChannel.toString());</span><br><span class="line">                &#x2F;&#x2F; clear up context</span><br><span class="line">                context.cleanup();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            &#x2F;&#x2F; ClosedChannelException</span><br><span class="line">            &#x2F;&#x2F; AsynchronousCloseException</span><br><span class="line">            &#x2F;&#x2F; ClosedByInterruptException</span><br><span class="line">            &#x2F;&#x2F; Other IOException, for example &quot;to many open files&quot; ...</span><br><span class="line">            LOG.warn(&quot;Query server encounter exception.&quot;, e);</span><br><span class="line">            try &#123;</span><br><span class="line">                Thread.sleep(100);</span><br><span class="line">            &#125; catch (InterruptedException e1) &#123;</span><br><span class="line">                &#x2F;&#x2F; Do nothing</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            &#x2F;&#x2F; NotYetBoundException</span><br><span class="line">            &#x2F;&#x2F; SecurityException</span><br><span class="line">            LOG.warn(&quot;Query server failed when calling accept.&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#96;&#96;&#96; </span><br><span class="line"></span><br><span class="line">+ submit提交连接的上下文给线程池</span><br></pre></td></tr></table></figure>
<p>// submit one MysqlContext to this scheduler.<br>// return true, if this connection has been successfully submitted, otherwise return false.<br>// Caller should close ConnectContext if return false.<br>public boolean submit(ConnectContext context) {<br>  if (context == null) {</p>
<pre><code>  return false;
</code></pre><p>  }</p>
<p>  context.setConnectionId(nextConnectionId.getAndAdd(1));<br>  // no necessary for nio.<br>  if (context instanceof NConnectContext) {</p>
<pre><code>  return true;
</code></pre><p>  }<br>  if (executor.submit(new LoopHandler(context)) == null) {</p>
<pre><code>  LOG.warn(&quot;Submit one thread failed.&quot;);
  return false;
</code></pre><p>  }<br>  return true;<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoopHandler.java (实现Runnable接口)</span><br></pre></td></tr></table></figure>
<p>public void run() {<br>  try {</p>
<pre><code>  // Set thread local info
  context.setThreadLocalInfo();
  context.setConnectScheduler(ConnectScheduler.this);
  // authenticate check failed.
  if (!MysqlProto.negotiate(context)) {
      return;
  }

  if (registerConnection(context)) {
      MysqlProto.sendResponsePacket(context);
  } else {
      context.getState().setError(&quot;Reach limit of connections&quot;);
      MysqlProto.sendResponsePacket(context);
      return;
  }

  context.setStartTime();
  ConnectProcessor processor = new ConnectProcessor(context);
  processor.loop();
</code></pre><p>  } catch (Exception e) {</p>
<pre><code>  // for unauthrorized access such lvs probe request, may cause exception, just log it in debug level
  if (context.getCurrentUserIdentity() != null) {
      LOG.warn(&quot;connect processor exception because &quot;, e);
  } else {
      LOG.debug(&quot;connect processor exception because &quot;, e);
  }
</code></pre><p>  } finally {</p>
<pre><code>  unregisterConnection(context);
  context.cleanup();
</code></pre><p>  }<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; loop</span><br></pre></td></tr></table></figure>
<p>public void loop() {<br>  while (!ctx.isKilled()) {</p>
<pre><code>  try {
      processOnce();
  } catch (Exception e) {
      // TODO(zhaochun): something wrong
      LOG.warn(&quot;Exception happened in one seesion(&quot; + ctx + &quot;).&quot;, e);
      ctx.setKilled();
      break;
  }
</code></pre><p>  }<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; processOnce</span><br></pre></td></tr></table></figure>
<p>// handle one process<br>public void processOnce() throws IOException {<br>  // set status of query to OK.<br>  ctx.getState().reset();<br>  executor = null;</p>
<p>  // reset sequence id of MySQL protocol<br>  final MysqlChannel channel = ctx.getMysqlChannel();<br>  channel.setSequenceId(0);<br>  // read packet from channel<br>  try {</p>
<pre><code>  packetBuf = channel.fetchOnePacket();
  if (packetBuf == null) {
      throw new IOException(&quot;Error happened when receiving packet.&quot;);
  }
</code></pre><p>  } catch (AsynchronousCloseException e) {</p>
<pre><code>  // when this happened, timeout checker close this channel
  // killed flag in ctx has been already set, just return
  return;
</code></pre><p>  }</p>
<p>  // dispatch<br>  dispatch();<br>  // finalize<br>  finalizeCommand();</p>
<p>  ctx.setCommand(MysqlCommand.COM_SLEEP);<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; dispatch</span><br></pre></td></tr></table></figure>
<p>int code = packetBuf.get();<br>MysqlCommand command = MysqlCommand.fromCode(code);<br>….<br>ctx.setCommand(command);<br>….</p>
</li>
</ul>
<p>switch (command) {<br>    case COM_INIT_DB:<br>        handleInitDb();<br>        break;<br>    case COM_QUIT:<br>        handleQuit();<br>        break;<br>    case COM_QUERY:<br>        handleQuery();<br>        ctx.setStartTime();<br>        break;<br>    case COM_FIELD_LIST:<br>        handleFieldList();<br>        break;<br>    case COM_CHANGE_USER:<br>        handleChangeUser();<br>        break;<br>    case COM_RESET_CONNECTION:<br>        handleResetConnnection();<br>        break;<br>    case COM_PING:<br>        handlePing();<br>        break;<br>    default:<br>        ctx.getState().setError(“Unsupported command(“ + command + “)”);<br>        LOG.warn(“Unsupported command(“ + command + “)”);<br>        break;<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ ConnectProcessor.java -&gt; handleQuery</span><br></pre></td></tr></table></figure><br>….<br>List<StatementBase> stmts = analyze(originStmt);<br>for (int i = 0; i &lt; stmts.size(); ++i) {<br>    ctx.getState().reset();<br>    if (i &gt; 0) {<br>        ctx.resetRetureRows();<br>        ctx.setQueryId(UUIDUtil.genUUID());<br>    }<br>    parsedStmt = stmts.get(i);<br>    parsedStmt.setOrigStmt(new OriginStatement(originStmt, i));</p>
<pre><code>executor = new StmtExecutor(ctx, parsedStmt);
ctx.setExecutor(executor);

ctx.setIsLastStmt(i == stmts.size() - 1);

executor.execute();

// do not execute following stmt when current stmt failed, this is consistent with mysql server
if (ctx.getState().getStateType() == QueryState.MysqlStateType.ERR) {
    break;
}

if (i != stmts.size() - 1) {
    // NOTE: set serverStatus after executor.execute(),
    //      because when execute() throws exception, the following stmt will not execute
    //      and the serverStatus with MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS will
    //      cause client error: Packet sequence number wrong
    ctx.getState().serverStatus |= MysqlServerStatusFlag.SERVER_MORE_RESULTS_EXISTS;
    finalizeCommand();
}
</code></pre><p>}<br>….</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ ConnectProcessor.java -&gt; analyze</span><br></pre></td></tr></table></figure>
<p>// analyze the origin stmt and return multi-statements<br>private List<StatementBase> analyze(String originStmt) throws AnalysisException {<br>    LOG.debug(“the originStmts are: {}”, originStmt);<br>    // Parse statement with parser generated by CUP&amp;FLEX<br>    SqlScanner input = new SqlScanner(new StringReader(originStmt), ctx.getSessionVariable().getSqlMode());<br>    SqlParser parser = new SqlParser(input);<br>    try {<br>        return SqlParserUtils.getMultiStmts(parser);<br>    } catch (Error e) {<br>        throw new AnalysisException(“Please check your sql, we meet an error when parsing.”, e);<br>    } catch (AnalysisException e) {<br>        LOG.warn(“origin_stmt: “ + originStmt + “; Analyze error message: “ + parser.getErrorMsg(originStmt), e);<br>        String errorMessage = parser.getErrorMsg(originStmt);<br>        if (errorMessage == null) {<br>            throw e;<br>        } else {<br>            throw new AnalysisException(errorMessage, e);<br>        }<br>    } catch (Exception e) {<br>        // TODO(lingbin): we catch ‘Exception’ to prevent unexpected error,<br>        // should be removed this try-catch clause future.<br>        LOG.warn(“origin_stmt: “ + originStmt + “; exception: “, e);<br>        String errorMessage = e.getMessage();<br>        if (errorMessage == null) {<br>            throw new AnalysisException(“Internal Error”);<br>        } else {<br>            throw new AnalysisException(“Internal Error: “ + errorMessage);<br>        }<br>    }<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>} else if (parsedStmt instanceof DdlStmt) {<br>    handleDdlStmt();<br>}<br>……<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ StmtExecutor.java -&gt; handleDdlStmt</span><br></pre></td></tr></table></figure><br>private void handleDdlStmt() {<br>  try {<br>      DdlExecutor.execute(context.getCatalog(), (DdlStmt) parsedStmt);<br>      context.getState().setOk();<br>  } catch (QueryStateException e) {<br>      if (e.getQueryState().getStateType() != MysqlStateType.OK) {<br>          LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      }<br>      context.setState(e.getQueryState());<br>  } catch (UserException e) {<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      // Return message to info client what happened.<br>      context.getState().setError(e.getMessage());<br>  } catch (Exception e) {<br>      // Maybe our bug<br>      LOG.warn(“DDL statement(“ + originStmt.originStmt + “) process failed.”, e);<br>      context.getState().setError(“Unexpected exception: “ + e.getMessage());<br>  }<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ DdlExecutor.java -&gt; execute</span><br></pre></td></tr></table></figure><br>……..<br>else if (ddlStmt instanceof LoadStmt) {<br>    LoadStmt loadStmt = (LoadStmt) ddlStmt;<br>    EtlJobType jobType = loadStmt.getEtlJobType();<br>    if (jobType == EtlJobType.UNKNOWN) {<br>        throw new DdlException(“Unknown load job type”);<br>    }<br>    if (jobType == EtlJobType.HADOOP &amp;&amp; Config.disable_hadoop_load) {<br>        throw new DdlException(“Load job by hadoop cluster is disabled.”</p>
<pre><code>            + &quot; Try using broker load. See &#39;help broker load;&#39;&quot;);
}

catalog.getLoadManager().createLoadJobFromStmt(loadStmt);
</code></pre><p>}<br>……..<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ LoadManager.java -&gt; createLoadJobFromStmt</span><br></pre></td></tr></table></figure><br>public void createLoadJobFromStmt(LoadStmt stmt) throws DdlException {<br>  Database database = checkDb(stmt.getLabel().getDbName());<br>  long dbId = database.getId();<br>  LoadJob loadJob = null;<br>  writeLock();<br>  try {<br>      checkLabelUsed(dbId, stmt.getLabel().getLabelName());<br>      if (stmt.getBrokerDesc() == null &amp;&amp; stmt.getResourceDesc() == null) {<br>          throw new DdlException(“LoadManager only support the broker and spark load.”);<br>      }<br>      if (loadJobScheduler.isQueueFull()) {<br>          throw new DdlException(<br>                  “There are more than “ + Config.desired_max_waiting_jobs + “ load jobs in waiting queue, “</p>
<pre><code>                      + &quot;please retry later.&quot;);
  }
  loadJob = BulkLoadJob.fromLoadStmt(stmt);
  createLoadJob(loadJob);
</code></pre><p>  } finally {<br>      writeUnlock();<br>  }<br>  Catalog.getCurrentCatalog().getEditLog().logCreateLoadJob(loadJob);</p>
<p>  // The job must be submitted after edit log.<br>  // It guarantee that load job has not been changed before edit log.<br>  loadJobScheduler.submitJob(loadJob);<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">通过 &#96;createLoadJobFromStmt&#96; 创建load任务</span><br><span class="line">+ LoadJobScheduler.java -&gt; process</span><br><span class="line">注意：LoadJobScheduler 继承自 MasterDaemon，MasterDaemon 继承自 Daemon，</span><br><span class="line">Daemon继承自Thread，重载了run方法，里面有一个loop，主要执行runOneCycle</span><br><span class="line">MasterDaemon 又重写了 runOneCycle，执行 runAfterCatalogReady 函数</span><br><span class="line">LoadJobScheduler 又重写了 runAfterCatalogReady 主要就是干process处理，里面是一个死循环，不断从LinkedBlockingQueue类型的needScheduleJobs里出栈取要珍惜的job</span><br></pre></td></tr></table></figure><br>while (true) {<br>  // take one load job from queue<br>  LoadJob loadJob = needScheduleJobs.poll();<br>  if (loadJob == null) {<br>      return;<br>  }</p>
<p>  // schedule job<br>  try {<br>      loadJob.execute();<br>  }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ LoadJob.java -&gt; execute</span><br></pre></td></tr></table></figure><br>/**</p>
<ul>
<li>create pending task for load job and add pending task into pool</li>
<li>if job has been cancelled, this step will be ignored<br>*</li>
<li>@throws LabelAlreadyUsedException  the job is duplicated</li>
<li>@throws BeginTransactionException  the limit of load job is exceeded</li>
<li>@throws AnalysisException          there are error params in job</li>
<li><p>@throws DuplicatedRequestException<br>*/<br>public void execute() throws LabelAlreadyUsedException, BeginTransactionException, AnalysisException,</p>
<pre><code>DuplicatedRequestException, LoadException {
</code></pre><p>writeLock();<br>try {</p>
<pre><code>unprotectedExecute();
</code></pre><p>} finally {</p>
<pre><code>writeUnlock();
</code></pre><p>}<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; unprotectedExecuteJob</span><br></pre></td></tr></table></figure>
<p>protected void unprotectedExecuteJob() throws LoadException {<br>// create pending task<br>LoadTask task = new SparkLoadPendingTask(this, fileGroupAggInfo.getAggKeyToFileGroups(),</p>
<pre><code>    sparkResource, brokerDesc);
</code></pre><p>task.init();<br>idToTasks.put(task.getSignature(), task);<br>submitTask(Catalog.getCurrentCatalog().getPendingLoadTaskScheduler(), task);<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; init</span><br></pre></td></tr></table></figure>
<p>public void init() throws LoadException {<br>createEtlJobConf();<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ LoadTask -&gt; exec</span><br></pre></td></tr></table></figure>
<p>@Override<br>protected void exec() {<br>boolean isFinished = false;<br>try {</p>
<pre><code>// execute pending task
executeTask();
// callback on pending task finished
callback.onTaskFinished(attachment);
isFinished = true;
</code></pre><p>} catch (UserException e) {</p>
<pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());
LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())
        .add(&quot;error_msg&quot;, &quot;Failed to execute load task&quot;).build(), e);
</code></pre><p>} catch (Exception e) {</p>
<pre><code>failMsg.setMsg(e.getMessage() == null ? &quot;&quot; : e.getMessage());
LOG.warn(new LogBuilder(LogKey.LOAD_JOB, callback.getCallbackId())
        .add(&quot;error_msg&quot;, &quot;Unexpected failed to execute load task&quot;).build(), e);
</code></pre><p>} finally {</p>
<pre><code>if (!isFinished) {
    // callback on pending task failed
    callback.onTaskFailed(signature, failMsg);
}
</code></pre><p>}<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ SparkLoadPendingTask.java -&gt; executeTask</span><br></pre></td></tr></table></figure>
<p>void executeTask() throws LoadException {<br>LOG.info(“begin to execute spark pending task. load job id: {}”, loadJobId);<br>submitEtlJob();<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadPendingTask.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure>
<p>private void submitEtlJob() throws LoadException {<br>SparkPendingTaskAttachment sparkAttachment = (SparkPendingTaskAttachment) attachment;<br>// retry different output path<br>etlJobConfig.outputPath = EtlJobConfig.getOutputPath(resource.getWorkingDir(), dbId, loadLabel, signature);<br>sparkAttachment.setOutputPath(etlJobConfig.outputPath);</p>
<p>// handler submit etl job<br>SparkEtlJobHandler handler = new SparkEtlJobHandler();<br>handler.submitEtlJob(loadJobId, loadLabel, etlJobConfig, resource, brokerDesc, sparkLoadAppHandle,</p>
<pre><code>    sparkAttachment);
</code></pre><p>LOG.info(“submit spark etl job success. load job id: {}, attachment: {}”, loadJobId, sparkAttachment);<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkEtlJobHandler.java -&gt; submitEtlJob</span><br></pre></td></tr></table></figure>
<p>public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobConfig, SparkResource resource,</p>
<pre><code>                     BrokerDesc brokerDesc, SparkLoadAppHandle handle, SparkPendingTaskAttachment attachment)
</code></pre><p>  throws LoadException {<br>// delete outputPath<br>// init local dir<br>// prepare dpp archive<br>SparkLauncher launcher = new SparkLauncher(envs);<br>// master      |  deployMode<br>// ——————|——————-<br>// yarn        |  cluster<br>// spark://xx  |  client<br>launcher.setMaster(resource.getMaster())</p>
<pre><code>  .setDeployMode(resource.getDeployMode().name().toLowerCase())
  .setAppResource(appResourceHdfsPath)
  .setMainClass(SparkEtlJob.class.getCanonicalName())
  .setAppName(String.format(ETL_JOB_NAME, loadLabel))
  .setSparkHome(sparkHome)
  .addAppArgs(jobConfigHdfsPath)
  .redirectError();
</code></pre><p>// spark configs</p>
<p>// start app<br>State state = null;<br>String appId = null;<br>String logPath = null;<br>String errMsg = “start spark app failed. error: “;<br>try {<br>  Process process = launcher.launch();<br>  handle.setProcess(process);<br>  if (!FeConstants.runningUnitTest) {</p>
<pre><code>  SparkLauncherMonitor.LogMonitor logMonitor = SparkLauncherMonitor.createLogMonitor(handle);
  logMonitor.setSubmitTimeoutMs(GET_APPID_TIMEOUT_MS);
  logMonitor.setRedirectLogPath(logFilePath);
  logMonitor.start();
  try {
      logMonitor.join();
  } catch (InterruptedException e) {
      logMonitor.interrupt();
      throw new LoadException(errMsg + e.getMessage());
  }
</code></pre><p>  }<br>  appId = handle.getAppId();<br>  state = handle.getState();<br>  logPath = handle.getLogPath();<br>} catch (IOException e) {<br>  LOG.warn(errMsg, e);<br>  throw new LoadException(errMsg + e.getMessage());<br>}<br>……….<br>// success<br>attachment.setAppId(appId);<br>attachment.setHandle(handle);<br>}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ SparkLoadJob.java -&gt; onTaskFinished</span><br></pre></td></tr></table></figure>
<p>public void onTaskFinished(TaskAttachment attachment) {<br>if (attachment instanceof SparkPendingTaskAttachment) {</p>
<pre><code>onPendingTaskFinished((SparkPendingTaskAttachment) attachment);
</code></pre><p>}<br>}</p>
</li>
</ul>
<p>private void onPendingTaskFinished(SparkPendingTaskAttachment attachment) {<br>    writeLock();<br>    try {<br>        // check if job has been cancelled<br>        if (isTxnDone()) {<br>            LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)<br>                    .add(“state”, state)<br>                    .add(“error_msg”, “this task will be ignored when job is: “ + state)<br>                    .build());<br>            return;<br>        }</p>
<pre><code>    if (finishedTaskIds.contains(attachment.getTaskId())) {
        LOG.warn(new LogBuilder(LogKey.LOAD_JOB, id)
                .add(&quot;task_id&quot;, attachment.getTaskId())
                .add(&quot;error_msg&quot;, &quot;this is a duplicated callback of pending task &quot;
                        + &quot;when broker already has loading task&quot;)
                .build());
        return;
    }

    // add task id into finishedTaskIds
    finishedTaskIds.add(attachment.getTaskId());

    sparkLoadAppHandle = attachment.getHandle();
    appId = attachment.getAppId();
    etlOutputPath = attachment.getOutputPath();

    executeEtl();
    // log etl state
    unprotectedLogUpdateStateInfo();
} finally {
    writeUnlock();
}
</code></pre><p>}</p>
<p>```</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/13/cpp_introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/13/cpp_introduction/" class="post-title-link" itemprop="url">cpp奇葩语法介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-13 19:04:11" itemprop="dateCreated datePublished" datetime="2022-01-13T19:04:11+08:00">2022-01-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/introduction/" itemprop="url" rel="index"><span itemprop="name">introduction</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="const"><a href="#const" class="headerlink" title="const"></a>const</h3><h3 id="friend"><a href="#friend" class="headerlink" title="friend"></a>friend</h3><blockquote>
<p>友邻函数</p>
</blockquote>
<h3 id="extern"><a href="#extern" class="headerlink" title="extern"></a>extern</h3><h3 id="vitrual"><a href="#vitrual" class="headerlink" title="vitrual"></a>vitrual</h3><blockquote>
<p>基类希望其派生类进行覆盖（<code>override</code>）的函数。这种函数，基类通常将其定义为虚函数（加<code>virtual</code>）。当我们使用基类的指针或者引用调用虚函数时，该调用将被<strong>动态绑定</strong></p>
<h4 id="用法解释："><a href="#用法解释：" class="headerlink" title="用法解释："></a>用法解释：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Base &#123;</span><br><span class="line">  public:</span><br><span class="line">    virtual void print() &#123;</span><br><span class="line">      cout &lt;&lt; &quot;&#x3D;&#x3D;BASE&#x3D;&#x3D;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">class Derived: public Base &#123;</span><br><span class="line">  public:</span><br><span class="line">    void print()&#123;</span><br><span class="line">      cout &lt;&lt; &quot;&#x3D;&#x3D;DERIVED&#x3D;&#x3D;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int main() &#123;</span><br><span class="line">  Base *pointer &#x3D; new Derived();</span><br><span class="line">  &#x2F;&#x2F; &#x3D;&#x3D;DERIVED&#x3D;&#x3D;</span><br><span class="line">  pointer-&gt;print();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>类<code>Base</code>中加了<code>Virtual</code>关键字的函数就是虚拟函数（例如函数<code>print</code>），于是在<code>Base</code>的派生类<code>Derived</code>中就可以通过重写虚拟函数来实现对基类虚拟函数的覆盖。当基类<code>Base</code>的指针<code>point</code>指向派生类<code>Derived</code>的对象时，对<code>point</code>的<code>print</code>函数的调用实际上是调用了<code>Derived</code>的<code>print</code>函数而不是<code>Base</code>的<code>print</code>函数。这是面向对象中的多态性的体现 </p>
<h4 id="纯虚函数"><a href="#纯虚函数" class="headerlink" title="纯虚函数"></a>纯虚函数</h4><p>纯虚函数声明如下： <code>virtual void funtion1()=0;</code> 纯虚函数一定没有定义，纯虚函数用来规范派生类的行为，即接口。包含纯虚函数的类是抽象类，抽象类不能定义实例，但可以声明指向实现该抽象类的具体类的指针或引用。</p>
</blockquote>
<h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><ul>
<li>定义一个函数为虚函数，不代表函数为不被实现的函数。</li>
<li>定义一个虚函数是为了允许用基类的指针或引用来调用子类的这个函数。</li>
<li>定义一个函数为纯虚函数，才代表函数没有被实现。</li>
<li>定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。</li>
<li>任何友元(friend)/构造(construct)/static静态函数之外的函数都可以是虚函数。</li>
<li>关键字virtual只能出现在类内部的声明语句之前而不能用于类外部的函数定义</li>
<li>基类定义了virtual，继承类的该函数也具有了virtual属性</li>
</ul>
<h3 id="static"><a href="#static" class="headerlink" title="static"></a>static</h3><h3 id="template"><a href="#template" class="headerlink" title="template"></a>template</h3><h3 id="inline"><a href="#inline" class="headerlink" title="inline"></a>inline</h3><h3 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h3><blockquote>
<p>在声明变量时根据变量初始值的类型自动为此变量选择匹配的类型。</p>
<h4 id="用法解释：-1"><a href="#用法解释：-1" class="headerlink" title="用法解释："></a>用法解释：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">auto f &#x3D; 3.14;  &#x2F;&#x2F;double</span><br><span class="line">auto s(&quot;hello&quot;);  &#x2F;&#x2F;const char*</span><br><span class="line">auto z &#x3D; new auto(9);  &#x2F;&#x2F;int *</span><br></pre></td></tr></table></figure>
<h4 id="注意点-1"><a href="#注意点-1" class="headerlink" title="注意点"></a>注意点</h4><ul>
<li>可以用valatile，pointer（*），reference（&amp;），rvalue reference（&amp;&amp;） 来修饰auto<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auto k &#x3D; 5;  </span><br><span class="line">auto* pK &#x3D; new auto(k);  </span><br><span class="line">auto** ppK &#x3D; new auto(&amp;k);  </span><br><span class="line">const auto n &#x3D; 6;</span><br></pre></td></tr></table></figure></li>
<li>用auto声明的变量必须初始化</li>
<li>auto不能与其他类型组合连用</li>
<li>函数和模板参数不能被声明为auto</li>
<li>定义在堆上的变量，使用了auto的表达式必须被初始化</li>
<li>以为auto是一个占位符，并不是一个他自己的类型，因此不能用于类型转换或其他一些操作，如sizeof和typeid</li>
<li>定义在一个auto序列的变量必须始终推导成同一类型<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 错误，必须是初始化为同一类型</span><br><span class="line">auto x1 &#x3D; 5, x2 &#x3D; 5.0, x3&#x3D;&#39;r&#39;;</span><br></pre></td></tr></table></figure></li>
<li>auto不能自动推导成CV-qualifiers (constant &amp; volatile qualifiers)</li>
<li>auto会退化成指向数组的指针，除非被声明为引用</li>
</ul>
</blockquote>
<h3 id="template-1"><a href="#template-1" class="headerlink" title="template"></a>template</h3><h3 id="左值和右职"><a href="#左值和右职" class="headerlink" title="左值和右职"></a>左值和右职</h3><h4 id="左值和右值的概念"><a href="#左值和右值的概念" class="headerlink" title="左值和右值的概念"></a>左值和右值的概念</h4><ul>
<li>左值是可以放在赋值号左边可以被赋值的值；左值必须要在内存中有实体；</li>
<li>右值当在赋值号右边取出值赋给其他变量的值；右值可以在内存也可以在CPU寄存器。</li>
<li>一个对象被用作右值时，使用的是它的内容(值)，被当作左值时，使用的是它的地址。</li>
</ul>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><ul>
<li>引用是C++语法做的优化，引用的本质还是靠指针来实现的。引用相当于变量的别名。</li>
<li>引用可以改变指针的指向，还可以改变指针所指向的值。</li>
<li>引用的基本规则：<ul>
<li>声明引用的时候必须初始化，且一旦绑定，不可把引用绑定到其他对象；即引用必须初始化，不能对引用重定义；</li>
<li>对引用的一切操作，就相当于对原对象的操作。</li>
</ul>
</li>
</ul>
<h4 id="左值引用和右值引用"><a href="#左值引用和右值引用" class="headerlink" title="左值引用和右值引用"></a>左值引用和右值引用</h4><ul>
<li>左值引用：<ul>
<li>左值引用的基本语法：type &amp;引用名 = 左值表达式；</li>
</ul>
</li>
<li>右值引用：<ul>
<li>右值引用的基本语法type &amp;&amp;引用名 = 右值表达式；</li>
<li>右值引用在企业开发人员在代码优化方面会经常用到。</li>
<li>右值引用的“&amp;&amp;”中间不可以有空格。</li>
</ul>
</li>
</ul>
<h3 id="operator"><a href="#operator" class="headerlink" title="operator"></a>operator</h3><blockquote>
<p>operator是C++的关键字，它和运算符一起使用，表示一个运算符函数，理解时应将operator=整体上视为一个函数名。</p>
</blockquote>
<p>1、只有C++预定义的操作符才可以被重载；</p>
<p>2、对于内置类型的操作符，它的预定义不能改变，即不能改变操作符原来的功能；</p>
<p>3、重载操作符不能改变他们的操作符优先级；</p>
<p>4、重载操作符不能改变操作数的个数；</p>
<p>5、除了对（）操作符外，对其他重载操作符提供缺省实参都是非法的； </p>
<h3 id="explicit"><a href="#explicit" class="headerlink" title="explicit"></a>explicit</h3><blockquote>
<p>放构造函数前，防止隐式转换，普通构造函数能够被隐式调用，而explicit构造函数只能被显式调用。例子如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">class Test1 &#123;</span><br><span class="line">  public:</span><br><span class="line">    Test1(int n) &#123;</span><br><span class="line">      num &#x3D; n;</span><br><span class="line">    &#125;</span><br><span class="line">  private:</span><br><span class="line">    int num;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Test2 &#123;</span><br><span class="line">  public:</span><br><span class="line">    explicit Test2(int n) &#123;</span><br><span class="line">      num &#x3D; n;</span><br><span class="line">    &#125;</span><br><span class="line">  private:</span><br><span class="line">    int num;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">  Test1 t1 &#x3D; 12; &#x2F;&#x2F; 隐私调用其构造函数Test1，等同于Test1 t1(12)</span><br><span class="line">  Test2 t2 &#x3D; 100; &#x2F;&#x2F;编译错误，不能隐式调用其构造函数</span><br><span class="line">  Test2 t3(323); &#x2F;&#x2F;显示调用成功</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="dynamic-cast"><a href="#dynamic-cast" class="headerlink" title="dynamic_cast"></a>dynamic_cast</h3><blockquote>
<p>将基类的指针或引用安全地转换成派生类的指针或引用，并用派生类的指针或引用调用非虚函数。如果是基类指针或引用调用的是虚函数无需转换就能在运行时调用派生类的虚函数</p>
</blockquote>
<p>前提条件：当我们将dynamic_cast用于某种类型的指针或引用时，只有该类型含有虚函数时，才能进行这种转换。否则，编译器会报错。</p>
<p>dynamic_cast运算符的调用形式如下所示：</p>
<p>dynamic_cast<type*>(e)  //e是指针</p>
<p>dynamic_cast<type&>(e)  //e是左值</p>
<p>dynamic_cast<type&&>(e)//e是右值</p>
<p>e能成功转换为type*类型的情况有三种：</p>
<p>1）e的类型是目标type的公有派生类：派生类向基类转换一定会成功。</p>
<p>2）e的类型是目标type的基类，当e是指针指向派生类对象，或者基类引用引用派生类对象时，类型转换才会成功，当e指向基类对象，试图转换为派生类对象时，转换失败。</p>
<p>3）e的类型就是type的类型时，一定会转换成功。</p>
<h3 id="reinterpt-cast"><a href="#reinterpt-cast" class="headerlink" title="reinterpt_cast"></a>reinterpt_cast</h3><blockquote>
<p>该函数将一个类型的指针转换为另一个类型的指针，这种转换不用修改指针变量值存放格式(不改变指针变量值)，只需在编译时重新解释指针的类型就可做到。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int* a &#x3D; 1;</span><br><span class="line">double* b &#x3D; reinterpret_cast&lt;double*&gt;(a)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="const-cast"><a href="#const-cast" class="headerlink" title="const_cast"></a>const_cast</h3><blockquote>
<p>该函数用于去除指针变量的常量属性，将它转换为一个对应指针类型的普通变量。反过来说，也可以将一个非常量的指针变量转换为一个常量指针变量。这种转换是在编译期间作出的类型更改。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">const int* a &#x3D; 1;</span><br><span class="line">int* pk &#x3D; const_cast&lt;int*&gt;(a); &#x2F;&#x2F; 相当于 int* pk &#x3D; (int*) a</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="static-cast"><a href="#static-cast" class="headerlink" title="static_cast"></a>static_cast</h3><blockquote>
<p>该函数主要用于基本类型之间和具有继承关系的类型之间的转换。这种转换一般会更改变量的内部表示方式，因此，static_cast应用于指针类型转换没有太大意义。</p>
</blockquote>
<p>主要有如下几种用法：</p>
<ul>
<li>用于类层次结构中基类和子类之间指针或引用的转换。</li>
<li>进行上行转换（把子类的指针或引用转换成基类表示）是安全的；</li>
<li>进行下行转换（把基类指针或引用转换成子类指针或引用）时，由于没有动态类型检查，所以是不安全的。</li>
<li>用于基本数据类型之间的转换，如把int转换成char，把int转换成enum。这种转换的安全性也要开发人员来保证。</li>
<li>把void指针转换成目标类型的指针(不安全!!)</li>
<li>把任何类型的表达式转换成void类型。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;基本类型转换</span><br><span class="line">int i&#x3D;0;</span><br><span class="line">double d &#x3D; static_cast&lt;double&gt;(i);  &#x2F;&#x2F;相当于 double d &#x3D; (double)i;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;转换继承类的对象为基类对象</span><br><span class="line">class Base&#123;&#125;;</span><br><span class="line">class Derived : public Base&#123;&#125;;</span><br><span class="line">Derived d;</span><br><span class="line">Base b &#x3D; static_cast&lt;Base&gt;(d);     &#x2F;&#x2F;相当于 Base b &#x3D; (Base)d;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="mutable"><a href="#mutable" class="headerlink" title="mutable"></a>mutable</h3><p>mutable的作用有两点：<br>（1）保持常量对象中大部分数据成员仍然是“只读”的情况下，实现对个别数据成员的修改；<br>（2）使类的const函数可以修改对象的mutable数据成员。</p>
<p>使用mutable的注意事项：<br>（1）mutable只能作用于类的非静态和非常量数据成员。<br>（2）在一个类中，应尽量或者不用mutable，大量使用mutable表示程序设计存在缺陷。</p>
<h3 id="using"><a href="#using" class="headerlink" title="using"></a>using</h3><ul>
<li><ol>
<li>命名空间的使用<blockquote>
<p>一般是为了代码的冲突，都会用命名空间，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 命名空间名称</span><br><span class="line">namespace android</span><br><span class="line">class Test &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 直接使用该命名空间</span><br><span class="line">using namespace android;</span><br><span class="line">&#x2F;&#x2F; 使用该命名空间的Test类</span><br><span class="line">using android::Test;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>在子类汇总引用基类的成员<blockquote>
<p>注意，using只是引用，不参与形参的指定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Base &#123;</span><br><span class="line">public:</span><br><span class="line">  Base() &#123;&#125;</span><br><span class="line">  virtual ~Base() &#123;&#125;</span><br><span class="line">  void hello()&#123; std::cout &lt;&lt; &quot;hello world&quot; &lt;&lt; std::endl; &#125;</span><br><span class="line">protected:</span><br><span class="line">  int value;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; 私有继承，无法使用基类的public&#x2F;protected属性的变量和函数</span><br><span class="line">class Common: private Base &#123;</span><br><span class="line">public:</span><br><span class="line">&#x2F;&#x2F; 使用using方法是来引用，这样Common类就能直接用了</span><br><span class="line">  using Base::hello;</span><br><span class="line">  using Base:value;</span><br><span class="line"></span><br><span class="line">  void test() &#123; std::cout &lt;&lt; &quot;value is: &quot; &lt;&lt; value &lt;&lt; std::endll &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
<li><ol>
<li>别名指定<blockquote>
<p>从可读性上说，typedef 要比 using 好理解，另外typedef是无法使用模版的，而using可以使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 这样之后就可以使用value_type xx 去代表type xx</span><br><span class="line">using value_type &#x3D; type;</span><br><span class="line"></span><br><span class="line">template&lt;typename T&gt;</span><br><span class="line">using Vec &#x3D; MyVector&lt;T, MyAlloc&lt;T&gt;&gt;;</span><br><span class="line">&#x2F;&#x2F;usage</span><br><span class="line">Vec&lt;int&gt; vec;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ol>
</li>
</ul>
<h3 id="const-char-char-const-char-const的区别"><a href="#const-char-char-const-char-const的区别" class="headerlink" title="const char , char const , char * const的区别"></a>const char <em>, char const </em>, char * const的区别</h3><blockquote>
<p>把一个声明从右向左读。( * 读成 pointer to ),C++标准规定，const关键字放在类型或变量名之前等价的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; cp is a const pointer to char</span><br><span class="line">&#x2F;&#x2F; 定义一个指向字符的指针常数，即const指针</span><br><span class="line">char * const cp;  </span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; p is a pointer to const char</span><br><span class="line">&#x2F;&#x2F; 定义一个指向字符常数的指针</span><br><span class="line">const char * p; </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 同上因为C++里面没有const*的运算符，所以const只能属于前面的类型。</span><br><span class="line">char const * p;</span><br></pre></td></tr></table></figure></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/13/clickhouse-mutation-problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/13/clickhouse-mutation-problem/" class="post-title-link" itemprop="url">clickhouse报错Metadata on replica的解决方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-13 19:04:11" itemprop="dateCreated datePublished" datetime="2022-01-13T19:04:11+08:00">2022-01-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-08-22 18:09:00" itemprop="dateModified" datetime="2022-08-22T18:09:00+08:00">2022-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClickHouse exception, code: 517, host: xx.xx.xx.xx, port: xxxx; Code: 517, e.displayText() &#x3D; DB::Exception: Metadata on replica is not up to date with common metadata in Zookeeper. Cannot alter: Bad version</span><br></pre></td></tr></table></figure>
<p>我们在修改表结构（例如<code>alter table drop column xxx</code>）时经常会遇到以上报错，原因副本上的元数据和在zookeeper上的元数据不一致，无法更新，因为版本号不一样。</p>
<h3 id="查找system-replication-queue"><a href="#查找system-replication-queue" class="headerlink" title="查找system.replication_queue"></a>查找system.replication_queue</h3><ul>
<li>表介绍<br><a href="https://clickhouse.com/docs/en/operations/system-tables/replication_queue/" target="_blank" rel="noopener">链接地址</a>包含了所有<code>ReplicatedMergeTree</code>复制表家族在<code>zookeeper</code>上存储的副本任务队列的相关信息。</li>
<li><p>列信息</p>
<ul>
<li>database (String) — 数据库名称.</li>
<li>table (String) — 表名称.</li>
<li>replica_name (String) — zookeeper上副本名称，同表不同副本有不同名字.</li>
<li>position (UInt32) — 当前任务队列的位置.</li>
<li>node_name (String) — ZooKeeper上节点名称.</li>
<li>type (String) — 任务队列的名称，分别是:<ul>
<li>GET_PART — 从另一个副本拿到part.</li>
<li>ATTACH_PART — 加载part, 有可能来自我们自己的副本 (如果是在detached目录上发现). 您可以认为它是带有一些优化的GET_PART，因为他们接近相似.</li>
<li>MERGE_PARTS — 合并part.</li>
<li>DROP_RANGE — 删除指定范围内的指定分区列表.</li>
<li>CLEAR_COLUMN — 注意：从指定分区删除特殊列（已弃用）.</li>
<li>CLEAR_INDEX — 注意：从指定分区删除指定索引（已弃用）.</li>
<li>REPLACE_RANGE — 删除一定范围内的part，并用新part替换.</li>
<li>MUTATE_PART — 对part应用用一个或多个mutation.</li>
<li>ALTER_METADATA — 根据/metadata和/columns路径应用alter修改.</li>
</ul>
</li>
<li>create_time (Datetime) — 任务被提交执行后的时间.</li>
<li>required_quorum (UInt32) — 等待任务完成并且确认完成的副本数. 这个字段仅跟GET_PARTS任务相关.</li>
<li>source_replica (String) — 源副本的名称.</li>
<li>new_part_name (String) — 新part的名称.</li>
<li>parts_to_merge (Array (String)) — 要更新或者合并的part名称.</li>
<li>is_detach (UInt8) — DETACH_PARTS任务是否在任务队列里的标示位.</li>
<li>is_currently_executing (UInt8) — 当然任务是否正在执行的标示位.</li>
<li>num_tries (UInt32) — 尝试完成任务失败的次数.</li>
<li>last_exception (String) — 上次错误发生的详情.</li>
<li>last_attempt_time (Datetime) — 任务最后一次尝试的时间</li>
<li>num_postponed (UInt32) — 延期任务数.</li>
<li>postpone_reason (String) — 任务延期时间.</li>
<li>last_postpone_time (Datetime) — 任务上次延期的时间.</li>
<li>merge_type (String) — 当前合并的类型. 如果是mutation则为空.</li>
</ul>
</li>
<li><p>通过该表捞出zookeeper的节点副本信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select node_name from system.replication_queue where database &#x3D; &#39;xx&#39; and table &#x3D; &#39;xx&#39; and is_currently_executing &#x3D; 1</span><br></pre></td></tr></table></figure>
<h3 id="system-replcas"><a href="#system-replcas" class="headerlink" title="system.replcas"></a>system.replcas</h3></li>
</ul>
<h3 id="system-mutations"><a href="#system-mutations" class="headerlink" title="system.mutations"></a>system.mutations</h3><h3 id="处理方式"><a href="#处理方式" class="headerlink" title="处理方式"></a>处理方式</h3><p>+ </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/12/clickhouse-distribute-insert-problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Blank Lin">
      <meta itemprop="description" content="say something about me">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlankLin">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/12/clickhouse-distribute-insert-problem/" class="post-title-link" itemprop="url">clickhouse分布式表写入积压排查</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-12 16:04:11" itemprop="dateCreated datePublished" datetime="2022-01-12T16:04:11+08:00">2022-01-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-08 16:56:30" itemprop="dateModified" datetime="2022-12-08T16:56:30+08:00">2022-12-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><ul>
<li>首先解释下为什么要写入分布式表，而不是<code>MergeTree</code>表<br><a href="https://clickhouse.com/docs/en/engines/table-engines/special/distributed/" target="_blank" rel="noopener">分布式表链接</a>，分布式表引擎不会存储任务数据，但是允许分布式查询可以路由到多台机器，读取都是并行的，每一个读操作，如果有配置的话，远程机器上的表索引都会被使用到，所以我们知道分布式表是不存储数据的，只是数据的搬运工而已，我们正常做法应该是直接写入数据到<code>MergeTree</code>引擎表，然后通过分布式做路由分发查询而已。那么问题来了，什么场景要写入到分布式表呢？<br>因为分布式表建表语句支持指定分片索引<code>sharding_key</code>，这个<code>sharding_key</code>可以把通过分布式表写入的数据转发到同一个<code>shard</code>，那么在同一个shard里的数据才能满足<strong>排序主键和去重</strong>。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]</span><br><span class="line">(</span><br><span class="line">    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],</span><br><span class="line">    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],</span><br><span class="line">    ...</span><br><span class="line">) ENGINE &#x3D; Distributed(cluster, database, table[, sharding_key[, policy_name]])</span><br><span class="line">[SETTINGS name&#x3D;value, ...]</span><br></pre></td></tr></table></figure></li>
<li>可以使用<code>xxHash32</code>函数来对要去重的字段进行哈希计算后路由到同一个分片上<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENGINE &#x3D; Distributed(&#39;cluster&#39;, &#39;database&#39;, &#39;table_local&#39;, xxHash32(logid))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="system-metrics"><a href="#system-metrics" class="headerlink" title="system.metrics"></a>system.metrics</h3><ul>
<li><p>介绍</p>
<blockquote>
<p><a href="https://clickhouse.com/docs/en/operations/system-tables/metrics/" target="_blank" rel="noopener">地址</a>,该表包含了被直接算计的指标，或者当前值，举例就是同时查询的进程数，或者当前副本延迟时间，这个表一直被实时更新。<br>该表包含3个元素，如下</p>
<ul>
<li>metric (String) — 指标名.</li>
<li>value (Int64) — 指标值.</li>
<li>description (String) — 指标描述.</li>
</ul>
</blockquote>
</li>
<li><p>找出当前每个节点分布式文件写入的总数，找出最高的那个节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from system.metrics where metric &#x3D; &#39;DistributedFilesToInsert&#39;</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/1.png" alt="clickhouse"></p>
</li>
</ul>
<h3 id="system-distribution-queue"><a href="#system-distribution-queue" class="headerlink" title="system.distribution_queue"></a>system.distribution_queue</h3><ul>
<li>介绍<blockquote>
<p><a href="https://clickhouse.com/docs/en/operations/system-tables/distribution_queue/" target="_blank" rel="noopener">地址</a>，该表包含了关于本地文件等待传递到shard的队列信息，这些本地文件包含的用异步方式通过写入分布式表创建的新part文件。  </p>
</blockquote>
</li>
</ul>
<p>该表包含字段如下：</p>
<ul>
<li><p>database (String) — 数据库名称.</p>
</li>
<li><p>table (String) — 表名称.</p>
</li>
<li><p>data_path (String) — 本地文件的路径.</p>
</li>
<li><p>is_blocked (UInt8) — 标示位，是否传递文件到服务器被锁住.</p>
</li>
<li><p>error_count (UInt64) — 错误数.</p>
</li>
<li><p>data_files (UInt64) — 一个目录下文件个数.</p>
</li>
<li><p>data_compressed_bytes (UInt64) — 单位字节，被压缩的数据大小.</p>
</li>
<li><p>broken_data_files (UInt64) — 由于错误而标示损坏的文件数.</p>
</li>
<li><p>broken_data_compressed_bytes (UInt64) — 单位字节，所损文件的压缩字节大小.</p>
</li>
<li><p>last_exception (String) — 上次发生错误的内容.</p>
</li>
</ul>
<ul>
<li>去最高的那个节点查找正在写入的队列<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from system.distribution_queue where data_files &gt; 0</span><br></pre></td></tr></table></figure>
<img src="/images/clickhouse/distribute/2.png" alt="clickhouse"><blockquote>
<p>通过<code>data_files</code>可以看到当前在等待写入的文件数，通过<code>data_compressed_bytes</code>可以看到当前等待写入的总文件大小，通过<code>error_count</code>可以看到错误次数，通过<code>last_exception</code>可以看到上次发生错误的内容</p>
</blockquote>
</li>
</ul>
<h3 id="若是clickhosue19版本，则使用以下命令查询"><a href="#若是clickhosue19版本，则使用以下命令查询" class="headerlink" title="若是clickhosue19版本，则使用以下命令查询"></a>若是clickhosue19版本，则使用以下命令查询</h3><ul>
<li>查出分布式表存储的路径配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd config.d</span><br><span class="line">cat storage.xml</span><br><span class="line">&lt;path&gt;&#x2F;data1&#x2F;default&#x2F;clickhouse-data&lt;&#x2F;path&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果不是这样的配置，直接查询 <code>storage_configuration</code>的配置</p>
</blockquote>
</li>
<li><p>进入分布式表的存储目录，计算出每个库表的总文件数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;data1&#x2F;default&#x2F;clickhouse-data&#x2F;data</span><br><span class="line"># find -type f 表示查找出所有类型是文件的格式</span><br><span class="line"># awk -F &#39;,&#39; &#39;&#123;print $1&#125;&#39; 表示按照,切割后取第一个</span><br><span class="line"># uniq -c 表示聚合后去重</span><br><span class="line"># sort -h -r 表示逆序排序</span><br><span class="line"># awk -F &#39;&#x2F;default&#39; &#39;&#123;print $1&#125;&#39; 表示按&#x2F;default切割后取第一条</span><br><span class="line">find -type f | awk -F &#39;,&#39; &#39;&#123;print $1&#125;&#39; |  uniq -c | sort -h -r | awk -F &#39;&#x2F;default&#39; &#39;&#123;print $1&#125;&#39;</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/3.png" alt="clickhouse"></p>
<blockquote>
<p>文件数目最多的就是写入积压的</p>
</blockquote>
</li>
<li><p>根据flush命令获取到写入错误的原因</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYSTEM FLUSH DISTRIBUTED db.tb</span><br></pre></td></tr></table></figure>
<p><img src="/images/clickhouse/distribute/4.png" alt="clickhouse"></p>
<blockquote>
<p>根据错误能直接解决就直接去解决，无法解决的话看下面</p>
<h3 id="解决分布式表写入积压"><a href="#解决分布式表写入积压" class="headerlink" title="解决分布式表写入积压"></a>解决分布式表写入积压</h3></blockquote>
</li>
<li>删除分布式表<blockquote>
<p>则意味着这个分布式表的所有写入任务都会自动清理，谨慎操作，别把底表删了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table if exists db.tb</span><br></pre></td></tr></table></figure></blockquote>
</li>
<li>清空分布式表数据<blockquote>
<p>这个方式只是清除掉积压的数据，不用删表，用户通过分布式表来查询时不会报表不存在，但是如果数据量非常大就不要用truncate方式了，因为会导致整个表被锁非常久，应该用<code>alter table xx drop partititon xx</code>方式，一个一个分区删。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate table db.tb</span><br></pre></td></tr></table></figure></blockquote>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Blank Lin</p>
  <div class="site-description" itemprop="description">say something about me</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Blank Lin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
